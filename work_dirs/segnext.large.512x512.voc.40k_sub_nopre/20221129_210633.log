2022-11-29 21:06:33,733 - mmseg - INFO - Multi-processing start method is `None`
2022-11-29 21:06:33,733 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>
2022-11-29 21:06:33,780 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.8 (default, Apr 13 2021, 19:58:26) [GCC 7.3.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.5, V11.5.119
GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-3)
PyTorch: 1.11.0+cu102
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.2-Product Build 20210312 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu102
OpenCV: 4.6.0
MMCV: 1.6.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 10.2
MMSegmentation: 0.24.1+
------------------------------------------------------------

2022-11-29 21:06:33,780 - mmseg - INFO - Distributed training: False
2022-11-29 21:06:34,080 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
ham_norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='MSCAN',
        embed_dims=[64, 128, 320, 512],
        mlp_ratios=[8, 8, 4, 4],
        drop_rate=0.0,
        drop_path_rate=0.3,
        depths=[3, 5, 27, 3],
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        init_cfg=dict()),
    decode_head=dict(
        type='LightHamHead',
        in_channels=[128, 320, 512],
        in_index=[1, 2, 3],
        channels=1024,
        ham_channels=1024,
        dropout_ratio=0.1,
        num_classes=21,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'PascalVOCDataset'
data_root = '/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=1,
    train=dict(
        type='PascalVOCDataset',
        data_root='/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/train_sub.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='PascalVOCDataset',
        data_root='/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='PascalVOCDataset',
        data_root='/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/test.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=40000)
checkpoint_config = dict(by_epoch=False, interval=5000)
evaluation = dict(interval=5000, metric='mIoU')
find_unused_parameters = True
work_dir = './work_dirs/segnext.large.512x512.voc.40k_sub_nopre'
gpu_ids = [0]
auto_resume = False

2022-11-29 21:06:34,080 - mmseg - INFO - Set random seed to 471590485, deterministic: False
2022-11-29 21:06:34,572 - mmseg - INFO - initialize LightHamHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.patch_embed1.proj.0.weight - torch.Size([32, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed1.proj.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed1.proj.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed1.proj.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed1.proj.3.weight - torch.Size([64, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed1.proj.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed1.proj.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed1.proj.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.layer_scale_1 - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.layer_scale_2 - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.proj_1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.proj_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([64, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([64, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([64, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([64, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([64, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([64, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv3.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.spatial_gating_unit.conv3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.proj_2.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.attn.proj_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.mlp.fc1.weight - torch.Size([512, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.mlp.fc1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.mlp.dwconv.dwconv.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.mlp.dwconv.dwconv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.mlp.fc2.weight - torch.Size([64, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.0.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.layer_scale_1 - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.layer_scale_2 - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.proj_1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.proj_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([64, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([64, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([64, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([64, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([64, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([64, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv3.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.spatial_gating_unit.conv3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.proj_2.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.attn.proj_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.mlp.fc1.weight - torch.Size([512, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.mlp.fc1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.mlp.dwconv.dwconv.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.mlp.dwconv.dwconv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.mlp.fc2.weight - torch.Size([64, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.1.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.layer_scale_1 - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.layer_scale_2 - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.proj_1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.proj_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([64, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([64, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([64, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([64, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([64, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([64, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv3.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.spatial_gating_unit.conv3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.proj_2.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.attn.proj_2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.mlp.fc1.weight - torch.Size([512, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.mlp.fc1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.mlp.dwconv.dwconv.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.mlp.dwconv.dwconv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.mlp.fc2.weight - torch.Size([64, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block1.2.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed2.proj.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed2.proj.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed2.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed2.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.layer_scale_1 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.layer_scale_2 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.proj_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.attn.proj_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.0.mlp.fc2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.layer_scale_1 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.layer_scale_2 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.proj_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.attn.proj_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.1.mlp.fc2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.layer_scale_1 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.layer_scale_2 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.proj_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.attn.proj_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.2.mlp.fc2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.layer_scale_1 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.layer_scale_2 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.proj_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.attn.proj_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.3.mlp.fc2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.layer_scale_1 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.layer_scale_2 - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.proj_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.attn.proj_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block2.4.mlp.fc2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed3.proj.weight - torch.Size([320, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed3.proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed3.norm.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed3.norm.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.0.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.1.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.2.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.3.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.4.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.5.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.6.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.7.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.8.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.9.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.10.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.11.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.12.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.13.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.14.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.15.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.16.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.17.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.18.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.19.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.20.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.21.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.22.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.23.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.24.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.25.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.layer_scale_1 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.layer_scale_2 - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.proj_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.attn.proj_2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block3.26.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed4.proj.weight - torch.Size([512, 320, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed4.proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed4.norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed4.norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.layer_scale_1 - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.layer_scale_2 - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.proj_1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.proj_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv0.weight - torch.Size([512, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([512, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([512, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([512, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([512, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([512, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([512, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv3.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.spatial_gating_unit.conv3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.proj_2.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.attn.proj_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.mlp.fc1.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.mlp.fc1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.mlp.dwconv.dwconv.weight - torch.Size([2048, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.mlp.dwconv.dwconv.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.mlp.fc2.weight - torch.Size([512, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.0.mlp.fc2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.layer_scale_1 - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.layer_scale_2 - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.proj_1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.proj_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv0.weight - torch.Size([512, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([512, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([512, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([512, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([512, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([512, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([512, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv3.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.spatial_gating_unit.conv3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.proj_2.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.attn.proj_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.mlp.fc1.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.mlp.fc1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.mlp.dwconv.dwconv.weight - torch.Size([2048, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.mlp.dwconv.dwconv.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.mlp.fc2.weight - torch.Size([512, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.1.mlp.fc2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.layer_scale_1 - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.layer_scale_2 - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.proj_1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.proj_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv0.weight - torch.Size([512, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([512, 1, 1, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([512, 1, 7, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([512, 1, 1, 11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([512, 1, 11, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([512, 1, 1, 21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([512, 1, 21, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv3.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.spatial_gating_unit.conv3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.proj_2.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.attn.proj_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.mlp.fc1.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.mlp.fc1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.mlp.dwconv.dwconv.weight - torch.Size([2048, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.mlp.dwconv.dwconv.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.mlp.fc2.weight - torch.Size([512, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.block4.2.mlp.fc2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([21, 1024, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([21]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.squeeze.conv.weight - torch.Size([1024, 960, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.squeeze.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.squeeze.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_in.conv.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_in.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_out.conv.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_out.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_out.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.conv.weight - torch.Size([1024, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.align.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2022-11-29 21:06:34,606 - mmseg - INFO - EncoderDecoder(
  (backbone): MSCAN(
    (patch_embed1): StemConv(
      (proj): Sequential(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU()
        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)
            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)
            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)
            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)
            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)
            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)
            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)
            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)
            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)
            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)
            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)
            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)
            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)
            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)
            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)
            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)
            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)
            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)
            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (conv0_1): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=512)
            (conv0_2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=512)
            (conv1_1): Conv2d(512, 512, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=512)
            (conv1_2): Conv2d(512, 512, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=512)
            (conv2_1): Conv2d(512, 512, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=512)
            (conv2_2): Conv2d(512, 512, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=512)
            (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (conv0_1): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=512)
            (conv0_2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=512)
            (conv1_1): Conv2d(512, 512, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=512)
            (conv1_2): Conv2d(512, 512, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=512)
            (conv2_1): Conv2d(512, 512, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=512)
            (conv2_2): Conv2d(512, 512, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=512)
            (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (conv0_1): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=512)
            (conv0_2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=512)
            (conv1_1): Conv2d(512, 512, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=512)
            (conv1_2): Conv2d(512, 512, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=512)
            (conv2_1): Conv2d(512, 512, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=512)
            (conv2_2): Conv2d(512, 512, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=512)
            (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decode_head): LightHamHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(1024, 21, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (squeeze): ConvModule(
      (conv): Conv2d(960, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
    (hamburger): Hamburger(
      (ham_in): ConvModule(
        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (ham): NMF2D()
      (ham_out): ConvModule(
        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
      )
    )
    (align): ConvModule(
      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2022-11-29 21:06:34,654 - mmseg - INFO - Loaded 183 images
2022-11-29 21:06:37,830 - mmseg - INFO - Loaded 724 images
2022-11-29 21:06:37,831 - mmseg - INFO - Start running, host: yl407@dcc-carlsonlab-gpu-13, work_dir: /work/yl407/SegNeXt/work_dirs/segnext.large.512x512.voc.40k_sub_nopre
2022-11-29 21:06:37,831 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-11-29 21:06:37,832 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters
2022-11-29 21:06:37,833 - mmseg - INFO - Checkpoints will be saved to /work/yl407/SegNeXt/work_dirs/segnext.large.512x512.voc.40k_sub_nopre by HardDiskBackend.
2022-11-29 21:06:52,984 - mmseg - INFO - Iter [50/40000]	lr: 1.958e-06, eta: 3:20:05, time: 0.301, data_time: 0.010, memory: 5537, decode.loss_ce: 2.3073, decode.acc_seg: 29.7545, loss: 2.3073
2022-11-29 21:07:06,410 - mmseg - INFO - Iter [100/40000]	lr: 3.950e-06, eta: 3:09:12, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.7499, decode.acc_seg: 60.4354, loss: 1.7499
2022-11-29 21:07:19,863 - mmseg - INFO - Iter [150/40000]	lr: 5.938e-06, eta: 3:05:31, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4689, decode.acc_seg: 62.6580, loss: 1.4689
2022-11-29 21:07:35,519 - mmseg - INFO - Iter [200/40000]	lr: 7.920e-06, eta: 3:10:53, time: 0.313, data_time: 0.048, memory: 5537, decode.loss_ce: 1.3311, decode.acc_seg: 66.9993, loss: 1.3311
2022-11-29 21:07:49,099 - mmseg - INFO - Iter [250/40000]	lr: 9.898e-06, eta: 3:08:30, time: 0.272, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4309, decode.acc_seg: 64.3485, loss: 1.4309
2022-11-29 21:08:02,761 - mmseg - INFO - Iter [300/40000]	lr: 1.187e-05, eta: 3:07:01, time: 0.273, data_time: 0.006, memory: 5537, decode.loss_ce: 1.6707, decode.acc_seg: 58.7883, loss: 1.6707
2022-11-29 21:08:16,327 - mmseg - INFO - Iter [350/40000]	lr: 1.384e-05, eta: 3:05:42, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 1.6075, decode.acc_seg: 58.6716, loss: 1.6075
2022-11-29 21:08:32,043 - mmseg - INFO - Iter [400/40000]	lr: 1.580e-05, eta: 3:08:13, time: 0.314, data_time: 0.047, memory: 5537, decode.loss_ce: 1.3348, decode.acc_seg: 66.4359, loss: 1.3348
2022-11-29 21:08:45,678 - mmseg - INFO - Iter [450/40000]	lr: 1.776e-05, eta: 3:07:04, time: 0.273, data_time: 0.006, memory: 5537, decode.loss_ce: 1.5007, decode.acc_seg: 61.5268, loss: 1.5007
2022-11-29 21:08:59,152 - mmseg - INFO - Iter [500/40000]	lr: 1.971e-05, eta: 3:05:53, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2993, decode.acc_seg: 66.0155, loss: 1.2993
2022-11-29 21:09:14,713 - mmseg - INFO - Iter [550/40000]	lr: 2.166e-05, eta: 3:07:22, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 1.4630, decode.acc_seg: 64.6914, loss: 1.4630
2022-11-29 21:09:27,938 - mmseg - INFO - Iter [600/40000]	lr: 2.360e-05, eta: 3:06:01, time: 0.264, data_time: 0.005, memory: 5537, decode.loss_ce: 1.4562, decode.acc_seg: 62.5303, loss: 1.4562
2022-11-29 21:09:41,270 - mmseg - INFO - Iter [650/40000]	lr: 2.554e-05, eta: 3:04:56, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4481, decode.acc_seg: 62.7831, loss: 1.4481
2022-11-29 21:09:54,672 - mmseg - INFO - Iter [700/40000]	lr: 2.747e-05, eta: 3:04:03, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3917, decode.acc_seg: 67.0723, loss: 1.3917
2022-11-29 21:10:10,650 - mmseg - INFO - Iter [750/40000]	lr: 2.940e-05, eta: 3:05:30, time: 0.320, data_time: 0.049, memory: 5537, decode.loss_ce: 1.5340, decode.acc_seg: 64.6547, loss: 1.5340
2022-11-29 21:10:23,913 - mmseg - INFO - Iter [800/40000]	lr: 3.132e-05, eta: 3:04:30, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 1.6322, decode.acc_seg: 58.6734, loss: 1.6322
2022-11-29 21:10:37,238 - mmseg - INFO - Iter [850/40000]	lr: 3.324e-05, eta: 3:03:40, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4338, decode.acc_seg: 62.4622, loss: 1.4338
2022-11-29 21:10:50,607 - mmseg - INFO - Iter [900/40000]	lr: 3.515e-05, eta: 3:02:55, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3997, decode.acc_seg: 65.4960, loss: 1.3997
2022-11-29 21:11:06,061 - mmseg - INFO - Iter [950/40000]	lr: 3.706e-05, eta: 3:03:39, time: 0.309, data_time: 0.047, memory: 5537, decode.loss_ce: 1.3140, decode.acc_seg: 67.0312, loss: 1.3140
2022-11-29 21:11:19,304 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:11:19,304 - mmseg - INFO - Iter [1000/40000]	lr: 3.896e-05, eta: 3:02:51, time: 0.265, data_time: 0.005, memory: 5537, decode.loss_ce: 1.5270, decode.acc_seg: 62.9430, loss: 1.5270
2022-11-29 21:11:32,664 - mmseg - INFO - Iter [1050/40000]	lr: 4.086e-05, eta: 3:02:11, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.5534, decode.acc_seg: 60.7231, loss: 1.5534
2022-11-29 21:11:48,134 - mmseg - INFO - Iter [1100/40000]	lr: 4.275e-05, eta: 3:02:48, time: 0.309, data_time: 0.048, memory: 5537, decode.loss_ce: 1.4291, decode.acc_seg: 63.9612, loss: 1.4291
2022-11-29 21:12:01,447 - mmseg - INFO - Iter [1150/40000]	lr: 4.464e-05, eta: 3:02:07, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4018, decode.acc_seg: 63.5494, loss: 1.4018
2022-11-29 21:12:14,835 - mmseg - INFO - Iter [1200/40000]	lr: 4.652e-05, eta: 3:01:31, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2651, decode.acc_seg: 67.8025, loss: 1.2651
2022-11-29 21:12:28,276 - mmseg - INFO - Iter [1250/40000]	lr: 4.840e-05, eta: 3:00:59, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.5541, decode.acc_seg: 58.0918, loss: 1.5541
2022-11-29 21:12:44,311 - mmseg - INFO - Iter [1300/40000]	lr: 5.027e-05, eta: 3:01:45, time: 0.321, data_time: 0.047, memory: 5537, decode.loss_ce: 1.5422, decode.acc_seg: 61.1370, loss: 1.5422
2022-11-29 21:13:00,312 - mmseg - INFO - Iter [1350/40000]	lr: 5.214e-05, eta: 3:02:25, time: 0.320, data_time: 0.006, memory: 5537, decode.loss_ce: 1.6008, decode.acc_seg: 63.4031, loss: 1.6008
2022-11-29 21:13:16,406 - mmseg - INFO - Iter [1400/40000]	lr: 5.400e-05, eta: 3:03:05, time: 0.322, data_time: 0.006, memory: 5537, decode.loss_ce: 1.5042, decode.acc_seg: 61.0497, loss: 1.5042
2022-11-29 21:13:32,406 - mmseg - INFO - Iter [1450/40000]	lr: 5.586e-05, eta: 3:03:37, time: 0.320, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4033, decode.acc_seg: 66.8551, loss: 1.4033
2022-11-29 21:13:48,816 - mmseg - INFO - Iter [1500/40000]	lr: 5.771e-05, eta: 3:04:18, time: 0.328, data_time: 0.047, memory: 5537, decode.loss_ce: 1.4093, decode.acc_seg: 63.5669, loss: 1.4093
2022-11-29 21:14:02,277 - mmseg - INFO - Iter [1550/40000]	lr: 5.768e-05, eta: 3:03:41, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3955, decode.acc_seg: 63.4623, loss: 1.3955
2022-11-29 21:14:15,638 - mmseg - INFO - Iter [1600/40000]	lr: 5.760e-05, eta: 3:03:03, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.6063, decode.acc_seg: 59.7884, loss: 1.6063
2022-11-29 21:14:31,126 - mmseg - INFO - Iter [1650/40000]	lr: 5.753e-05, eta: 3:03:16, time: 0.310, data_time: 0.047, memory: 5537, decode.loss_ce: 1.4150, decode.acc_seg: 66.2966, loss: 1.4150
2022-11-29 21:14:45,814 - mmseg - INFO - Iter [1700/40000]	lr: 5.745e-05, eta: 3:03:10, time: 0.294, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2423, decode.acc_seg: 67.9405, loss: 1.2423
2022-11-29 21:14:59,357 - mmseg - INFO - Iter [1750/40000]	lr: 5.738e-05, eta: 3:02:38, time: 0.271, data_time: 0.005, memory: 5537, decode.loss_ce: 1.4509, decode.acc_seg: 63.1360, loss: 1.4509
2022-11-29 21:15:13,352 - mmseg - INFO - Iter [1800/40000]	lr: 5.730e-05, eta: 3:02:17, time: 0.280, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3108, decode.acc_seg: 67.0911, loss: 1.3108
2022-11-29 21:15:29,227 - mmseg - INFO - Iter [1850/40000]	lr: 5.723e-05, eta: 3:02:34, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 1.5754, decode.acc_seg: 58.2251, loss: 1.5754
2022-11-29 21:15:42,580 - mmseg - INFO - Iter [1900/40000]	lr: 5.715e-05, eta: 3:02:00, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4043, decode.acc_seg: 65.2179, loss: 1.4043
2022-11-29 21:15:55,909 - mmseg - INFO - Iter [1950/40000]	lr: 5.708e-05, eta: 3:01:26, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.5473, decode.acc_seg: 57.9069, loss: 1.5473
2022-11-29 21:16:09,687 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:16:09,688 - mmseg - INFO - Iter [2000/40000]	lr: 5.700e-05, eta: 3:01:02, time: 0.276, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4763, decode.acc_seg: 62.9311, loss: 1.4763
2022-11-29 21:16:25,323 - mmseg - INFO - Iter [2050/40000]	lr: 5.693e-05, eta: 3:01:12, time: 0.313, data_time: 0.047, memory: 5537, decode.loss_ce: 1.4635, decode.acc_seg: 63.0794, loss: 1.4635
2022-11-29 21:16:38,638 - mmseg - INFO - Iter [2100/40000]	lr: 5.685e-05, eta: 3:00:40, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3673, decode.acc_seg: 68.4315, loss: 1.3673
2022-11-29 21:16:52,086 - mmseg - INFO - Iter [2150/40000]	lr: 5.678e-05, eta: 3:00:10, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.5774, decode.acc_seg: 58.3474, loss: 1.5774
2022-11-29 21:17:07,679 - mmseg - INFO - Iter [2200/40000]	lr: 5.670e-05, eta: 3:00:19, time: 0.312, data_time: 0.047, memory: 5537, decode.loss_ce: 1.3151, decode.acc_seg: 65.6790, loss: 1.3151
2022-11-29 21:17:22,266 - mmseg - INFO - Iter [2250/40000]	lr: 5.663e-05, eta: 3:00:09, time: 0.292, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4675, decode.acc_seg: 64.8734, loss: 1.4675
2022-11-29 21:17:35,615 - mmseg - INFO - Iter [2300/40000]	lr: 5.655e-05, eta: 2:59:39, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3793, decode.acc_seg: 62.9658, loss: 1.3793
2022-11-29 21:17:49,050 - mmseg - INFO - Iter [2350/40000]	lr: 5.648e-05, eta: 2:59:11, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4667, decode.acc_seg: 59.2067, loss: 1.4667
2022-11-29 21:18:05,113 - mmseg - INFO - Iter [2400/40000]	lr: 5.640e-05, eta: 2:59:24, time: 0.321, data_time: 0.049, memory: 5537, decode.loss_ce: 1.2590, decode.acc_seg: 65.9968, loss: 1.2590
2022-11-29 21:18:20,082 - mmseg - INFO - Iter [2450/40000]	lr: 5.633e-05, eta: 2:59:20, time: 0.299, data_time: 0.007, memory: 5537, decode.loss_ce: 1.4010, decode.acc_seg: 63.5029, loss: 1.4010
2022-11-29 21:18:33,628 - mmseg - INFO - Iter [2500/40000]	lr: 5.625e-05, eta: 2:58:54, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 1.7110, decode.acc_seg: 54.2397, loss: 1.7110
2022-11-29 21:18:47,041 - mmseg - INFO - Iter [2550/40000]	lr: 5.618e-05, eta: 2:58:26, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.1574, decode.acc_seg: 70.3728, loss: 1.1574
2022-11-29 21:19:02,700 - mmseg - INFO - Iter [2600/40000]	lr: 5.610e-05, eta: 2:58:32, time: 0.313, data_time: 0.047, memory: 5537, decode.loss_ce: 1.3352, decode.acc_seg: 65.7658, loss: 1.3352
2022-11-29 21:19:16,177 - mmseg - INFO - Iter [2650/40000]	lr: 5.603e-05, eta: 2:58:06, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3643, decode.acc_seg: 65.0044, loss: 1.3643
2022-11-29 21:19:29,625 - mmseg - INFO - Iter [2700/40000]	lr: 5.595e-05, eta: 2:57:39, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4921, decode.acc_seg: 61.6995, loss: 1.4921
2022-11-29 21:19:45,137 - mmseg - INFO - Iter [2750/40000]	lr: 5.588e-05, eta: 2:57:42, time: 0.310, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2932, decode.acc_seg: 65.3843, loss: 1.2932
2022-11-29 21:19:58,512 - mmseg - INFO - Iter [2800/40000]	lr: 5.580e-05, eta: 2:57:15, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3268, decode.acc_seg: 67.0519, loss: 1.3268
2022-11-29 21:20:11,935 - mmseg - INFO - Iter [2850/40000]	lr: 5.573e-05, eta: 2:56:49, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4168, decode.acc_seg: 61.4286, loss: 1.4168
2022-11-29 21:20:25,324 - mmseg - INFO - Iter [2900/40000]	lr: 5.565e-05, eta: 2:56:24, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4263, decode.acc_seg: 62.4639, loss: 1.4263
2022-11-29 21:20:41,867 - mmseg - INFO - Iter [2950/40000]	lr: 5.558e-05, eta: 2:56:38, time: 0.331, data_time: 0.048, memory: 5537, decode.loss_ce: 1.4423, decode.acc_seg: 60.7053, loss: 1.4423
2022-11-29 21:20:55,313 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:20:55,313 - mmseg - INFO - Iter [3000/40000]	lr: 5.550e-05, eta: 2:56:13, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4255, decode.acc_seg: 63.3417, loss: 1.4255
2022-11-29 21:21:08,621 - mmseg - INFO - Iter [3050/40000]	lr: 5.543e-05, eta: 2:55:47, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4513, decode.acc_seg: 62.6494, loss: 1.4513
2022-11-29 21:21:22,006 - mmseg - INFO - Iter [3100/40000]	lr: 5.535e-05, eta: 2:55:22, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3440, decode.acc_seg: 64.2188, loss: 1.3440
2022-11-29 21:21:37,965 - mmseg - INFO - Iter [3150/40000]	lr: 5.528e-05, eta: 2:55:28, time: 0.319, data_time: 0.047, memory: 5537, decode.loss_ce: 1.4476, decode.acc_seg: 62.7488, loss: 1.4476
2022-11-29 21:21:51,376 - mmseg - INFO - Iter [3200/40000]	lr: 5.520e-05, eta: 2:55:03, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2659, decode.acc_seg: 67.9253, loss: 1.2659
2022-11-29 21:22:04,680 - mmseg - INFO - Iter [3250/40000]	lr: 5.513e-05, eta: 2:54:38, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 1.5171, decode.acc_seg: 58.8763, loss: 1.5171
2022-11-29 21:22:20,191 - mmseg - INFO - Iter [3300/40000]	lr: 5.505e-05, eta: 2:54:38, time: 0.310, data_time: 0.047, memory: 5537, decode.loss_ce: 1.3903, decode.acc_seg: 59.3036, loss: 1.3903
2022-11-29 21:22:33,914 - mmseg - INFO - Iter [3350/40000]	lr: 5.498e-05, eta: 2:54:17, time: 0.274, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2769, decode.acc_seg: 66.1530, loss: 1.2769
2022-11-29 21:22:49,935 - mmseg - INFO - Iter [3400/40000]	lr: 5.490e-05, eta: 2:54:22, time: 0.320, data_time: 0.006, memory: 5537, decode.loss_ce: 1.6200, decode.acc_seg: 55.6941, loss: 1.6200
2022-11-29 21:23:05,970 - mmseg - INFO - Iter [3450/40000]	lr: 5.483e-05, eta: 2:54:26, time: 0.321, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4167, decode.acc_seg: 62.9086, loss: 1.4167
2022-11-29 21:23:22,922 - mmseg - INFO - Iter [3500/40000]	lr: 5.475e-05, eta: 2:54:39, time: 0.339, data_time: 0.047, memory: 5537, decode.loss_ce: 1.2707, decode.acc_seg: 68.3801, loss: 1.2707
2022-11-29 21:23:36,210 - mmseg - INFO - Iter [3550/40000]	lr: 5.468e-05, eta: 2:54:14, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3528, decode.acc_seg: 62.9581, loss: 1.3528
2022-11-29 21:23:49,572 - mmseg - INFO - Iter [3600/40000]	lr: 5.460e-05, eta: 2:53:50, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4367, decode.acc_seg: 62.0302, loss: 1.4367
2022-11-29 21:24:03,007 - mmseg - INFO - Iter [3650/40000]	lr: 5.453e-05, eta: 2:53:27, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 1.5547, decode.acc_seg: 58.1544, loss: 1.5547
2022-11-29 21:24:18,670 - mmseg - INFO - Iter [3700/40000]	lr: 5.445e-05, eta: 2:53:25, time: 0.313, data_time: 0.048, memory: 5537, decode.loss_ce: 1.3571, decode.acc_seg: 63.4529, loss: 1.3571
2022-11-29 21:24:32,026 - mmseg - INFO - Iter [3750/40000]	lr: 5.438e-05, eta: 2:53:02, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.5174, decode.acc_seg: 61.0419, loss: 1.5174
2022-11-29 21:24:45,422 - mmseg - INFO - Iter [3800/40000]	lr: 5.430e-05, eta: 2:52:39, time: 0.268, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2573, decode.acc_seg: 67.3108, loss: 1.2573
2022-11-29 21:25:00,899 - mmseg - INFO - Iter [3850/40000]	lr: 5.423e-05, eta: 2:52:35, time: 0.310, data_time: 0.047, memory: 5537, decode.loss_ce: 1.1145, decode.acc_seg: 67.4404, loss: 1.1145
2022-11-29 21:25:14,252 - mmseg - INFO - Iter [3900/40000]	lr: 5.415e-05, eta: 2:52:12, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2636, decode.acc_seg: 63.4317, loss: 1.2636
2022-11-29 21:25:27,634 - mmseg - INFO - Iter [3950/40000]	lr: 5.408e-05, eta: 2:51:49, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4277, decode.acc_seg: 62.6597, loss: 1.4277
2022-11-29 21:25:41,042 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:25:41,042 - mmseg - INFO - Iter [4000/40000]	lr: 5.400e-05, eta: 2:51:27, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4229, decode.acc_seg: 62.3334, loss: 1.4229
2022-11-29 21:25:56,730 - mmseg - INFO - Iter [4050/40000]	lr: 5.393e-05, eta: 2:51:25, time: 0.314, data_time: 0.048, memory: 5537, decode.loss_ce: 1.3297, decode.acc_seg: 65.7263, loss: 1.3297
2022-11-29 21:26:10,142 - mmseg - INFO - Iter [4100/40000]	lr: 5.385e-05, eta: 2:51:03, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3458, decode.acc_seg: 63.8614, loss: 1.3458
2022-11-29 21:26:23,477 - mmseg - INFO - Iter [4150/40000]	lr: 5.378e-05, eta: 2:50:40, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4598, decode.acc_seg: 60.1057, loss: 1.4598
2022-11-29 21:26:36,817 - mmseg - INFO - Iter [4200/40000]	lr: 5.370e-05, eta: 2:50:18, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4436, decode.acc_seg: 58.3554, loss: 1.4436
2022-11-29 21:26:52,261 - mmseg - INFO - Iter [4250/40000]	lr: 5.363e-05, eta: 2:50:13, time: 0.309, data_time: 0.047, memory: 5537, decode.loss_ce: 1.4120, decode.acc_seg: 62.3139, loss: 1.4120
2022-11-29 21:27:05,660 - mmseg - INFO - Iter [4300/40000]	lr: 5.355e-05, eta: 2:49:52, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3197, decode.acc_seg: 64.0023, loss: 1.3197
2022-11-29 21:27:18,992 - mmseg - INFO - Iter [4350/40000]	lr: 5.348e-05, eta: 2:49:30, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2911, decode.acc_seg: 64.7679, loss: 1.2911
2022-11-29 21:27:34,566 - mmseg - INFO - Iter [4400/40000]	lr: 5.340e-05, eta: 2:49:26, time: 0.311, data_time: 0.048, memory: 5537, decode.loss_ce: 1.3295, decode.acc_seg: 63.1131, loss: 1.3295
2022-11-29 21:27:47,980 - mmseg - INFO - Iter [4450/40000]	lr: 5.333e-05, eta: 2:49:05, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3775, decode.acc_seg: 57.8217, loss: 1.3775
2022-11-29 21:28:01,309 - mmseg - INFO - Iter [4500/40000]	lr: 5.325e-05, eta: 2:48:43, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4297, decode.acc_seg: 61.7342, loss: 1.4297
2022-11-29 21:28:14,637 - mmseg - INFO - Iter [4550/40000]	lr: 5.318e-05, eta: 2:48:22, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2827, decode.acc_seg: 67.6524, loss: 1.2827
2022-11-29 21:28:30,066 - mmseg - INFO - Iter [4600/40000]	lr: 5.310e-05, eta: 2:48:17, time: 0.309, data_time: 0.047, memory: 5537, decode.loss_ce: 1.4092, decode.acc_seg: 65.6511, loss: 1.4092
2022-11-29 21:28:43,381 - mmseg - INFO - Iter [4650/40000]	lr: 5.303e-05, eta: 2:47:55, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3593, decode.acc_seg: 62.1488, loss: 1.3593
2022-11-29 21:28:56,712 - mmseg - INFO - Iter [4700/40000]	lr: 5.295e-05, eta: 2:47:34, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2076, decode.acc_seg: 63.9671, loss: 1.2076
2022-11-29 21:29:10,022 - mmseg - INFO - Iter [4750/40000]	lr: 5.288e-05, eta: 2:47:13, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4680, decode.acc_seg: 59.7817, loss: 1.4680
2022-11-29 21:29:25,520 - mmseg - INFO - Iter [4800/40000]	lr: 5.280e-05, eta: 2:47:08, time: 0.310, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2879, decode.acc_seg: 64.0966, loss: 1.2879
2022-11-29 21:29:38,815 - mmseg - INFO - Iter [4850/40000]	lr: 5.273e-05, eta: 2:46:47, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 1.4824, decode.acc_seg: 60.1619, loss: 1.4824
2022-11-29 21:29:52,183 - mmseg - INFO - Iter [4900/40000]	lr: 5.265e-05, eta: 2:46:26, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 1.3894, decode.acc_seg: 62.4869, loss: 1.3894
2022-11-29 21:30:07,857 - mmseg - INFO - Iter [4950/40000]	lr: 5.258e-05, eta: 2:46:22, time: 0.313, data_time: 0.047, memory: 5537, decode.loss_ce: 1.3501, decode.acc_seg: 62.7192, loss: 1.3501
2022-11-29 21:30:21,185 - mmseg - INFO - Saving checkpoint at 5000 iterations
2022-11-29 21:30:23,675 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:30:23,676 - mmseg - INFO - Iter [5000/40000]	lr: 5.250e-05, eta: 2:46:19, time: 0.316, data_time: 0.006, memory: 5537, decode.loss_ce: 1.2643, decode.acc_seg: 63.5590, loss: 1.2643
2022-11-29 21:31:41,247 - mmseg - INFO - per class results:
2022-11-29 21:31:41,250 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 73.37 | 100.0 |
|  aeroplane  |  0.0  |  0.0  |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  0.0  |  0.0  |
|     boat    |  0.0  |  0.0  |
|    bottle   |  0.0  |  0.0  |
|     bus     |  0.0  |  0.0  |
|     car     |  0.0  |  0.0  |
|     cat     |  0.0  |  0.0  |
|    chair    |  0.0  |  0.0  |
|     cow     |  0.0  |  0.0  |
| diningtable |  0.0  |  0.0  |
|     dog     |  0.0  |  0.0  |
|    horse    |  0.0  |  0.0  |
|  motorbike  |  0.0  |  0.0  |
|    person   |  0.07 |  0.07 |
| pottedplant |  0.0  |  0.0  |
|    sheep    |  0.0  |  0.0  |
|     sofa    |  0.0  |  0.0  |
|    train    |  0.0  |  0.0  |
|  tvmonitor  |  0.0  |  0.0  |
+-------------+-------+-------+
2022-11-29 21:31:41,250 - mmseg - INFO - Summary:
2022-11-29 21:31:41,250 - mmseg - INFO - 
+-------+------+------+
|  aAcc | mIoU | mAcc |
+-------+------+------+
| 73.37 | 3.5  | 4.77 |
+-------+------+------+
2022-11-29 21:31:41,253 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:31:41,253 - mmseg - INFO - Iter(val) [724]	aAcc: 0.7337, mIoU: 0.0350, mAcc: 0.0477, IoU.background: 0.7337, IoU.aeroplane: 0.0000, IoU.bicycle: 0.0000, IoU.bird: 0.0000, IoU.boat: 0.0000, IoU.bottle: 0.0000, IoU.bus: 0.0000, IoU.car: 0.0000, IoU.cat: 0.0000, IoU.chair: 0.0000, IoU.cow: 0.0000, IoU.diningtable: 0.0000, IoU.dog: 0.0000, IoU.horse: 0.0000, IoU.motorbike: 0.0000, IoU.person: 0.0007, IoU.pottedplant: 0.0000, IoU.sheep: 0.0000, IoU.sofa: 0.0000, IoU.train: 0.0000, IoU.tvmonitor: 0.0000, Acc.background: 1.0000, Acc.aeroplane: 0.0000, Acc.bicycle: 0.0000, Acc.bird: 0.0000, Acc.boat: 0.0000, Acc.bottle: 0.0000, Acc.bus: 0.0000, Acc.car: 0.0000, Acc.cat: 0.0000, Acc.chair: 0.0000, Acc.cow: 0.0000, Acc.diningtable: 0.0000, Acc.dog: 0.0000, Acc.horse: 0.0000, Acc.motorbike: 0.0000, Acc.person: 0.0007, Acc.pottedplant: 0.0000, Acc.sheep: 0.0000, Acc.sofa: 0.0000, Acc.train: 0.0000, Acc.tvmonitor: 0.0000
2022-11-29 21:31:55,632 - mmseg - INFO - Iter [5050/40000]	lr: 5.243e-05, eta: 2:55:03, time: 1.839, data_time: 1.558, memory: 5537, decode.loss_ce: 1.5911, decode.acc_seg: 56.2459, loss: 1.5911
2022-11-29 21:32:09,937 - mmseg - INFO - Iter [5100/40000]	lr: 5.235e-05, eta: 2:54:43, time: 0.286, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2884, decode.acc_seg: 67.0157, loss: 1.2884
2022-11-29 21:32:26,522 - mmseg - INFO - Iter [5150/40000]	lr: 5.228e-05, eta: 2:54:38, time: 0.332, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2842, decode.acc_seg: 66.0346, loss: 1.2842
2022-11-29 21:32:40,159 - mmseg - INFO - Iter [5200/40000]	lr: 5.220e-05, eta: 2:54:14, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.4018, decode.acc_seg: 58.6192, loss: 1.4018
2022-11-29 21:32:53,849 - mmseg - INFO - Iter [5250/40000]	lr: 5.213e-05, eta: 2:53:50, time: 0.274, data_time: 0.006, memory: 5537, decode.loss_ce: 1.0796, decode.acc_seg: 68.8562, loss: 1.0796
2022-11-29 21:33:07,507 - mmseg - INFO - Iter [5300/40000]	lr: 5.205e-05, eta: 2:53:26, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.4548, decode.acc_seg: 58.9815, loss: 1.4548
2022-11-29 21:33:23,236 - mmseg - INFO - Iter [5350/40000]	lr: 5.198e-05, eta: 2:53:16, time: 0.315, data_time: 0.047, memory: 5537, decode.loss_ce: 1.3006, decode.acc_seg: 64.3705, loss: 1.3006
2022-11-29 21:33:36,933 - mmseg - INFO - Iter [5400/40000]	lr: 5.190e-05, eta: 2:52:52, time: 0.274, data_time: 0.006, memory: 5537, decode.loss_ce: 1.1518, decode.acc_seg: 65.4706, loss: 1.1518
2022-11-29 21:33:50,698 - mmseg - INFO - Iter [5450/40000]	lr: 5.183e-05, eta: 2:52:30, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.4580, decode.acc_seg: 56.8012, loss: 1.4580
2022-11-29 21:34:06,550 - mmseg - INFO - Iter [5500/40000]	lr: 5.175e-05, eta: 2:52:20, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 1.3747, decode.acc_seg: 63.9332, loss: 1.3747
2022-11-29 21:34:20,186 - mmseg - INFO - Iter [5550/40000]	lr: 5.168e-05, eta: 2:51:57, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3142, decode.acc_seg: 61.1889, loss: 1.3142
2022-11-29 21:34:33,834 - mmseg - INFO - Iter [5600/40000]	lr: 5.160e-05, eta: 2:51:34, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1894, decode.acc_seg: 62.7527, loss: 1.1894
2022-11-29 21:34:47,558 - mmseg - INFO - Iter [5650/40000]	lr: 5.153e-05, eta: 2:51:11, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1105, decode.acc_seg: 64.4791, loss: 1.1105
2022-11-29 21:35:04,060 - mmseg - INFO - Iter [5700/40000]	lr: 5.145e-05, eta: 2:51:06, time: 0.330, data_time: 0.048, memory: 5537, decode.loss_ce: 1.3634, decode.acc_seg: 62.9885, loss: 1.3634
2022-11-29 21:35:18,251 - mmseg - INFO - Iter [5750/40000]	lr: 5.138e-05, eta: 2:50:46, time: 0.284, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2954, decode.acc_seg: 65.3290, loss: 1.2954
2022-11-29 21:35:32,183 - mmseg - INFO - Iter [5800/40000]	lr: 5.130e-05, eta: 2:50:25, time: 0.279, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2634, decode.acc_seg: 62.9836, loss: 1.2634
2022-11-29 21:35:46,354 - mmseg - INFO - Iter [5850/40000]	lr: 5.123e-05, eta: 2:50:05, time: 0.283, data_time: 0.007, memory: 5537, decode.loss_ce: 1.4066, decode.acc_seg: 59.3940, loss: 1.4066
2022-11-29 21:36:02,096 - mmseg - INFO - Iter [5900/40000]	lr: 5.115e-05, eta: 2:49:55, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 1.3635, decode.acc_seg: 59.1206, loss: 1.3635
2022-11-29 21:36:15,759 - mmseg - INFO - Iter [5950/40000]	lr: 5.108e-05, eta: 2:49:33, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3813, decode.acc_seg: 60.4275, loss: 1.3813
2022-11-29 21:36:29,420 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:36:29,421 - mmseg - INFO - Iter [6000/40000]	lr: 5.100e-05, eta: 2:49:11, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2217, decode.acc_seg: 69.1619, loss: 1.2217
2022-11-29 21:36:45,290 - mmseg - INFO - Iter [6050/40000]	lr: 5.093e-05, eta: 2:49:01, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2115, decode.acc_seg: 67.8035, loss: 1.2115
2022-11-29 21:36:59,046 - mmseg - INFO - Iter [6100/40000]	lr: 5.085e-05, eta: 2:48:39, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0804, decode.acc_seg: 66.5892, loss: 1.0804
2022-11-29 21:37:12,815 - mmseg - INFO - Iter [6150/40000]	lr: 5.078e-05, eta: 2:48:18, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3387, decode.acc_seg: 61.1351, loss: 1.3387
2022-11-29 21:37:26,442 - mmseg - INFO - Iter [6200/40000]	lr: 5.070e-05, eta: 2:47:56, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3492, decode.acc_seg: 61.7579, loss: 1.3492
2022-11-29 21:37:42,216 - mmseg - INFO - Iter [6250/40000]	lr: 5.063e-05, eta: 2:47:46, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1750, decode.acc_seg: 69.1863, loss: 1.1750
2022-11-29 21:37:55,839 - mmseg - INFO - Iter [6300/40000]	lr: 5.055e-05, eta: 2:47:24, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2991, decode.acc_seg: 61.6784, loss: 1.2991
2022-11-29 21:38:09,471 - mmseg - INFO - Iter [6350/40000]	lr: 5.048e-05, eta: 2:47:02, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2692, decode.acc_seg: 60.8630, loss: 1.2692
2022-11-29 21:38:23,117 - mmseg - INFO - Iter [6400/40000]	lr: 5.040e-05, eta: 2:46:41, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2450, decode.acc_seg: 62.9888, loss: 1.2450
2022-11-29 21:38:39,065 - mmseg - INFO - Iter [6450/40000]	lr: 5.033e-05, eta: 2:46:32, time: 0.319, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2277, decode.acc_seg: 63.1385, loss: 1.2277
2022-11-29 21:38:53,993 - mmseg - INFO - Iter [6500/40000]	lr: 5.025e-05, eta: 2:46:17, time: 0.299, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3303, decode.acc_seg: 60.0535, loss: 1.3303
2022-11-29 21:39:07,580 - mmseg - INFO - Iter [6550/40000]	lr: 5.018e-05, eta: 2:45:55, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3616, decode.acc_seg: 60.2311, loss: 1.3616
2022-11-29 21:39:23,388 - mmseg - INFO - Iter [6600/40000]	lr: 5.010e-05, eta: 2:45:45, time: 0.316, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2483, decode.acc_seg: 67.0142, loss: 1.2483
2022-11-29 21:39:37,064 - mmseg - INFO - Iter [6650/40000]	lr: 5.003e-05, eta: 2:45:24, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1678, decode.acc_seg: 61.8026, loss: 1.1678
2022-11-29 21:39:50,661 - mmseg - INFO - Iter [6700/40000]	lr: 4.995e-05, eta: 2:45:03, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3340, decode.acc_seg: 61.1439, loss: 1.3340
2022-11-29 21:40:04,238 - mmseg - INFO - Iter [6750/40000]	lr: 4.988e-05, eta: 2:44:42, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1898, decode.acc_seg: 64.6189, loss: 1.1898
2022-11-29 21:40:20,009 - mmseg - INFO - Iter [6800/40000]	lr: 4.980e-05, eta: 2:44:31, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2727, decode.acc_seg: 62.1154, loss: 1.2727
2022-11-29 21:40:33,765 - mmseg - INFO - Iter [6850/40000]	lr: 4.973e-05, eta: 2:44:11, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3138, decode.acc_seg: 62.4286, loss: 1.3138
2022-11-29 21:40:47,365 - mmseg - INFO - Iter [6900/40000]	lr: 4.965e-05, eta: 2:43:50, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1550, decode.acc_seg: 63.3245, loss: 1.1550
2022-11-29 21:41:00,996 - mmseg - INFO - Iter [6950/40000]	lr: 4.958e-05, eta: 2:43:30, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0597, decode.acc_seg: 67.9446, loss: 1.0597
2022-11-29 21:41:16,725 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:41:16,725 - mmseg - INFO - Iter [7000/40000]	lr: 4.950e-05, eta: 2:43:19, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1130, decode.acc_seg: 64.4894, loss: 1.1130
2022-11-29 21:41:30,402 - mmseg - INFO - Iter [7050/40000]	lr: 4.943e-05, eta: 2:42:59, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0600, decode.acc_seg: 66.3883, loss: 1.0600
2022-11-29 21:41:43,985 - mmseg - INFO - Iter [7100/40000]	lr: 4.935e-05, eta: 2:42:38, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3471, decode.acc_seg: 60.4795, loss: 1.3471
2022-11-29 21:41:59,778 - mmseg - INFO - Iter [7150/40000]	lr: 4.928e-05, eta: 2:42:27, time: 0.316, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2980, decode.acc_seg: 60.0213, loss: 1.2980
2022-11-29 21:42:13,473 - mmseg - INFO - Iter [7200/40000]	lr: 4.920e-05, eta: 2:42:07, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1984, decode.acc_seg: 62.7403, loss: 1.1984
2022-11-29 21:42:27,180 - mmseg - INFO - Iter [7250/40000]	lr: 4.913e-05, eta: 2:41:48, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3331, decode.acc_seg: 59.3679, loss: 1.3331
2022-11-29 21:42:40,878 - mmseg - INFO - Iter [7300/40000]	lr: 4.905e-05, eta: 2:41:28, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1137, decode.acc_seg: 67.5866, loss: 1.1137
2022-11-29 21:42:57,139 - mmseg - INFO - Iter [7350/40000]	lr: 4.898e-05, eta: 2:41:19, time: 0.325, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1268, decode.acc_seg: 66.4094, loss: 1.1268
2022-11-29 21:43:12,333 - mmseg - INFO - Iter [7400/40000]	lr: 4.890e-05, eta: 2:41:06, time: 0.304, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1663, decode.acc_seg: 63.3142, loss: 1.1663
2022-11-29 21:43:26,029 - mmseg - INFO - Iter [7450/40000]	lr: 4.883e-05, eta: 2:40:46, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1448, decode.acc_seg: 66.5720, loss: 1.1448
2022-11-29 21:43:39,668 - mmseg - INFO - Iter [7500/40000]	lr: 4.875e-05, eta: 2:40:26, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3698, decode.acc_seg: 59.1184, loss: 1.3698
2022-11-29 21:43:55,418 - mmseg - INFO - Iter [7550/40000]	lr: 4.868e-05, eta: 2:40:16, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1547, decode.acc_seg: 64.6880, loss: 1.1547
2022-11-29 21:44:09,079 - mmseg - INFO - Iter [7600/40000]	lr: 4.860e-05, eta: 2:39:56, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3885, decode.acc_seg: 56.6739, loss: 1.3885
2022-11-29 21:44:22,759 - mmseg - INFO - Iter [7650/40000]	lr: 4.853e-05, eta: 2:39:36, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1403, decode.acc_seg: 65.2788, loss: 1.1403
2022-11-29 21:44:39,043 - mmseg - INFO - Iter [7700/40000]	lr: 4.845e-05, eta: 2:39:28, time: 0.326, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1143, decode.acc_seg: 65.1794, loss: 1.1143
2022-11-29 21:44:52,862 - mmseg - INFO - Iter [7750/40000]	lr: 4.838e-05, eta: 2:39:09, time: 0.276, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0842, decode.acc_seg: 67.0922, loss: 1.0842
2022-11-29 21:45:06,543 - mmseg - INFO - Iter [7800/40000]	lr: 4.830e-05, eta: 2:38:49, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0721, decode.acc_seg: 64.8040, loss: 1.0721
2022-11-29 21:45:20,184 - mmseg - INFO - Iter [7850/40000]	lr: 4.823e-05, eta: 2:38:30, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2890, decode.acc_seg: 62.5344, loss: 1.2890
2022-11-29 21:45:36,386 - mmseg - INFO - Iter [7900/40000]	lr: 4.815e-05, eta: 2:38:21, time: 0.324, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2612, decode.acc_seg: 61.8769, loss: 1.2612
2022-11-29 21:45:50,912 - mmseg - INFO - Iter [7950/40000]	lr: 4.808e-05, eta: 2:38:05, time: 0.291, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1299, decode.acc_seg: 64.8991, loss: 1.1299
2022-11-29 21:46:04,737 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:46:04,737 - mmseg - INFO - Iter [8000/40000]	lr: 4.800e-05, eta: 2:37:46, time: 0.276, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1448, decode.acc_seg: 63.8917, loss: 1.1448
2022-11-29 21:46:18,350 - mmseg - INFO - Iter [8050/40000]	lr: 4.793e-05, eta: 2:37:27, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1445, decode.acc_seg: 63.3399, loss: 1.1445
2022-11-29 21:46:34,569 - mmseg - INFO - Iter [8100/40000]	lr: 4.785e-05, eta: 2:37:18, time: 0.324, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1846, decode.acc_seg: 60.8685, loss: 1.1846
2022-11-29 21:46:48,444 - mmseg - INFO - Iter [8150/40000]	lr: 4.778e-05, eta: 2:36:59, time: 0.277, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1894, decode.acc_seg: 63.7250, loss: 1.1894
2022-11-29 21:47:02,084 - mmseg - INFO - Iter [8200/40000]	lr: 4.770e-05, eta: 2:36:40, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3774, decode.acc_seg: 60.7840, loss: 1.3774
2022-11-29 21:47:18,066 - mmseg - INFO - Iter [8250/40000]	lr: 4.763e-05, eta: 2:36:30, time: 0.320, data_time: 0.049, memory: 5537, decode.loss_ce: 1.2146, decode.acc_seg: 64.3812, loss: 1.2146
2022-11-29 21:47:31,794 - mmseg - INFO - Iter [8300/40000]	lr: 4.755e-05, eta: 2:36:11, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3162, decode.acc_seg: 59.6412, loss: 1.3162
2022-11-29 21:47:45,463 - mmseg - INFO - Iter [8350/40000]	lr: 4.748e-05, eta: 2:35:52, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2166, decode.acc_seg: 66.1828, loss: 1.2166
2022-11-29 21:47:59,085 - mmseg - INFO - Iter [8400/40000]	lr: 4.740e-05, eta: 2:35:33, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2714, decode.acc_seg: 60.3679, loss: 1.2714
2022-11-29 21:48:15,356 - mmseg - INFO - Iter [8450/40000]	lr: 4.733e-05, eta: 2:35:24, time: 0.325, data_time: 0.048, memory: 5537, decode.loss_ce: 1.4565, decode.acc_seg: 53.2081, loss: 1.4565
2022-11-29 21:48:28,954 - mmseg - INFO - Iter [8500/40000]	lr: 4.725e-05, eta: 2:35:04, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9302, decode.acc_seg: 73.3531, loss: 0.9302
2022-11-29 21:48:43,860 - mmseg - INFO - Iter [8550/40000]	lr: 4.718e-05, eta: 2:34:50, time: 0.298, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1190, decode.acc_seg: 65.0966, loss: 1.1190
2022-11-29 21:49:00,354 - mmseg - INFO - Iter [8600/40000]	lr: 4.710e-05, eta: 2:34:42, time: 0.330, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0825, decode.acc_seg: 63.1861, loss: 1.0825
2022-11-29 21:49:16,232 - mmseg - INFO - Iter [8650/40000]	lr: 4.703e-05, eta: 2:34:31, time: 0.318, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2043, decode.acc_seg: 59.3457, loss: 1.2043
2022-11-29 21:49:29,812 - mmseg - INFO - Iter [8700/40000]	lr: 4.695e-05, eta: 2:34:12, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1205, decode.acc_seg: 64.4202, loss: 1.1205
2022-11-29 21:49:44,596 - mmseg - INFO - Iter [8750/40000]	lr: 4.688e-05, eta: 2:33:57, time: 0.296, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1828, decode.acc_seg: 66.7615, loss: 1.1828
2022-11-29 21:50:00,705 - mmseg - INFO - Iter [8800/40000]	lr: 4.680e-05, eta: 2:33:47, time: 0.322, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1081, decode.acc_seg: 64.6508, loss: 1.1081
2022-11-29 21:50:14,379 - mmseg - INFO - Iter [8850/40000]	lr: 4.673e-05, eta: 2:33:28, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0965, decode.acc_seg: 66.3227, loss: 1.0965
2022-11-29 21:50:30,882 - mmseg - INFO - Iter [8900/40000]	lr: 4.665e-05, eta: 2:33:19, time: 0.330, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2021, decode.acc_seg: 66.8061, loss: 1.2021
2022-11-29 21:50:45,645 - mmseg - INFO - Iter [8950/40000]	lr: 4.658e-05, eta: 2:33:05, time: 0.295, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3088, decode.acc_seg: 58.1925, loss: 1.3088
2022-11-29 21:51:03,065 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:51:03,065 - mmseg - INFO - Iter [9000/40000]	lr: 4.650e-05, eta: 2:32:59, time: 0.348, data_time: 0.047, memory: 5537, decode.loss_ce: 1.1782, decode.acc_seg: 64.0521, loss: 1.1782
2022-11-29 21:51:16,680 - mmseg - INFO - Iter [9050/40000]	lr: 4.643e-05, eta: 2:32:40, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1576, decode.acc_seg: 62.2833, loss: 1.1576
2022-11-29 21:51:31,105 - mmseg - INFO - Iter [9100/40000]	lr: 4.635e-05, eta: 2:32:24, time: 0.288, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9835, decode.acc_seg: 68.3914, loss: 0.9835
2022-11-29 21:51:46,074 - mmseg - INFO - Iter [9150/40000]	lr: 4.628e-05, eta: 2:32:10, time: 0.299, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1668, decode.acc_seg: 60.9826, loss: 1.1668
2022-11-29 21:52:01,887 - mmseg - INFO - Iter [9200/40000]	lr: 4.620e-05, eta: 2:31:58, time: 0.316, data_time: 0.047, memory: 5537, decode.loss_ce: 1.2299, decode.acc_seg: 61.7195, loss: 1.2299
2022-11-29 21:52:15,632 - mmseg - INFO - Iter [9250/40000]	lr: 4.613e-05, eta: 2:31:40, time: 0.275, data_time: 0.008, memory: 5537, decode.loss_ce: 1.0057, decode.acc_seg: 65.4779, loss: 1.0057
2022-11-29 21:52:29,292 - mmseg - INFO - Iter [9300/40000]	lr: 4.605e-05, eta: 2:31:21, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1909, decode.acc_seg: 61.8861, loss: 1.1909
2022-11-29 21:52:45,350 - mmseg - INFO - Iter [9350/40000]	lr: 4.598e-05, eta: 2:31:11, time: 0.321, data_time: 0.049, memory: 5537, decode.loss_ce: 1.1251, decode.acc_seg: 62.5431, loss: 1.1251
2022-11-29 21:52:59,598 - mmseg - INFO - Iter [9400/40000]	lr: 4.590e-05, eta: 2:30:54, time: 0.285, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0355, decode.acc_seg: 68.3304, loss: 1.0355
2022-11-29 21:53:14,020 - mmseg - INFO - Iter [9450/40000]	lr: 4.583e-05, eta: 2:30:38, time: 0.288, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0747, decode.acc_seg: 64.1378, loss: 1.0747
2022-11-29 21:53:27,938 - mmseg - INFO - Iter [9500/40000]	lr: 4.575e-05, eta: 2:30:21, time: 0.278, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0799, decode.acc_seg: 62.6012, loss: 1.0799
2022-11-29 21:53:44,273 - mmseg - INFO - Iter [9550/40000]	lr: 4.568e-05, eta: 2:30:11, time: 0.327, data_time: 0.049, memory: 5537, decode.loss_ce: 1.0618, decode.acc_seg: 66.2067, loss: 1.0618
2022-11-29 21:53:58,078 - mmseg - INFO - Iter [9600/40000]	lr: 4.560e-05, eta: 2:29:53, time: 0.276, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1811, decode.acc_seg: 62.1610, loss: 1.1811
2022-11-29 21:54:11,690 - mmseg - INFO - Iter [9650/40000]	lr: 4.553e-05, eta: 2:29:34, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3267, decode.acc_seg: 59.5531, loss: 1.3267
2022-11-29 21:54:27,496 - mmseg - INFO - Iter [9700/40000]	lr: 4.545e-05, eta: 2:29:23, time: 0.316, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1873, decode.acc_seg: 62.9817, loss: 1.1873
2022-11-29 21:54:41,886 - mmseg - INFO - Iter [9750/40000]	lr: 4.538e-05, eta: 2:29:07, time: 0.288, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0836, decode.acc_seg: 63.5849, loss: 1.0836
2022-11-29 21:54:55,990 - mmseg - INFO - Iter [9800/40000]	lr: 4.530e-05, eta: 2:28:50, time: 0.282, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2551, decode.acc_seg: 58.3964, loss: 1.2551
2022-11-29 21:55:09,718 - mmseg - INFO - Iter [9850/40000]	lr: 4.523e-05, eta: 2:28:32, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0506, decode.acc_seg: 63.3477, loss: 1.0506
2022-11-29 21:55:25,477 - mmseg - INFO - Iter [9900/40000]	lr: 4.515e-05, eta: 2:28:20, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1331, decode.acc_seg: 67.6975, loss: 1.1331
2022-11-29 21:55:39,077 - mmseg - INFO - Iter [9950/40000]	lr: 4.508e-05, eta: 2:28:02, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0332, decode.acc_seg: 65.2878, loss: 1.0332
2022-11-29 21:55:52,699 - mmseg - INFO - Saving checkpoint at 10000 iterations
2022-11-29 21:55:55,736 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:55:55,736 - mmseg - INFO - Iter [10000/40000]	lr: 4.500e-05, eta: 2:27:52, time: 0.333, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2423, decode.acc_seg: 58.7502, loss: 1.2423
2022-11-29 21:56:38,657 - mmseg - INFO - per class results:
2022-11-29 21:56:38,659 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 73.24 | 89.25 |
|  aeroplane  |  0.29 |  0.3  |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  0.45 |  0.8  |
|     boat    |  0.0  |  0.0  |
|    bottle   |  0.0  |  0.0  |
|     bus     |  1.39 |  1.65 |
|     car     |  0.69 |  0.73 |
|     cat     |  6.46 | 23.28 |
|    chair    |  0.0  |  0.0  |
|     cow     |  2.2  |  5.11 |
| diningtable |  0.0  |  0.0  |
|     dog     |  9.36 | 26.07 |
|    horse    |  2.92 |  3.37 |
|  motorbike  |  6.0  | 24.34 |
|    person   |  5.68 |  6.49 |
| pottedplant |  0.0  |  0.0  |
|    sheep    |  8.81 | 14.68 |
|     sofa    |  0.0  |  0.0  |
|    train    |  6.33 |  9.08 |
|  tvmonitor  |  0.0  |  0.0  |
+-------------+-------+-------+
2022-11-29 21:56:38,659 - mmseg - INFO - Summary:
2022-11-29 21:56:38,659 - mmseg - INFO - 
+------+------+------+
| aAcc | mIoU | mAcc |
+------+------+------+
| 67.5 | 5.9  | 9.77 |
+------+------+------+
2022-11-29 21:56:38,661 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 21:56:38,661 - mmseg - INFO - Iter(val) [724]	aAcc: 0.6750, mIoU: 0.0590, mAcc: 0.0977, IoU.background: 0.7324, IoU.aeroplane: 0.0029, IoU.bicycle: 0.0000, IoU.bird: 0.0045, IoU.boat: 0.0000, IoU.bottle: 0.0000, IoU.bus: 0.0139, IoU.car: 0.0069, IoU.cat: 0.0646, IoU.chair: 0.0000, IoU.cow: 0.0220, IoU.diningtable: 0.0000, IoU.dog: 0.0936, IoU.horse: 0.0292, IoU.motorbike: 0.0600, IoU.person: 0.0568, IoU.pottedplant: 0.0000, IoU.sheep: 0.0881, IoU.sofa: 0.0000, IoU.train: 0.0633, IoU.tvmonitor: 0.0000, Acc.background: 0.8925, Acc.aeroplane: 0.0030, Acc.bicycle: 0.0000, Acc.bird: 0.0080, Acc.boat: 0.0000, Acc.bottle: 0.0000, Acc.bus: 0.0165, Acc.car: 0.0073, Acc.cat: 0.2328, Acc.chair: 0.0000, Acc.cow: 0.0511, Acc.diningtable: 0.0000, Acc.dog: 0.2607, Acc.horse: 0.0337, Acc.motorbike: 0.2434, Acc.person: 0.0649, Acc.pottedplant: 0.0000, Acc.sheep: 0.1468, Acc.sofa: 0.0000, Acc.train: 0.0908, Acc.tvmonitor: 0.0000
2022-11-29 21:56:52,841 - mmseg - INFO - Iter [10050/40000]	lr: 4.493e-05, eta: 2:29:44, time: 1.142, data_time: 0.866, memory: 5537, decode.loss_ce: 1.0695, decode.acc_seg: 66.5202, loss: 1.0695
2022-11-29 21:57:08,789 - mmseg - INFO - Iter [10100/40000]	lr: 4.485e-05, eta: 2:29:32, time: 0.319, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1578, decode.acc_seg: 63.3113, loss: 1.1578
2022-11-29 21:57:22,551 - mmseg - INFO - Iter [10150/40000]	lr: 4.478e-05, eta: 2:29:13, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1195, decode.acc_seg: 63.7507, loss: 1.1195
2022-11-29 21:57:36,268 - mmseg - INFO - Iter [10200/40000]	lr: 4.470e-05, eta: 2:28:54, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3316, decode.acc_seg: 59.3688, loss: 1.3316
2022-11-29 21:57:52,060 - mmseg - INFO - Iter [10250/40000]	lr: 4.463e-05, eta: 2:28:41, time: 0.316, data_time: 0.047, memory: 5537, decode.loss_ce: 1.0299, decode.acc_seg: 66.3664, loss: 1.0299
2022-11-29 21:58:06,537 - mmseg - INFO - Iter [10300/40000]	lr: 4.455e-05, eta: 2:28:25, time: 0.289, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0161, decode.acc_seg: 65.3843, loss: 1.0161
2022-11-29 21:58:23,055 - mmseg - INFO - Iter [10350/40000]	lr: 4.448e-05, eta: 2:28:14, time: 0.330, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0663, decode.acc_seg: 61.6521, loss: 1.0663
2022-11-29 21:58:37,198 - mmseg - INFO - Iter [10400/40000]	lr: 4.440e-05, eta: 2:27:57, time: 0.283, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1007, decode.acc_seg: 65.2382, loss: 1.1007
2022-11-29 21:58:53,258 - mmseg - INFO - Iter [10450/40000]	lr: 4.433e-05, eta: 2:27:45, time: 0.321, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2797, decode.acc_seg: 59.3863, loss: 1.2797
2022-11-29 21:59:06,996 - mmseg - INFO - Iter [10500/40000]	lr: 4.425e-05, eta: 2:27:26, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0187, decode.acc_seg: 67.1525, loss: 1.0187
2022-11-29 21:59:20,731 - mmseg - INFO - Iter [10550/40000]	lr: 4.418e-05, eta: 2:27:08, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0254, decode.acc_seg: 65.1213, loss: 1.0254
2022-11-29 21:59:34,377 - mmseg - INFO - Iter [10600/40000]	lr: 4.410e-05, eta: 2:26:49, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2051, decode.acc_seg: 59.9708, loss: 1.2051
2022-11-29 21:59:50,580 - mmseg - INFO - Iter [10650/40000]	lr: 4.403e-05, eta: 2:26:37, time: 0.324, data_time: 0.048, memory: 5537, decode.loss_ce: 0.9960, decode.acc_seg: 63.1684, loss: 0.9960
2022-11-29 22:00:04,753 - mmseg - INFO - Iter [10700/40000]	lr: 4.395e-05, eta: 2:26:20, time: 0.283, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1238, decode.acc_seg: 62.0571, loss: 1.1238
2022-11-29 22:00:18,480 - mmseg - INFO - Iter [10750/40000]	lr: 4.388e-05, eta: 2:26:02, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0511, decode.acc_seg: 65.1427, loss: 1.0511
2022-11-29 22:00:34,311 - mmseg - INFO - Iter [10800/40000]	lr: 4.380e-05, eta: 2:25:49, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 0.9816, decode.acc_seg: 68.6515, loss: 0.9816
2022-11-29 22:00:48,387 - mmseg - INFO - Iter [10850/40000]	lr: 4.373e-05, eta: 2:25:32, time: 0.282, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0462, decode.acc_seg: 66.0128, loss: 1.0462
2022-11-29 22:01:02,034 - mmseg - INFO - Iter [10900/40000]	lr: 4.365e-05, eta: 2:25:13, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9618, decode.acc_seg: 66.7372, loss: 0.9618
2022-11-29 22:01:17,787 - mmseg - INFO - Iter [10950/40000]	lr: 4.358e-05, eta: 2:25:00, time: 0.315, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0296, decode.acc_seg: 62.7247, loss: 1.0296
2022-11-29 22:01:33,611 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:01:33,611 - mmseg - INFO - Iter [11000/40000]	lr: 4.350e-05, eta: 2:24:48, time: 0.316, data_time: 0.048, memory: 5537, decode.loss_ce: 1.2637, decode.acc_seg: 60.5302, loss: 1.2637
2022-11-29 22:01:47,278 - mmseg - INFO - Iter [11050/40000]	lr: 4.343e-05, eta: 2:24:29, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9651, decode.acc_seg: 61.5974, loss: 0.9651
2022-11-29 22:02:00,910 - mmseg - INFO - Iter [11100/40000]	lr: 4.335e-05, eta: 2:24:11, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1002, decode.acc_seg: 67.9069, loss: 1.1002
2022-11-29 22:02:15,866 - mmseg - INFO - Iter [11150/40000]	lr: 4.328e-05, eta: 2:23:56, time: 0.299, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0907, decode.acc_seg: 63.9822, loss: 1.0907
2022-11-29 22:02:33,939 - mmseg - INFO - Iter [11200/40000]	lr: 4.320e-05, eta: 2:23:49, time: 0.361, data_time: 0.048, memory: 5537, decode.loss_ce: 0.9712, decode.acc_seg: 65.4231, loss: 0.9712
2022-11-29 22:02:47,647 - mmseg - INFO - Iter [11250/40000]	lr: 4.313e-05, eta: 2:23:30, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0185, decode.acc_seg: 67.1877, loss: 1.0185
2022-11-29 22:03:01,372 - mmseg - INFO - Iter [11300/40000]	lr: 4.305e-05, eta: 2:23:12, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0158, decode.acc_seg: 63.9178, loss: 1.0158
2022-11-29 22:03:17,147 - mmseg - INFO - Iter [11350/40000]	lr: 4.298e-05, eta: 2:22:59, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 1.0873, decode.acc_seg: 65.5378, loss: 1.0873
2022-11-29 22:03:32,948 - mmseg - INFO - Iter [11400/40000]	lr: 4.290e-05, eta: 2:22:46, time: 0.316, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9148, decode.acc_seg: 70.6478, loss: 0.9148
2022-11-29 22:03:46,713 - mmseg - INFO - Iter [11450/40000]	lr: 4.283e-05, eta: 2:22:28, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9922, decode.acc_seg: 64.9964, loss: 0.9922
2022-11-29 22:04:00,429 - mmseg - INFO - Iter [11500/40000]	lr: 4.275e-05, eta: 2:22:10, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2647, decode.acc_seg: 60.5768, loss: 1.2647
2022-11-29 22:04:16,480 - mmseg - INFO - Iter [11550/40000]	lr: 4.268e-05, eta: 2:21:58, time: 0.321, data_time: 0.048, memory: 5537, decode.loss_ce: 0.8793, decode.acc_seg: 68.9412, loss: 0.8793
2022-11-29 22:04:30,293 - mmseg - INFO - Iter [11600/40000]	lr: 4.260e-05, eta: 2:21:40, time: 0.276, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9771, decode.acc_seg: 66.7186, loss: 0.9771
2022-11-29 22:04:44,090 - mmseg - INFO - Iter [11650/40000]	lr: 4.253e-05, eta: 2:21:22, time: 0.276, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3236, decode.acc_seg: 56.0234, loss: 1.3236
2022-11-29 22:04:57,880 - mmseg - INFO - Iter [11700/40000]	lr: 4.245e-05, eta: 2:21:05, time: 0.276, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9429, decode.acc_seg: 66.6177, loss: 0.9429
2022-11-29 22:05:13,724 - mmseg - INFO - Iter [11750/40000]	lr: 4.238e-05, eta: 2:20:52, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 0.7820, decode.acc_seg: 71.7685, loss: 0.7820
2022-11-29 22:05:27,382 - mmseg - INFO - Iter [11800/40000]	lr: 4.230e-05, eta: 2:20:34, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1485, decode.acc_seg: 58.0687, loss: 1.1485
2022-11-29 22:05:41,104 - mmseg - INFO - Iter [11850/40000]	lr: 4.223e-05, eta: 2:20:16, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0428, decode.acc_seg: 64.1629, loss: 1.0428
2022-11-29 22:05:57,043 - mmseg - INFO - Iter [11900/40000]	lr: 4.215e-05, eta: 2:20:03, time: 0.319, data_time: 0.048, memory: 5537, decode.loss_ce: 1.0527, decode.acc_seg: 64.9954, loss: 1.0527
2022-11-29 22:06:11,136 - mmseg - INFO - Iter [11950/40000]	lr: 4.208e-05, eta: 2:19:46, time: 0.282, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9672, decode.acc_seg: 67.0674, loss: 0.9672
2022-11-29 22:06:24,742 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:06:24,742 - mmseg - INFO - Iter [12000/40000]	lr: 4.200e-05, eta: 2:19:28, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0322, decode.acc_seg: 65.5134, loss: 1.0322
2022-11-29 22:06:38,836 - mmseg - INFO - Iter [12050/40000]	lr: 4.193e-05, eta: 2:19:11, time: 0.282, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2181, decode.acc_seg: 56.2871, loss: 1.2181
2022-11-29 22:06:56,025 - mmseg - INFO - Iter [12100/40000]	lr: 4.185e-05, eta: 2:19:02, time: 0.344, data_time: 0.049, memory: 5537, decode.loss_ce: 1.0078, decode.acc_seg: 65.8402, loss: 1.0078
2022-11-29 22:07:10,442 - mmseg - INFO - Iter [12150/40000]	lr: 4.178e-05, eta: 2:18:45, time: 0.288, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0707, decode.acc_seg: 64.5548, loss: 1.0707
2022-11-29 22:07:26,931 - mmseg - INFO - Iter [12200/40000]	lr: 4.170e-05, eta: 2:18:34, time: 0.330, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9122, decode.acc_seg: 67.9375, loss: 0.9122
2022-11-29 22:07:42,819 - mmseg - INFO - Iter [12250/40000]	lr: 4.163e-05, eta: 2:18:21, time: 0.318, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0220, decode.acc_seg: 67.4191, loss: 1.0220
2022-11-29 22:07:59,631 - mmseg - INFO - Iter [12300/40000]	lr: 4.155e-05, eta: 2:18:10, time: 0.336, data_time: 0.048, memory: 5537, decode.loss_ce: 0.8752, decode.acc_seg: 68.6097, loss: 0.8752
2022-11-29 22:08:13,373 - mmseg - INFO - Iter [12350/40000]	lr: 4.148e-05, eta: 2:17:53, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8803, decode.acc_seg: 70.3370, loss: 0.8803
2022-11-29 22:08:27,050 - mmseg - INFO - Iter [12400/40000]	lr: 4.140e-05, eta: 2:17:35, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1346, decode.acc_seg: 62.1121, loss: 1.1346
2022-11-29 22:08:43,096 - mmseg - INFO - Iter [12450/40000]	lr: 4.133e-05, eta: 2:17:22, time: 0.321, data_time: 0.048, memory: 5537, decode.loss_ce: 1.0112, decode.acc_seg: 64.0255, loss: 1.0112
2022-11-29 22:08:57,081 - mmseg - INFO - Iter [12500/40000]	lr: 4.125e-05, eta: 2:17:05, time: 0.280, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8770, decode.acc_seg: 68.8176, loss: 0.8770
2022-11-29 22:09:10,712 - mmseg - INFO - Iter [12550/40000]	lr: 4.118e-05, eta: 2:16:47, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8676, decode.acc_seg: 70.1949, loss: 0.8676
2022-11-29 22:09:24,622 - mmseg - INFO - Iter [12600/40000]	lr: 4.110e-05, eta: 2:16:30, time: 0.278, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9365, decode.acc_seg: 68.9479, loss: 0.9365
2022-11-29 22:09:40,375 - mmseg - INFO - Iter [12650/40000]	lr: 4.103e-05, eta: 2:16:17, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1190, decode.acc_seg: 58.0909, loss: 1.1190
2022-11-29 22:09:54,074 - mmseg - INFO - Iter [12700/40000]	lr: 4.095e-05, eta: 2:15:59, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0471, decode.acc_seg: 64.9897, loss: 1.0471
2022-11-29 22:10:07,793 - mmseg - INFO - Iter [12750/40000]	lr: 4.088e-05, eta: 2:15:42, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8134, decode.acc_seg: 69.6262, loss: 0.8134
2022-11-29 22:10:21,454 - mmseg - INFO - Iter [12800/40000]	lr: 4.080e-05, eta: 2:15:24, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9642, decode.acc_seg: 70.6103, loss: 0.9642
2022-11-29 22:10:37,587 - mmseg - INFO - Iter [12850/40000]	lr: 4.073e-05, eta: 2:15:12, time: 0.323, data_time: 0.048, memory: 5537, decode.loss_ce: 0.9424, decode.acc_seg: 65.2323, loss: 0.9424
2022-11-29 22:10:51,344 - mmseg - INFO - Iter [12900/40000]	lr: 4.065e-05, eta: 2:14:54, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0816, decode.acc_seg: 63.7264, loss: 1.0816
2022-11-29 22:11:05,038 - mmseg - INFO - Iter [12950/40000]	lr: 4.058e-05, eta: 2:14:37, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7981, decode.acc_seg: 73.1188, loss: 0.7981
2022-11-29 22:11:20,904 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:11:20,904 - mmseg - INFO - Iter [13000/40000]	lr: 4.050e-05, eta: 2:14:24, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 1.0446, decode.acc_seg: 65.6823, loss: 1.0446
2022-11-29 22:11:34,599 - mmseg - INFO - Iter [13050/40000]	lr: 4.043e-05, eta: 2:14:06, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9961, decode.acc_seg: 65.5422, loss: 0.9961
2022-11-29 22:11:48,289 - mmseg - INFO - Iter [13100/40000]	lr: 4.035e-05, eta: 2:13:49, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0031, decode.acc_seg: 65.1408, loss: 1.0031
2022-11-29 22:12:01,934 - mmseg - INFO - Iter [13150/40000]	lr: 4.028e-05, eta: 2:13:31, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8908, decode.acc_seg: 70.1472, loss: 0.8908
2022-11-29 22:12:18,135 - mmseg - INFO - Iter [13200/40000]	lr: 4.020e-05, eta: 2:13:19, time: 0.324, data_time: 0.049, memory: 5537, decode.loss_ce: 0.9142, decode.acc_seg: 68.6485, loss: 0.9142
2022-11-29 22:12:32,882 - mmseg - INFO - Iter [13250/40000]	lr: 4.013e-05, eta: 2:13:04, time: 0.295, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2074, decode.acc_seg: 61.7323, loss: 1.2074
2022-11-29 22:12:46,969 - mmseg - INFO - Iter [13300/40000]	lr: 4.005e-05, eta: 2:12:47, time: 0.282, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0614, decode.acc_seg: 62.5799, loss: 1.0614
2022-11-29 22:13:00,659 - mmseg - INFO - Iter [13350/40000]	lr: 3.998e-05, eta: 2:12:30, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7913, decode.acc_seg: 71.9638, loss: 0.7913
2022-11-29 22:13:16,478 - mmseg - INFO - Iter [13400/40000]	lr: 3.990e-05, eta: 2:12:16, time: 0.316, data_time: 0.049, memory: 5537, decode.loss_ce: 0.9115, decode.acc_seg: 68.2526, loss: 0.9115
2022-11-29 22:13:30,374 - mmseg - INFO - Iter [13450/40000]	lr: 3.983e-05, eta: 2:12:00, time: 0.278, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8894, decode.acc_seg: 69.3978, loss: 0.8894
2022-11-29 22:13:45,062 - mmseg - INFO - Iter [13500/40000]	lr: 3.975e-05, eta: 2:11:44, time: 0.294, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0231, decode.acc_seg: 62.9588, loss: 1.0231
2022-11-29 22:14:01,445 - mmseg - INFO - Iter [13550/40000]	lr: 3.968e-05, eta: 2:11:32, time: 0.328, data_time: 0.048, memory: 5537, decode.loss_ce: 1.0374, decode.acc_seg: 66.1510, loss: 1.0374
2022-11-29 22:14:15,123 - mmseg - INFO - Iter [13600/40000]	lr: 3.960e-05, eta: 2:11:15, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0157, decode.acc_seg: 59.3145, loss: 1.0157
2022-11-29 22:14:28,704 - mmseg - INFO - Iter [13650/40000]	lr: 3.953e-05, eta: 2:10:57, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8399, decode.acc_seg: 68.1435, loss: 0.8399
2022-11-29 22:14:42,823 - mmseg - INFO - Iter [13700/40000]	lr: 3.945e-05, eta: 2:10:41, time: 0.282, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1045, decode.acc_seg: 63.4920, loss: 1.1045
2022-11-29 22:15:00,086 - mmseg - INFO - Iter [13750/40000]	lr: 3.938e-05, eta: 2:10:30, time: 0.345, data_time: 0.049, memory: 5537, decode.loss_ce: 0.8173, decode.acc_seg: 70.7126, loss: 0.8173
2022-11-29 22:15:13,675 - mmseg - INFO - Iter [13800/40000]	lr: 3.930e-05, eta: 2:10:13, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8750, decode.acc_seg: 67.9402, loss: 0.8750
2022-11-29 22:15:27,351 - mmseg - INFO - Iter [13850/40000]	lr: 3.923e-05, eta: 2:09:56, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 1.1029, decode.acc_seg: 61.6846, loss: 1.1029
2022-11-29 22:15:41,085 - mmseg - INFO - Iter [13900/40000]	lr: 3.915e-05, eta: 2:09:39, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9130, decode.acc_seg: 68.6904, loss: 0.9130
2022-11-29 22:15:56,861 - mmseg - INFO - Iter [13950/40000]	lr: 3.908e-05, eta: 2:09:25, time: 0.316, data_time: 0.047, memory: 5537, decode.loss_ce: 0.9348, decode.acc_seg: 65.3760, loss: 0.9348
2022-11-29 22:16:10,583 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:16:10,584 - mmseg - INFO - Iter [14000/40000]	lr: 3.900e-05, eta: 2:09:08, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7951, decode.acc_seg: 70.2675, loss: 0.7951
2022-11-29 22:16:24,295 - mmseg - INFO - Iter [14050/40000]	lr: 3.893e-05, eta: 2:08:51, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9525, decode.acc_seg: 65.1908, loss: 0.9525
2022-11-29 22:16:40,328 - mmseg - INFO - Iter [14100/40000]	lr: 3.885e-05, eta: 2:08:38, time: 0.321, data_time: 0.048, memory: 5537, decode.loss_ce: 0.8188, decode.acc_seg: 73.3887, loss: 0.8188
2022-11-29 22:16:55,331 - mmseg - INFO - Iter [14150/40000]	lr: 3.878e-05, eta: 2:08:24, time: 0.300, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8234, decode.acc_seg: 73.4044, loss: 0.8234
2022-11-29 22:17:09,364 - mmseg - INFO - Iter [14200/40000]	lr: 3.870e-05, eta: 2:08:07, time: 0.281, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7639, decode.acc_seg: 73.9772, loss: 0.7639
2022-11-29 22:17:24,265 - mmseg - INFO - Iter [14250/40000]	lr: 3.863e-05, eta: 2:07:52, time: 0.298, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0798, decode.acc_seg: 63.6381, loss: 1.0798
2022-11-29 22:17:41,013 - mmseg - INFO - Iter [14300/40000]	lr: 3.855e-05, eta: 2:07:41, time: 0.335, data_time: 0.048, memory: 5537, decode.loss_ce: 0.9367, decode.acc_seg: 66.6339, loss: 0.9367
2022-11-29 22:17:54,726 - mmseg - INFO - Iter [14350/40000]	lr: 3.848e-05, eta: 2:07:24, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8550, decode.acc_seg: 68.9600, loss: 0.8550
2022-11-29 22:18:08,422 - mmseg - INFO - Iter [14400/40000]	lr: 3.840e-05, eta: 2:07:07, time: 0.274, data_time: 0.008, memory: 5537, decode.loss_ce: 0.8418, decode.acc_seg: 69.8616, loss: 0.8418
2022-11-29 22:18:22,173 - mmseg - INFO - Iter [14450/40000]	lr: 3.833e-05, eta: 2:06:50, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9681, decode.acc_seg: 66.4417, loss: 0.9681
2022-11-29 22:18:38,428 - mmseg - INFO - Iter [14500/40000]	lr: 3.825e-05, eta: 2:06:37, time: 0.325, data_time: 0.048, memory: 5537, decode.loss_ce: 0.8429, decode.acc_seg: 68.6857, loss: 0.8429
2022-11-29 22:18:52,160 - mmseg - INFO - Iter [14550/40000]	lr: 3.818e-05, eta: 2:06:20, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7951, decode.acc_seg: 71.7455, loss: 0.7951
2022-11-29 22:19:05,858 - mmseg - INFO - Iter [14600/40000]	lr: 3.810e-05, eta: 2:06:03, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8815, decode.acc_seg: 69.6575, loss: 0.8815
2022-11-29 22:19:21,644 - mmseg - INFO - Iter [14650/40000]	lr: 3.803e-05, eta: 2:05:50, time: 0.316, data_time: 0.048, memory: 5537, decode.loss_ce: 0.8000, decode.acc_seg: 68.0735, loss: 0.8000
2022-11-29 22:19:35,332 - mmseg - INFO - Iter [14700/40000]	lr: 3.795e-05, eta: 2:05:33, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8929, decode.acc_seg: 71.4111, loss: 0.8929
2022-11-29 22:19:48,984 - mmseg - INFO - Iter [14750/40000]	lr: 3.788e-05, eta: 2:05:16, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7828, decode.acc_seg: 70.3940, loss: 0.7828
2022-11-29 22:20:02,657 - mmseg - INFO - Iter [14800/40000]	lr: 3.780e-05, eta: 2:04:59, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8378, decode.acc_seg: 67.3425, loss: 0.8378
2022-11-29 22:20:18,466 - mmseg - INFO - Iter [14850/40000]	lr: 3.773e-05, eta: 2:04:46, time: 0.316, data_time: 0.048, memory: 5537, decode.loss_ce: 0.9173, decode.acc_seg: 67.0980, loss: 0.9173
2022-11-29 22:20:32,210 - mmseg - INFO - Iter [14900/40000]	lr: 3.765e-05, eta: 2:04:29, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9692, decode.acc_seg: 68.5304, loss: 0.9692
2022-11-29 22:20:45,859 - mmseg - INFO - Iter [14950/40000]	lr: 3.758e-05, eta: 2:04:12, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7062, decode.acc_seg: 74.7448, loss: 0.7062
2022-11-29 22:20:59,524 - mmseg - INFO - Saving checkpoint at 15000 iterations
2022-11-29 22:21:02,364 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:21:02,365 - mmseg - INFO - Iter [15000/40000]	lr: 3.750e-05, eta: 2:04:00, time: 0.330, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9280, decode.acc_seg: 69.3326, loss: 0.9280
2022-11-29 22:21:44,915 - mmseg - INFO - per class results:
2022-11-29 22:21:44,916 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 69.82 | 80.83 |
|  aeroplane  |  1.39 |  1.53 |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  0.36 |  1.28 |
|     boat    |  0.78 |  1.77 |
|    bottle   |  0.0  |  0.0  |
|     bus     |  2.3  |  2.54 |
|     car     |  0.05 |  0.05 |
|     cat     |  4.06 |  7.17 |
|    chair    |  0.0  |  0.0  |
|     cow     |  2.17 | 13.13 |
| diningtable |  0.0  |  0.0  |
|     dog     |  7.73 | 53.22 |
|    horse    |  2.3  |  2.78 |
|  motorbike  |  6.33 | 21.97 |
|    person   |  7.2  |  8.01 |
| pottedplant |  0.04 |  0.04 |
|    sheep    |  9.2  | 22.63 |
|     sofa    |  1.75 |  1.83 |
|    train    |  0.39 |  0.41 |
|  tvmonitor  |  0.0  |  0.0  |
+-------------+-------+-------+
2022-11-29 22:21:44,916 - mmseg - INFO - Summary:
2022-11-29 22:21:44,916 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 61.73 | 5.52 | 10.44 |
+-------+------+-------+
2022-11-29 22:21:44,918 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:21:44,918 - mmseg - INFO - Iter(val) [724]	aAcc: 0.6173, mIoU: 0.0552, mAcc: 0.1044, IoU.background: 0.6982, IoU.aeroplane: 0.0139, IoU.bicycle: 0.0000, IoU.bird: 0.0036, IoU.boat: 0.0078, IoU.bottle: 0.0000, IoU.bus: 0.0230, IoU.car: 0.0005, IoU.cat: 0.0406, IoU.chair: 0.0000, IoU.cow: 0.0217, IoU.diningtable: 0.0000, IoU.dog: 0.0773, IoU.horse: 0.0230, IoU.motorbike: 0.0633, IoU.person: 0.0720, IoU.pottedplant: 0.0004, IoU.sheep: 0.0920, IoU.sofa: 0.0175, IoU.train: 0.0039, IoU.tvmonitor: 0.0000, Acc.background: 0.8083, Acc.aeroplane: 0.0153, Acc.bicycle: 0.0000, Acc.bird: 0.0128, Acc.boat: 0.0177, Acc.bottle: 0.0000, Acc.bus: 0.0254, Acc.car: 0.0005, Acc.cat: 0.0717, Acc.chair: 0.0000, Acc.cow: 0.1313, Acc.diningtable: 0.0000, Acc.dog: 0.5322, Acc.horse: 0.0278, Acc.motorbike: 0.2197, Acc.person: 0.0801, Acc.pottedplant: 0.0004, Acc.sheep: 0.2263, Acc.sofa: 0.0183, Acc.train: 0.0041, Acc.tvmonitor: 0.0000
2022-11-29 22:22:00,994 - mmseg - INFO - Iter [15050/40000]	lr: 3.743e-05, eta: 2:04:57, time: 1.173, data_time: 0.900, memory: 5537, decode.loss_ce: 0.7664, decode.acc_seg: 70.0397, loss: 0.7664
2022-11-29 22:22:15,606 - mmseg - INFO - Iter [15100/40000]	lr: 3.735e-05, eta: 2:04:42, time: 0.292, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8653, decode.acc_seg: 69.1435, loss: 0.8653
2022-11-29 22:22:29,655 - mmseg - INFO - Iter [15150/40000]	lr: 3.728e-05, eta: 2:04:25, time: 0.281, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8772, decode.acc_seg: 68.4407, loss: 0.8772
2022-11-29 22:22:45,579 - mmseg - INFO - Iter [15200/40000]	lr: 3.720e-05, eta: 2:04:12, time: 0.318, data_time: 0.048, memory: 5537, decode.loss_ce: 0.7204, decode.acc_seg: 72.6903, loss: 0.7204
2022-11-29 22:23:00,075 - mmseg - INFO - Iter [15250/40000]	lr: 3.713e-05, eta: 2:03:56, time: 0.290, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8137, decode.acc_seg: 70.1236, loss: 0.8137
2022-11-29 22:23:13,740 - mmseg - INFO - Iter [15300/40000]	lr: 3.705e-05, eta: 2:03:38, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8176, decode.acc_seg: 68.7923, loss: 0.8176
2022-11-29 22:23:27,371 - mmseg - INFO - Iter [15350/40000]	lr: 3.698e-05, eta: 2:03:21, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9448, decode.acc_seg: 66.7329, loss: 0.9448
2022-11-29 22:23:43,190 - mmseg - INFO - Iter [15400/40000]	lr: 3.690e-05, eta: 2:03:07, time: 0.316, data_time: 0.049, memory: 5537, decode.loss_ce: 0.7616, decode.acc_seg: 71.3833, loss: 0.7616
2022-11-29 22:23:56,814 - mmseg - INFO - Iter [15450/40000]	lr: 3.683e-05, eta: 2:02:50, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8541, decode.acc_seg: 69.2839, loss: 0.8541
2022-11-29 22:24:10,476 - mmseg - INFO - Iter [15500/40000]	lr: 3.675e-05, eta: 2:02:33, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9402, decode.acc_seg: 63.6981, loss: 0.9402
2022-11-29 22:24:24,159 - mmseg - INFO - Iter [15550/40000]	lr: 3.668e-05, eta: 2:02:16, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9423, decode.acc_seg: 68.6467, loss: 0.9423
2022-11-29 22:24:41,038 - mmseg - INFO - Iter [15600/40000]	lr: 3.660e-05, eta: 2:02:04, time: 0.338, data_time: 0.048, memory: 5537, decode.loss_ce: 0.7548, decode.acc_seg: 74.7224, loss: 0.7548
2022-11-29 22:24:54,704 - mmseg - INFO - Iter [15650/40000]	lr: 3.653e-05, eta: 2:01:47, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9506, decode.acc_seg: 67.9625, loss: 0.9506
2022-11-29 22:25:08,412 - mmseg - INFO - Iter [15700/40000]	lr: 3.645e-05, eta: 2:01:30, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8498, decode.acc_seg: 69.2884, loss: 0.8498
2022-11-29 22:25:24,328 - mmseg - INFO - Iter [15750/40000]	lr: 3.638e-05, eta: 2:01:16, time: 0.318, data_time: 0.048, memory: 5537, decode.loss_ce: 1.1172, decode.acc_seg: 63.1056, loss: 1.1172
2022-11-29 22:25:37,951 - mmseg - INFO - Iter [15800/40000]	lr: 3.630e-05, eta: 2:00:59, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8746, decode.acc_seg: 68.5333, loss: 0.8746
2022-11-29 22:25:51,607 - mmseg - INFO - Iter [15850/40000]	lr: 3.623e-05, eta: 2:00:42, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7436, decode.acc_seg: 74.4360, loss: 0.7436
2022-11-29 22:26:05,304 - mmseg - INFO - Iter [15900/40000]	lr: 3.615e-05, eta: 2:00:25, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8540, decode.acc_seg: 65.5581, loss: 0.8540
2022-11-29 22:26:21,158 - mmseg - INFO - Iter [15950/40000]	lr: 3.608e-05, eta: 2:00:11, time: 0.317, data_time: 0.049, memory: 5537, decode.loss_ce: 0.8592, decode.acc_seg: 68.6037, loss: 0.8592
2022-11-29 22:26:35,370 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:26:35,370 - mmseg - INFO - Iter [16000/40000]	lr: 3.600e-05, eta: 1:59:55, time: 0.284, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8251, decode.acc_seg: 70.1922, loss: 0.8251
2022-11-29 22:26:49,396 - mmseg - INFO - Iter [16050/40000]	lr: 3.593e-05, eta: 1:59:39, time: 0.281, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8905, decode.acc_seg: 69.0458, loss: 0.8905
2022-11-29 22:27:03,006 - mmseg - INFO - Iter [16100/40000]	lr: 3.585e-05, eta: 1:59:22, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8667, decode.acc_seg: 68.5438, loss: 0.8667
2022-11-29 22:27:18,699 - mmseg - INFO - Iter [16150/40000]	lr: 3.578e-05, eta: 1:59:08, time: 0.314, data_time: 0.048, memory: 5537, decode.loss_ce: 0.7870, decode.acc_seg: 72.6221, loss: 0.7870
2022-11-29 22:27:32,485 - mmseg - INFO - Iter [16200/40000]	lr: 3.570e-05, eta: 1:58:51, time: 0.276, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8535, decode.acc_seg: 67.1439, loss: 0.8535
2022-11-29 22:27:46,144 - mmseg - INFO - Iter [16250/40000]	lr: 3.563e-05, eta: 1:58:34, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7772, decode.acc_seg: 70.3026, loss: 0.7772
2022-11-29 22:28:01,988 - mmseg - INFO - Iter [16300/40000]	lr: 3.555e-05, eta: 1:58:20, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 0.7478, decode.acc_seg: 74.8068, loss: 0.7478
2022-11-29 22:28:15,991 - mmseg - INFO - Iter [16350/40000]	lr: 3.548e-05, eta: 1:58:04, time: 0.280, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7168, decode.acc_seg: 71.9384, loss: 0.7168
2022-11-29 22:28:29,859 - mmseg - INFO - Iter [16400/40000]	lr: 3.540e-05, eta: 1:57:47, time: 0.277, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9949, decode.acc_seg: 60.0533, loss: 0.9949
2022-11-29 22:28:43,579 - mmseg - INFO - Iter [16450/40000]	lr: 3.533e-05, eta: 1:57:31, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8940, decode.acc_seg: 67.7501, loss: 0.8940
2022-11-29 22:28:59,447 - mmseg - INFO - Iter [16500/40000]	lr: 3.525e-05, eta: 1:57:17, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 0.8896, decode.acc_seg: 68.7777, loss: 0.8896
2022-11-29 22:29:13,166 - mmseg - INFO - Iter [16550/40000]	lr: 3.518e-05, eta: 1:57:00, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7342, decode.acc_seg: 73.0489, loss: 0.7342
2022-11-29 22:29:26,853 - mmseg - INFO - Iter [16600/40000]	lr: 3.510e-05, eta: 1:56:43, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6489, decode.acc_seg: 72.3166, loss: 0.6489
2022-11-29 22:29:40,542 - mmseg - INFO - Iter [16650/40000]	lr: 3.503e-05, eta: 1:56:27, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7676, decode.acc_seg: 71.9933, loss: 0.7676
2022-11-29 22:29:56,823 - mmseg - INFO - Iter [16700/40000]	lr: 3.495e-05, eta: 1:56:14, time: 0.326, data_time: 0.048, memory: 5537, decode.loss_ce: 0.7736, decode.acc_seg: 70.3929, loss: 0.7736
2022-11-29 22:30:10,462 - mmseg - INFO - Iter [16750/40000]	lr: 3.488e-05, eta: 1:55:57, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7968, decode.acc_seg: 74.7819, loss: 0.7968
2022-11-29 22:30:24,199 - mmseg - INFO - Iter [16800/40000]	lr: 3.480e-05, eta: 1:55:40, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8529, decode.acc_seg: 69.1778, loss: 0.8529
2022-11-29 22:30:40,004 - mmseg - INFO - Iter [16850/40000]	lr: 3.473e-05, eta: 1:55:26, time: 0.316, data_time: 0.048, memory: 5537, decode.loss_ce: 1.0546, decode.acc_seg: 61.9407, loss: 1.0546
2022-11-29 22:30:53,683 - mmseg - INFO - Iter [16900/40000]	lr: 3.465e-05, eta: 1:55:10, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8145, decode.acc_seg: 70.5026, loss: 0.8145
2022-11-29 22:31:07,486 - mmseg - INFO - Iter [16950/40000]	lr: 3.458e-05, eta: 1:54:53, time: 0.276, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8076, decode.acc_seg: 71.5534, loss: 0.8076
2022-11-29 22:31:21,140 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:31:21,141 - mmseg - INFO - Iter [17000/40000]	lr: 3.450e-05, eta: 1:54:36, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7221, decode.acc_seg: 74.0553, loss: 0.7221
2022-11-29 22:31:37,241 - mmseg - INFO - Iter [17050/40000]	lr: 3.443e-05, eta: 1:54:23, time: 0.322, data_time: 0.049, memory: 5537, decode.loss_ce: 0.7521, decode.acc_seg: 72.1470, loss: 0.7521
2022-11-29 22:31:50,781 - mmseg - INFO - Iter [17100/40000]	lr: 3.435e-05, eta: 1:54:06, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7670, decode.acc_seg: 69.7874, loss: 0.7670
2022-11-29 22:32:04,272 - mmseg - INFO - Iter [17150/40000]	lr: 3.428e-05, eta: 1:53:49, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7374, decode.acc_seg: 72.8308, loss: 0.7374
2022-11-29 22:32:17,766 - mmseg - INFO - Iter [17200/40000]	lr: 3.420e-05, eta: 1:53:32, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7980, decode.acc_seg: 73.6540, loss: 0.7980
2022-11-29 22:32:33,323 - mmseg - INFO - Iter [17250/40000]	lr: 3.413e-05, eta: 1:53:18, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5880, decode.acc_seg: 77.9966, loss: 0.5880
2022-11-29 22:32:46,953 - mmseg - INFO - Iter [17300/40000]	lr: 3.405e-05, eta: 1:53:02, time: 0.273, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7047, decode.acc_seg: 70.9337, loss: 0.7047
2022-11-29 22:33:00,502 - mmseg - INFO - Iter [17350/40000]	lr: 3.398e-05, eta: 1:52:45, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6816, decode.acc_seg: 75.7751, loss: 0.6816
2022-11-29 22:33:16,114 - mmseg - INFO - Iter [17400/40000]	lr: 3.390e-05, eta: 1:52:31, time: 0.312, data_time: 0.048, memory: 5537, decode.loss_ce: 0.6402, decode.acc_seg: 74.4729, loss: 0.6402
2022-11-29 22:33:29,698 - mmseg - INFO - Iter [17450/40000]	lr: 3.383e-05, eta: 1:52:14, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7905, decode.acc_seg: 69.5038, loss: 0.7905
2022-11-29 22:33:43,248 - mmseg - INFO - Iter [17500/40000]	lr: 3.375e-05, eta: 1:51:57, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9692, decode.acc_seg: 65.8201, loss: 0.9692
2022-11-29 22:33:57,080 - mmseg - INFO - Iter [17550/40000]	lr: 3.368e-05, eta: 1:51:41, time: 0.277, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7977, decode.acc_seg: 70.3299, loss: 0.7977
2022-11-29 22:34:12,699 - mmseg - INFO - Iter [17600/40000]	lr: 3.360e-05, eta: 1:51:27, time: 0.312, data_time: 0.047, memory: 5537, decode.loss_ce: 0.6311, decode.acc_seg: 75.6240, loss: 0.6311
2022-11-29 22:34:26,222 - mmseg - INFO - Iter [17650/40000]	lr: 3.353e-05, eta: 1:51:10, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.8168, decode.acc_seg: 70.4956, loss: 0.8168
2022-11-29 22:34:39,780 - mmseg - INFO - Iter [17700/40000]	lr: 3.345e-05, eta: 1:50:54, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6649, decode.acc_seg: 75.9959, loss: 0.6649
2022-11-29 22:34:53,317 - mmseg - INFO - Iter [17750/40000]	lr: 3.338e-05, eta: 1:50:37, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7751, decode.acc_seg: 72.4479, loss: 0.7751
2022-11-29 22:35:10,110 - mmseg - INFO - Iter [17800/40000]	lr: 3.330e-05, eta: 1:50:24, time: 0.336, data_time: 0.049, memory: 5537, decode.loss_ce: 0.5767, decode.acc_seg: 75.5510, loss: 0.5767
2022-11-29 22:35:24,621 - mmseg - INFO - Iter [17850/40000]	lr: 3.323e-05, eta: 1:50:09, time: 0.290, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6243, decode.acc_seg: 74.3989, loss: 0.6243
2022-11-29 22:35:39,560 - mmseg - INFO - Iter [17900/40000]	lr: 3.315e-05, eta: 1:49:54, time: 0.299, data_time: 0.006, memory: 5537, decode.loss_ce: 0.8622, decode.acc_seg: 69.1941, loss: 0.8622
2022-11-29 22:35:55,207 - mmseg - INFO - Iter [17950/40000]	lr: 3.308e-05, eta: 1:49:40, time: 0.313, data_time: 0.047, memory: 5537, decode.loss_ce: 0.6445, decode.acc_seg: 76.4592, loss: 0.6445
2022-11-29 22:36:08,798 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:36:08,799 - mmseg - INFO - Iter [18000/40000]	lr: 3.300e-05, eta: 1:49:24, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8823, decode.acc_seg: 66.1573, loss: 0.8823
2022-11-29 22:36:22,362 - mmseg - INFO - Iter [18050/40000]	lr: 3.293e-05, eta: 1:49:07, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7478, decode.acc_seg: 74.1572, loss: 0.7478
2022-11-29 22:36:35,794 - mmseg - INFO - Iter [18100/40000]	lr: 3.285e-05, eta: 1:48:50, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7182, decode.acc_seg: 74.7878, loss: 0.7182
2022-11-29 22:36:51,351 - mmseg - INFO - Iter [18150/40000]	lr: 3.278e-05, eta: 1:48:36, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5877, decode.acc_seg: 73.7216, loss: 0.5877
2022-11-29 22:37:04,835 - mmseg - INFO - Iter [18200/40000]	lr: 3.270e-05, eta: 1:48:19, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8261, decode.acc_seg: 72.7537, loss: 0.8261
2022-11-29 22:37:18,281 - mmseg - INFO - Iter [18250/40000]	lr: 3.263e-05, eta: 1:48:03, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7376, decode.acc_seg: 72.4075, loss: 0.7376
2022-11-29 22:37:31,743 - mmseg - INFO - Iter [18300/40000]	lr: 3.255e-05, eta: 1:47:46, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7239, decode.acc_seg: 74.0326, loss: 0.7239
2022-11-29 22:37:47,318 - mmseg - INFO - Iter [18350/40000]	lr: 3.248e-05, eta: 1:47:32, time: 0.311, data_time: 0.048, memory: 5537, decode.loss_ce: 0.6346, decode.acc_seg: 74.6656, loss: 0.6346
2022-11-29 22:38:00,728 - mmseg - INFO - Iter [18400/40000]	lr: 3.240e-05, eta: 1:47:15, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.8014, decode.acc_seg: 71.8245, loss: 0.8014
2022-11-29 22:38:14,133 - mmseg - INFO - Iter [18450/40000]	lr: 3.233e-05, eta: 1:46:59, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5461, decode.acc_seg: 78.0969, loss: 0.5461
2022-11-29 22:38:29,782 - mmseg - INFO - Iter [18500/40000]	lr: 3.225e-05, eta: 1:46:45, time: 0.313, data_time: 0.049, memory: 5537, decode.loss_ce: 0.7938, decode.acc_seg: 69.7497, loss: 0.7938
2022-11-29 22:38:43,362 - mmseg - INFO - Iter [18550/40000]	lr: 3.218e-05, eta: 1:46:28, time: 0.272, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5977, decode.acc_seg: 77.5248, loss: 0.5977
2022-11-29 22:38:56,949 - mmseg - INFO - Iter [18600/40000]	lr: 3.210e-05, eta: 1:46:12, time: 0.272, data_time: 0.006, memory: 5537, decode.loss_ce: 0.8208, decode.acc_seg: 68.7336, loss: 0.8208
2022-11-29 22:39:10,398 - mmseg - INFO - Iter [18650/40000]	lr: 3.203e-05, eta: 1:45:55, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6799, decode.acc_seg: 72.5449, loss: 0.6799
2022-11-29 22:39:25,966 - mmseg - INFO - Iter [18700/40000]	lr: 3.195e-05, eta: 1:45:41, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 0.7153, decode.acc_seg: 74.6425, loss: 0.7153
2022-11-29 22:39:40,695 - mmseg - INFO - Iter [18750/40000]	lr: 3.188e-05, eta: 1:45:26, time: 0.295, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7504, decode.acc_seg: 71.2077, loss: 0.7504
2022-11-29 22:39:56,963 - mmseg - INFO - Iter [18800/40000]	lr: 3.180e-05, eta: 1:45:13, time: 0.325, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6113, decode.acc_seg: 74.4164, loss: 0.6113
2022-11-29 22:40:15,284 - mmseg - INFO - Iter [18850/40000]	lr: 3.173e-05, eta: 1:45:02, time: 0.366, data_time: 0.048, memory: 5537, decode.loss_ce: 0.7317, decode.acc_seg: 71.9505, loss: 0.7317
2022-11-29 22:40:28,899 - mmseg - INFO - Iter [18900/40000]	lr: 3.165e-05, eta: 1:44:46, time: 0.272, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5836, decode.acc_seg: 78.9165, loss: 0.5836
2022-11-29 22:40:42,494 - mmseg - INFO - Iter [18950/40000]	lr: 3.158e-05, eta: 1:44:29, time: 0.272, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7431, decode.acc_seg: 73.0520, loss: 0.7431
2022-11-29 22:40:56,008 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:40:56,009 - mmseg - INFO - Iter [19000/40000]	lr: 3.150e-05, eta: 1:44:13, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7141, decode.acc_seg: 68.9995, loss: 0.7141
2022-11-29 22:41:11,573 - mmseg - INFO - Iter [19050/40000]	lr: 3.143e-05, eta: 1:43:59, time: 0.311, data_time: 0.048, memory: 5537, decode.loss_ce: 0.6092, decode.acc_seg: 74.1135, loss: 0.6092
2022-11-29 22:41:24,967 - mmseg - INFO - Iter [19100/40000]	lr: 3.135e-05, eta: 1:43:42, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6659, decode.acc_seg: 74.7237, loss: 0.6659
2022-11-29 22:41:38,441 - mmseg - INFO - Iter [19150/40000]	lr: 3.128e-05, eta: 1:43:26, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6841, decode.acc_seg: 72.6206, loss: 0.6841
2022-11-29 22:41:51,930 - mmseg - INFO - Iter [19200/40000]	lr: 3.120e-05, eta: 1:43:09, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5749, decode.acc_seg: 78.1058, loss: 0.5749
2022-11-29 22:42:07,986 - mmseg - INFO - Iter [19250/40000]	lr: 3.113e-05, eta: 1:42:56, time: 0.321, data_time: 0.048, memory: 5537, decode.loss_ce: 0.6058, decode.acc_seg: 76.8264, loss: 0.6058
2022-11-29 22:42:22,382 - mmseg - INFO - Iter [19300/40000]	lr: 3.105e-05, eta: 1:42:40, time: 0.288, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5918, decode.acc_seg: 80.1886, loss: 0.5918
2022-11-29 22:42:35,829 - mmseg - INFO - Iter [19350/40000]	lr: 3.098e-05, eta: 1:42:24, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6255, decode.acc_seg: 76.1238, loss: 0.6255
2022-11-29 22:42:51,381 - mmseg - INFO - Iter [19400/40000]	lr: 3.090e-05, eta: 1:42:10, time: 0.311, data_time: 0.048, memory: 5537, decode.loss_ce: 0.6844, decode.acc_seg: 73.0847, loss: 0.6844
2022-11-29 22:43:05,406 - mmseg - INFO - Iter [19450/40000]	lr: 3.083e-05, eta: 1:41:54, time: 0.280, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7230, decode.acc_seg: 71.2105, loss: 0.7230
2022-11-29 22:43:18,905 - mmseg - INFO - Iter [19500/40000]	lr: 3.075e-05, eta: 1:41:38, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8062, decode.acc_seg: 70.7930, loss: 0.8062
2022-11-29 22:43:32,429 - mmseg - INFO - Iter [19550/40000]	lr: 3.068e-05, eta: 1:41:21, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6478, decode.acc_seg: 75.4103, loss: 0.6478
2022-11-29 22:43:48,008 - mmseg - INFO - Iter [19600/40000]	lr: 3.060e-05, eta: 1:41:07, time: 0.312, data_time: 0.048, memory: 5537, decode.loss_ce: 0.6389, decode.acc_seg: 74.2730, loss: 0.6389
2022-11-29 22:44:01,443 - mmseg - INFO - Iter [19650/40000]	lr: 3.053e-05, eta: 1:40:51, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6251, decode.acc_seg: 74.7444, loss: 0.6251
2022-11-29 22:44:14,947 - mmseg - INFO - Iter [19700/40000]	lr: 3.045e-05, eta: 1:40:35, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5327, decode.acc_seg: 78.4049, loss: 0.5327
2022-11-29 22:44:28,338 - mmseg - INFO - Iter [19750/40000]	lr: 3.038e-05, eta: 1:40:18, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6161, decode.acc_seg: 76.3658, loss: 0.6161
2022-11-29 22:44:44,258 - mmseg - INFO - Iter [19800/40000]	lr: 3.030e-05, eta: 1:40:04, time: 0.318, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5964, decode.acc_seg: 75.6643, loss: 0.5964
2022-11-29 22:44:58,480 - mmseg - INFO - Iter [19850/40000]	lr: 3.023e-05, eta: 1:39:49, time: 0.284, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6436, decode.acc_seg: 75.4015, loss: 0.6436
2022-11-29 22:45:12,115 - mmseg - INFO - Iter [19900/40000]	lr: 3.015e-05, eta: 1:39:33, time: 0.273, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5802, decode.acc_seg: 78.2255, loss: 0.5802
2022-11-29 22:45:27,611 - mmseg - INFO - Iter [19950/40000]	lr: 3.008e-05, eta: 1:39:19, time: 0.310, data_time: 0.047, memory: 5537, decode.loss_ce: 0.7142, decode.acc_seg: 72.3563, loss: 0.7142
2022-11-29 22:45:41,113 - mmseg - INFO - Saving checkpoint at 20000 iterations
2022-11-29 22:45:44,052 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:45:44,052 - mmseg - INFO - Iter [20000/40000]	lr: 3.000e-05, eta: 1:39:05, time: 0.329, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6810, decode.acc_seg: 72.6972, loss: 0.6810
2022-11-29 22:46:26,394 - mmseg - INFO - per class results:
2022-11-29 22:46:26,395 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 73.42 |  88.2 |
|  aeroplane  |  0.81 |  0.83 |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  0.1  |  0.17 |
|     boat    |  0.21 |  0.67 |
|    bottle   |  0.0  |  0.0  |
|     bus     |  3.01 |  3.82 |
|     car     |  7.65 |  8.77 |
|     cat     |  5.92 |  9.52 |
|    chair    |  0.0  |  0.0  |
|     cow     |  5.53 | 13.42 |
| diningtable |  1.37 |  1.49 |
|     dog     |  9.68 | 32.05 |
|    horse    |  1.34 |  2.01 |
|  motorbike  |  6.22 | 44.07 |
|    person   |  9.05 |  9.61 |
| pottedplant |  0.46 |  0.69 |
|    sheep    | 11.65 | 19.64 |
|     sofa    |  0.01 |  0.01 |
|    train    |  1.46 |  1.86 |
|  tvmonitor  |  0.26 |  0.41 |
+-------------+-------+-------+
2022-11-29 22:46:26,395 - mmseg - INFO - Summary:
2022-11-29 22:46:26,396 - mmseg - INFO - 
+-------+------+------+
|  aAcc | mIoU | mAcc |
+-------+------+------+
| 67.14 | 6.58 | 11.3 |
+-------+------+------+
2022-11-29 22:46:26,397 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:46:26,397 - mmseg - INFO - Iter(val) [724]	aAcc: 0.6714, mIoU: 0.0658, mAcc: 0.1130, IoU.background: 0.7342, IoU.aeroplane: 0.0081, IoU.bicycle: 0.0000, IoU.bird: 0.0010, IoU.boat: 0.0021, IoU.bottle: 0.0000, IoU.bus: 0.0301, IoU.car: 0.0765, IoU.cat: 0.0592, IoU.chair: 0.0000, IoU.cow: 0.0553, IoU.diningtable: 0.0137, IoU.dog: 0.0968, IoU.horse: 0.0134, IoU.motorbike: 0.0622, IoU.person: 0.0905, IoU.pottedplant: 0.0046, IoU.sheep: 0.1165, IoU.sofa: 0.0001, IoU.train: 0.0146, IoU.tvmonitor: 0.0026, Acc.background: 0.8820, Acc.aeroplane: 0.0083, Acc.bicycle: 0.0000, Acc.bird: 0.0017, Acc.boat: 0.0067, Acc.bottle: 0.0000, Acc.bus: 0.0382, Acc.car: 0.0877, Acc.cat: 0.0952, Acc.chair: 0.0000, Acc.cow: 0.1342, Acc.diningtable: 0.0149, Acc.dog: 0.3205, Acc.horse: 0.0201, Acc.motorbike: 0.4407, Acc.person: 0.0961, Acc.pottedplant: 0.0069, Acc.sheep: 0.1964, Acc.sofa: 0.0001, Acc.train: 0.0186, Acc.tvmonitor: 0.0041
2022-11-29 22:46:39,935 - mmseg - INFO - Iter [20050/40000]	lr: 2.993e-05, eta: 1:39:31, time: 1.118, data_time: 0.853, memory: 5537, decode.loss_ce: 0.5614, decode.acc_seg: 78.4594, loss: 0.5614
2022-11-29 22:46:53,415 - mmseg - INFO - Iter [20100/40000]	lr: 2.985e-05, eta: 1:39:15, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6708, decode.acc_seg: 76.0716, loss: 0.6708
2022-11-29 22:47:08,965 - mmseg - INFO - Iter [20150/40000]	lr: 2.978e-05, eta: 1:39:00, time: 0.311, data_time: 0.048, memory: 5537, decode.loss_ce: 0.6120, decode.acc_seg: 74.6515, loss: 0.6120
2022-11-29 22:47:22,527 - mmseg - INFO - Iter [20200/40000]	lr: 2.970e-05, eta: 1:38:44, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6115, decode.acc_seg: 75.6394, loss: 0.6115
2022-11-29 22:47:36,114 - mmseg - INFO - Iter [20250/40000]	lr: 2.963e-05, eta: 1:38:28, time: 0.272, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5644, decode.acc_seg: 78.7851, loss: 0.5644
2022-11-29 22:47:49,702 - mmseg - INFO - Iter [20300/40000]	lr: 2.955e-05, eta: 1:38:11, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6447, decode.acc_seg: 75.1654, loss: 0.6447
2022-11-29 22:48:05,410 - mmseg - INFO - Iter [20350/40000]	lr: 2.948e-05, eta: 1:37:57, time: 0.314, data_time: 0.049, memory: 5537, decode.loss_ce: 0.4712, decode.acc_seg: 79.3002, loss: 0.4712
2022-11-29 22:48:18,781 - mmseg - INFO - Iter [20400/40000]	lr: 2.940e-05, eta: 1:37:41, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6940, decode.acc_seg: 73.6135, loss: 0.6940
2022-11-29 22:48:32,178 - mmseg - INFO - Iter [20450/40000]	lr: 2.933e-05, eta: 1:37:24, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6674, decode.acc_seg: 74.1358, loss: 0.6674
2022-11-29 22:48:47,832 - mmseg - INFO - Iter [20500/40000]	lr: 2.925e-05, eta: 1:37:10, time: 0.313, data_time: 0.047, memory: 5537, decode.loss_ce: 0.6380, decode.acc_seg: 73.9697, loss: 0.6380
2022-11-29 22:49:02,210 - mmseg - INFO - Iter [20550/40000]	lr: 2.918e-05, eta: 1:36:55, time: 0.288, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5896, decode.acc_seg: 74.3913, loss: 0.5896
2022-11-29 22:49:16,322 - mmseg - INFO - Iter [20600/40000]	lr: 2.910e-05, eta: 1:36:39, time: 0.282, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6476, decode.acc_seg: 74.5947, loss: 0.6476
2022-11-29 22:49:29,836 - mmseg - INFO - Iter [20650/40000]	lr: 2.903e-05, eta: 1:36:23, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6363, decode.acc_seg: 74.8342, loss: 0.6363
2022-11-29 22:49:45,799 - mmseg - INFO - Iter [20700/40000]	lr: 2.895e-05, eta: 1:36:09, time: 0.319, data_time: 0.048, memory: 5537, decode.loss_ce: 0.6466, decode.acc_seg: 75.4537, loss: 0.6466
2022-11-29 22:50:01,772 - mmseg - INFO - Iter [20750/40000]	lr: 2.888e-05, eta: 1:35:55, time: 0.319, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5661, decode.acc_seg: 78.9605, loss: 0.5661
2022-11-29 22:50:16,852 - mmseg - INFO - Iter [20800/40000]	lr: 2.880e-05, eta: 1:35:40, time: 0.302, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6130, decode.acc_seg: 74.5913, loss: 0.6130
2022-11-29 22:50:30,299 - mmseg - INFO - Iter [20850/40000]	lr: 2.873e-05, eta: 1:35:23, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5373, decode.acc_seg: 77.1635, loss: 0.5373
2022-11-29 22:50:46,072 - mmseg - INFO - Iter [20900/40000]	lr: 2.865e-05, eta: 1:35:09, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 0.5738, decode.acc_seg: 79.6778, loss: 0.5738
2022-11-29 22:50:59,478 - mmseg - INFO - Iter [20950/40000]	lr: 2.858e-05, eta: 1:34:53, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6203, decode.acc_seg: 73.3934, loss: 0.6203
2022-11-29 22:51:12,931 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:51:12,932 - mmseg - INFO - Iter [21000/40000]	lr: 2.850e-05, eta: 1:34:37, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6123, decode.acc_seg: 77.5635, loss: 0.6123
2022-11-29 22:51:28,528 - mmseg - INFO - Iter [21050/40000]	lr: 2.843e-05, eta: 1:34:22, time: 0.312, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5628, decode.acc_seg: 77.4270, loss: 0.5628
2022-11-29 22:51:41,936 - mmseg - INFO - Iter [21100/40000]	lr: 2.835e-05, eta: 1:34:06, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5431, decode.acc_seg: 78.3771, loss: 0.5431
2022-11-29 22:51:55,374 - mmseg - INFO - Iter [21150/40000]	lr: 2.828e-05, eta: 1:33:50, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5403, decode.acc_seg: 77.9682, loss: 0.5403
2022-11-29 22:52:08,924 - mmseg - INFO - Iter [21200/40000]	lr: 2.820e-05, eta: 1:33:33, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5986, decode.acc_seg: 78.0492, loss: 0.5986
2022-11-29 22:52:24,767 - mmseg - INFO - Iter [21250/40000]	lr: 2.813e-05, eta: 1:33:19, time: 0.317, data_time: 0.047, memory: 5537, decode.loss_ce: 0.4686, decode.acc_seg: 81.8582, loss: 0.4686
2022-11-29 22:52:38,303 - mmseg - INFO - Iter [21300/40000]	lr: 2.805e-05, eta: 1:33:03, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4716, decode.acc_seg: 79.7301, loss: 0.4716
2022-11-29 22:52:52,279 - mmseg - INFO - Iter [21350/40000]	lr: 2.798e-05, eta: 1:32:47, time: 0.280, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6176, decode.acc_seg: 77.0675, loss: 0.6176
2022-11-29 22:53:05,722 - mmseg - INFO - Iter [21400/40000]	lr: 2.790e-05, eta: 1:32:31, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7756, decode.acc_seg: 71.8721, loss: 0.7756
2022-11-29 22:53:21,970 - mmseg - INFO - Iter [21450/40000]	lr: 2.783e-05, eta: 1:32:17, time: 0.325, data_time: 0.048, memory: 5537, decode.loss_ce: 0.5547, decode.acc_seg: 78.2494, loss: 0.5547
2022-11-29 22:53:36,156 - mmseg - INFO - Iter [21500/40000]	lr: 2.775e-05, eta: 1:32:02, time: 0.284, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5332, decode.acc_seg: 78.3639, loss: 0.5332
2022-11-29 22:53:50,107 - mmseg - INFO - Iter [21550/40000]	lr: 2.768e-05, eta: 1:31:46, time: 0.279, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5123, decode.acc_seg: 79.7213, loss: 0.5123
2022-11-29 22:54:05,853 - mmseg - INFO - Iter [21600/40000]	lr: 2.760e-05, eta: 1:31:32, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 0.5722, decode.acc_seg: 78.8699, loss: 0.5722
2022-11-29 22:54:20,539 - mmseg - INFO - Iter [21650/40000]	lr: 2.753e-05, eta: 1:31:17, time: 0.294, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5294, decode.acc_seg: 80.3658, loss: 0.5294
2022-11-29 22:54:34,370 - mmseg - INFO - Iter [21700/40000]	lr: 2.745e-05, eta: 1:31:01, time: 0.277, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6604, decode.acc_seg: 78.2752, loss: 0.6604
2022-11-29 22:54:48,189 - mmseg - INFO - Iter [21750/40000]	lr: 2.738e-05, eta: 1:30:45, time: 0.276, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6006, decode.acc_seg: 76.5359, loss: 0.6006
2022-11-29 22:55:04,429 - mmseg - INFO - Iter [21800/40000]	lr: 2.730e-05, eta: 1:30:31, time: 0.325, data_time: 0.048, memory: 5537, decode.loss_ce: 0.5705, decode.acc_seg: 79.0202, loss: 0.5705
2022-11-29 22:55:18,427 - mmseg - INFO - Iter [21850/40000]	lr: 2.723e-05, eta: 1:30:16, time: 0.280, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5369, decode.acc_seg: 77.2967, loss: 0.5369
2022-11-29 22:55:31,845 - mmseg - INFO - Iter [21900/40000]	lr: 2.715e-05, eta: 1:29:59, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5626, decode.acc_seg: 79.1767, loss: 0.5626
2022-11-29 22:55:45,338 - mmseg - INFO - Iter [21950/40000]	lr: 2.708e-05, eta: 1:29:43, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5979, decode.acc_seg: 75.4807, loss: 0.5979
2022-11-29 22:56:01,032 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 22:56:01,032 - mmseg - INFO - Iter [22000/40000]	lr: 2.700e-05, eta: 1:29:29, time: 0.314, data_time: 0.048, memory: 5537, decode.loss_ce: 0.6382, decode.acc_seg: 74.4870, loss: 0.6382
2022-11-29 22:56:14,466 - mmseg - INFO - Iter [22050/40000]	lr: 2.693e-05, eta: 1:29:13, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5944, decode.acc_seg: 79.2259, loss: 0.5944
2022-11-29 22:56:28,027 - mmseg - INFO - Iter [22100/40000]	lr: 2.685e-05, eta: 1:28:57, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5877, decode.acc_seg: 80.2231, loss: 0.5877
2022-11-29 22:56:43,729 - mmseg - INFO - Iter [22150/40000]	lr: 2.678e-05, eta: 1:28:43, time: 0.314, data_time: 0.048, memory: 5537, decode.loss_ce: 0.5555, decode.acc_seg: 79.1271, loss: 0.5555
2022-11-29 22:56:58,017 - mmseg - INFO - Iter [22200/40000]	lr: 2.670e-05, eta: 1:28:27, time: 0.286, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4622, decode.acc_seg: 79.5088, loss: 0.4622
2022-11-29 22:57:11,655 - mmseg - INFO - Iter [22250/40000]	lr: 2.663e-05, eta: 1:28:11, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5285, decode.acc_seg: 78.3122, loss: 0.5285
2022-11-29 22:57:25,128 - mmseg - INFO - Iter [22300/40000]	lr: 2.655e-05, eta: 1:27:55, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5907, decode.acc_seg: 74.9065, loss: 0.5907
2022-11-29 22:57:40,758 - mmseg - INFO - Iter [22350/40000]	lr: 2.648e-05, eta: 1:27:41, time: 0.313, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5163, decode.acc_seg: 78.4030, loss: 0.5163
2022-11-29 22:57:56,953 - mmseg - INFO - Iter [22400/40000]	lr: 2.640e-05, eta: 1:27:27, time: 0.324, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4721, decode.acc_seg: 83.1476, loss: 0.4721
2022-11-29 22:58:11,998 - mmseg - INFO - Iter [22450/40000]	lr: 2.633e-05, eta: 1:27:12, time: 0.301, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4646, decode.acc_seg: 81.0874, loss: 0.4646
2022-11-29 22:58:25,468 - mmseg - INFO - Iter [22500/40000]	lr: 2.625e-05, eta: 1:26:56, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5354, decode.acc_seg: 77.9228, loss: 0.5354
2022-11-29 22:58:41,712 - mmseg - INFO - Iter [22550/40000]	lr: 2.618e-05, eta: 1:26:42, time: 0.325, data_time: 0.049, memory: 5537, decode.loss_ce: 0.5460, decode.acc_seg: 77.3197, loss: 0.5460
2022-11-29 22:58:55,546 - mmseg - INFO - Iter [22600/40000]	lr: 2.610e-05, eta: 1:26:27, time: 0.277, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4745, decode.acc_seg: 81.1523, loss: 0.4745
2022-11-29 22:59:09,785 - mmseg - INFO - Iter [22650/40000]	lr: 2.603e-05, eta: 1:26:11, time: 0.285, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6588, decode.acc_seg: 77.9119, loss: 0.6588
2022-11-29 22:59:25,357 - mmseg - INFO - Iter [22700/40000]	lr: 2.595e-05, eta: 1:25:57, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 0.6056, decode.acc_seg: 77.2967, loss: 0.6056
2022-11-29 22:59:38,821 - mmseg - INFO - Iter [22750/40000]	lr: 2.588e-05, eta: 1:25:41, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5499, decode.acc_seg: 77.2229, loss: 0.5499
2022-11-29 22:59:52,423 - mmseg - INFO - Iter [22800/40000]	lr: 2.580e-05, eta: 1:25:25, time: 0.272, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5210, decode.acc_seg: 78.6841, loss: 0.5210
2022-11-29 23:00:05,897 - mmseg - INFO - Iter [22850/40000]	lr: 2.573e-05, eta: 1:25:09, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6550, decode.acc_seg: 73.8565, loss: 0.6550
2022-11-29 23:00:22,431 - mmseg - INFO - Iter [22900/40000]	lr: 2.565e-05, eta: 1:24:55, time: 0.331, data_time: 0.049, memory: 5537, decode.loss_ce: 0.4705, decode.acc_seg: 84.2349, loss: 0.4705
2022-11-29 23:00:36,528 - mmseg - INFO - Iter [22950/40000]	lr: 2.558e-05, eta: 1:24:40, time: 0.282, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4339, decode.acc_seg: 82.0767, loss: 0.4339
2022-11-29 23:00:50,200 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:00:50,201 - mmseg - INFO - Iter [23000/40000]	lr: 2.550e-05, eta: 1:24:24, time: 0.273, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5501, decode.acc_seg: 77.0692, loss: 0.5501
2022-11-29 23:01:03,862 - mmseg - INFO - Iter [23050/40000]	lr: 2.543e-05, eta: 1:24:08, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4787, decode.acc_seg: 78.4482, loss: 0.4787
2022-11-29 23:01:19,576 - mmseg - INFO - Iter [23100/40000]	lr: 2.535e-05, eta: 1:23:54, time: 0.314, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4248, decode.acc_seg: 83.2010, loss: 0.4248
2022-11-29 23:01:34,598 - mmseg - INFO - Iter [23150/40000]	lr: 2.528e-05, eta: 1:23:39, time: 0.300, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4193, decode.acc_seg: 82.3708, loss: 0.4193
2022-11-29 23:01:49,430 - mmseg - INFO - Iter [23200/40000]	lr: 2.520e-05, eta: 1:23:24, time: 0.297, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5531, decode.acc_seg: 79.5588, loss: 0.5531
2022-11-29 23:02:05,792 - mmseg - INFO - Iter [23250/40000]	lr: 2.513e-05, eta: 1:23:10, time: 0.327, data_time: 0.048, memory: 5537, decode.loss_ce: 0.5317, decode.acc_seg: 76.6140, loss: 0.5317
2022-11-29 23:02:19,469 - mmseg - INFO - Iter [23300/40000]	lr: 2.505e-05, eta: 1:22:54, time: 0.274, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5006, decode.acc_seg: 82.5654, loss: 0.5006
2022-11-29 23:02:32,968 - mmseg - INFO - Iter [23350/40000]	lr: 2.498e-05, eta: 1:22:39, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4803, decode.acc_seg: 81.2324, loss: 0.4803
2022-11-29 23:02:46,424 - mmseg - INFO - Iter [23400/40000]	lr: 2.490e-05, eta: 1:22:23, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4491, decode.acc_seg: 82.9765, loss: 0.4491
2022-11-29 23:03:01,950 - mmseg - INFO - Iter [23450/40000]	lr: 2.483e-05, eta: 1:22:08, time: 0.310, data_time: 0.047, memory: 5537, decode.loss_ce: 0.4056, decode.acc_seg: 84.5939, loss: 0.4056
2022-11-29 23:03:15,352 - mmseg - INFO - Iter [23500/40000]	lr: 2.475e-05, eta: 1:21:52, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4759, decode.acc_seg: 82.0057, loss: 0.4759
2022-11-29 23:03:28,865 - mmseg - INFO - Iter [23550/40000]	lr: 2.468e-05, eta: 1:21:36, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6833, decode.acc_seg: 75.3976, loss: 0.6833
2022-11-29 23:03:42,295 - mmseg - INFO - Iter [23600/40000]	lr: 2.460e-05, eta: 1:21:21, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4388, decode.acc_seg: 84.2026, loss: 0.4388
2022-11-29 23:03:57,855 - mmseg - INFO - Iter [23650/40000]	lr: 2.453e-05, eta: 1:21:06, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5045, decode.acc_seg: 80.6098, loss: 0.5045
2022-11-29 23:04:11,302 - mmseg - INFO - Iter [23700/40000]	lr: 2.445e-05, eta: 1:20:50, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4997, decode.acc_seg: 79.6419, loss: 0.4997
2022-11-29 23:04:24,674 - mmseg - INFO - Iter [23750/40000]	lr: 2.438e-05, eta: 1:20:34, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6134, decode.acc_seg: 78.0381, loss: 0.6134
2022-11-29 23:04:40,234 - mmseg - INFO - Iter [23800/40000]	lr: 2.430e-05, eta: 1:20:20, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5127, decode.acc_seg: 80.3218, loss: 0.5127
2022-11-29 23:04:53,953 - mmseg - INFO - Iter [23850/40000]	lr: 2.423e-05, eta: 1:20:04, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4207, decode.acc_seg: 83.7075, loss: 0.4207
2022-11-29 23:05:07,429 - mmseg - INFO - Iter [23900/40000]	lr: 2.415e-05, eta: 1:19:48, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5616, decode.acc_seg: 80.2397, loss: 0.5616
2022-11-29 23:05:21,131 - mmseg - INFO - Iter [23950/40000]	lr: 2.408e-05, eta: 1:19:33, time: 0.274, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5464, decode.acc_seg: 80.2280, loss: 0.5464
2022-11-29 23:05:36,686 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:05:36,687 - mmseg - INFO - Iter [24000/40000]	lr: 2.400e-05, eta: 1:19:18, time: 0.311, data_time: 0.048, memory: 5537, decode.loss_ce: 0.5282, decode.acc_seg: 78.4611, loss: 0.5282
2022-11-29 23:05:50,130 - mmseg - INFO - Iter [24050/40000]	lr: 2.393e-05, eta: 1:19:03, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5379, decode.acc_seg: 78.5160, loss: 0.5379
2022-11-29 23:06:03,514 - mmseg - INFO - Iter [24100/40000]	lr: 2.385e-05, eta: 1:18:47, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4606, decode.acc_seg: 82.7225, loss: 0.4606
2022-11-29 23:06:16,918 - mmseg - INFO - Iter [24150/40000]	lr: 2.378e-05, eta: 1:18:31, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5801, decode.acc_seg: 77.6443, loss: 0.5801
2022-11-29 23:06:32,460 - mmseg - INFO - Iter [24200/40000]	lr: 2.370e-05, eta: 1:18:16, time: 0.311, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4088, decode.acc_seg: 82.9355, loss: 0.4088
2022-11-29 23:06:45,899 - mmseg - INFO - Iter [24250/40000]	lr: 2.363e-05, eta: 1:18:01, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6197, decode.acc_seg: 75.7004, loss: 0.6197
2022-11-29 23:06:59,324 - mmseg - INFO - Iter [24300/40000]	lr: 2.355e-05, eta: 1:17:45, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4157, decode.acc_seg: 84.2479, loss: 0.4157
2022-11-29 23:07:14,838 - mmseg - INFO - Iter [24350/40000]	lr: 2.348e-05, eta: 1:17:30, time: 0.310, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5394, decode.acc_seg: 79.1554, loss: 0.5394
2022-11-29 23:07:28,328 - mmseg - INFO - Iter [24400/40000]	lr: 2.340e-05, eta: 1:17:15, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4554, decode.acc_seg: 79.4533, loss: 0.4554
2022-11-29 23:07:42,926 - mmseg - INFO - Iter [24450/40000]	lr: 2.333e-05, eta: 1:17:00, time: 0.292, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6082, decode.acc_seg: 77.3002, loss: 0.6082
2022-11-29 23:07:56,564 - mmseg - INFO - Iter [24500/40000]	lr: 2.325e-05, eta: 1:16:44, time: 0.273, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3968, decode.acc_seg: 85.9229, loss: 0.3968
2022-11-29 23:08:12,149 - mmseg - INFO - Iter [24550/40000]	lr: 2.318e-05, eta: 1:16:30, time: 0.312, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4769, decode.acc_seg: 80.6303, loss: 0.4769
2022-11-29 23:08:25,690 - mmseg - INFO - Iter [24600/40000]	lr: 2.310e-05, eta: 1:16:14, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5588, decode.acc_seg: 78.0524, loss: 0.5588
2022-11-29 23:08:39,132 - mmseg - INFO - Iter [24650/40000]	lr: 2.303e-05, eta: 1:15:58, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4954, decode.acc_seg: 83.6233, loss: 0.4954
2022-11-29 23:08:53,140 - mmseg - INFO - Iter [24700/40000]	lr: 2.295e-05, eta: 1:15:43, time: 0.280, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5480, decode.acc_seg: 79.4282, loss: 0.5480
2022-11-29 23:09:08,742 - mmseg - INFO - Iter [24750/40000]	lr: 2.288e-05, eta: 1:15:29, time: 0.312, data_time: 0.048, memory: 5537, decode.loss_ce: 0.3619, decode.acc_seg: 86.0436, loss: 0.3619
2022-11-29 23:09:22,209 - mmseg - INFO - Iter [24800/40000]	lr: 2.280e-05, eta: 1:15:13, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4464, decode.acc_seg: 83.0990, loss: 0.4464
2022-11-29 23:09:35,624 - mmseg - INFO - Iter [24850/40000]	lr: 2.273e-05, eta: 1:14:57, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4176, decode.acc_seg: 82.7349, loss: 0.4176
2022-11-29 23:09:51,344 - mmseg - INFO - Iter [24900/40000]	lr: 2.265e-05, eta: 1:14:43, time: 0.314, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5149, decode.acc_seg: 81.4096, loss: 0.5149
2022-11-29 23:10:04,882 - mmseg - INFO - Iter [24950/40000]	lr: 2.258e-05, eta: 1:14:27, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4637, decode.acc_seg: 80.3937, loss: 0.4637
2022-11-29 23:10:18,331 - mmseg - INFO - Saving checkpoint at 25000 iterations
2022-11-29 23:10:21,317 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:10:21,317 - mmseg - INFO - Iter [25000/40000]	lr: 2.250e-05, eta: 1:14:13, time: 0.329, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4502, decode.acc_seg: 81.5561, loss: 0.4502
2022-11-29 23:11:03,640 - mmseg - INFO - per class results:
2022-11-29 23:11:03,641 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 70.56 | 82.86 |
|  aeroplane  |  2.47 |  2.89 |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  0.07 |  0.09 |
|     boat    |  0.14 |  0.24 |
|    bottle   |  0.17 |  0.23 |
|     bus     |  5.86 | 20.15 |
|     car     |  13.8 | 24.84 |
|     cat     |  6.3  |  8.58 |
|    chair    |  0.8  |  1.0  |
|     cow     |  1.4  |  1.99 |
| diningtable |  1.08 |  1.14 |
|     dog     | 12.49 | 41.48 |
|    horse    |  0.0  |  0.0  |
|  motorbike  |  9.27 | 25.87 |
|    person   | 17.71 | 35.57 |
| pottedplant |  0.13 |  0.16 |
|    sheep    |  9.09 | 11.59 |
|     sofa    |  0.0  |  0.0  |
|    train    |  2.39 |  2.99 |
|  tvmonitor  |  2.66 |  8.66 |
+-------------+-------+-------+
2022-11-29 23:11:03,641 - mmseg - INFO - Summary:
2022-11-29 23:11:03,641 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 65.09 | 7.45 | 12.87 |
+-------+------+-------+
2022-11-29 23:11:03,643 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:11:03,643 - mmseg - INFO - Iter(val) [724]	aAcc: 0.6509, mIoU: 0.0745, mAcc: 0.1287, IoU.background: 0.7056, IoU.aeroplane: 0.0247, IoU.bicycle: 0.0000, IoU.bird: 0.0007, IoU.boat: 0.0014, IoU.bottle: 0.0017, IoU.bus: 0.0586, IoU.car: 0.1380, IoU.cat: 0.0630, IoU.chair: 0.0080, IoU.cow: 0.0140, IoU.diningtable: 0.0108, IoU.dog: 0.1249, IoU.horse: 0.0000, IoU.motorbike: 0.0927, IoU.person: 0.1771, IoU.pottedplant: 0.0013, IoU.sheep: 0.0909, IoU.sofa: 0.0000, IoU.train: 0.0239, IoU.tvmonitor: 0.0266, Acc.background: 0.8286, Acc.aeroplane: 0.0289, Acc.bicycle: 0.0000, Acc.bird: 0.0009, Acc.boat: 0.0024, Acc.bottle: 0.0023, Acc.bus: 0.2015, Acc.car: 0.2484, Acc.cat: 0.0858, Acc.chair: 0.0100, Acc.cow: 0.0199, Acc.diningtable: 0.0114, Acc.dog: 0.4148, Acc.horse: 0.0000, Acc.motorbike: 0.2587, Acc.person: 0.3557, Acc.pottedplant: 0.0016, Acc.sheep: 0.1159, Acc.sofa: 0.0000, Acc.train: 0.0299, Acc.tvmonitor: 0.0866
2022-11-29 23:11:17,837 - mmseg - INFO - Iter [25050/40000]	lr: 2.243e-05, eta: 1:14:23, time: 1.130, data_time: 0.853, memory: 5537, decode.loss_ce: 0.4582, decode.acc_seg: 81.4101, loss: 0.4582
2022-11-29 23:11:33,480 - mmseg - INFO - Iter [25100/40000]	lr: 2.235e-05, eta: 1:14:09, time: 0.313, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4800, decode.acc_seg: 81.6964, loss: 0.4800
2022-11-29 23:11:46,873 - mmseg - INFO - Iter [25150/40000]	lr: 2.228e-05, eta: 1:13:53, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4644, decode.acc_seg: 80.7841, loss: 0.4644
2022-11-29 23:12:00,306 - mmseg - INFO - Iter [25200/40000]	lr: 2.220e-05, eta: 1:13:37, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4647, decode.acc_seg: 84.3968, loss: 0.4647
2022-11-29 23:12:14,479 - mmseg - INFO - Iter [25250/40000]	lr: 2.213e-05, eta: 1:13:22, time: 0.283, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4887, decode.acc_seg: 80.9695, loss: 0.4887
2022-11-29 23:12:30,239 - mmseg - INFO - Iter [25300/40000]	lr: 2.205e-05, eta: 1:13:07, time: 0.315, data_time: 0.047, memory: 5537, decode.loss_ce: 0.4079, decode.acc_seg: 83.9829, loss: 0.4079
2022-11-29 23:12:43,674 - mmseg - INFO - Iter [25350/40000]	lr: 2.198e-05, eta: 1:12:52, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4580, decode.acc_seg: 83.9559, loss: 0.4580
2022-11-29 23:12:57,271 - mmseg - INFO - Iter [25400/40000]	lr: 2.190e-05, eta: 1:12:36, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4388, decode.acc_seg: 82.5783, loss: 0.4388
2022-11-29 23:13:12,912 - mmseg - INFO - Iter [25450/40000]	lr: 2.183e-05, eta: 1:12:21, time: 0.313, data_time: 0.047, memory: 5537, decode.loss_ce: 0.3810, decode.acc_seg: 81.6799, loss: 0.3810
2022-11-29 23:13:27,463 - mmseg - INFO - Iter [25500/40000]	lr: 2.175e-05, eta: 1:12:06, time: 0.291, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3630, decode.acc_seg: 87.1075, loss: 0.3630
2022-11-29 23:13:41,180 - mmseg - INFO - Iter [25550/40000]	lr: 2.168e-05, eta: 1:11:51, time: 0.274, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4221, decode.acc_seg: 82.7036, loss: 0.4221
2022-11-29 23:13:54,639 - mmseg - INFO - Iter [25600/40000]	lr: 2.160e-05, eta: 1:11:35, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4051, decode.acc_seg: 84.7856, loss: 0.4051
2022-11-29 23:14:10,155 - mmseg - INFO - Iter [25650/40000]	lr: 2.153e-05, eta: 1:11:20, time: 0.310, data_time: 0.047, memory: 5537, decode.loss_ce: 0.4033, decode.acc_seg: 83.5982, loss: 0.4033
2022-11-29 23:14:23,612 - mmseg - INFO - Iter [25700/40000]	lr: 2.145e-05, eta: 1:11:05, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5510, decode.acc_seg: 81.1236, loss: 0.5510
2022-11-29 23:14:37,066 - mmseg - INFO - Iter [25750/40000]	lr: 2.138e-05, eta: 1:10:49, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5555, decode.acc_seg: 80.4551, loss: 0.5555
2022-11-29 23:14:50,507 - mmseg - INFO - Iter [25800/40000]	lr: 2.130e-05, eta: 1:10:33, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3543, decode.acc_seg: 85.7458, loss: 0.3543
2022-11-29 23:15:06,277 - mmseg - INFO - Iter [25850/40000]	lr: 2.123e-05, eta: 1:10:19, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 0.3889, decode.acc_seg: 84.7859, loss: 0.3889
2022-11-29 23:15:19,833 - mmseg - INFO - Iter [25900/40000]	lr: 2.115e-05, eta: 1:10:03, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4906, decode.acc_seg: 80.9070, loss: 0.4906
2022-11-29 23:15:33,377 - mmseg - INFO - Iter [25950/40000]	lr: 2.108e-05, eta: 1:09:47, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3998, decode.acc_seg: 84.2418, loss: 0.3998
2022-11-29 23:15:48,963 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:15:48,963 - mmseg - INFO - Iter [26000/40000]	lr: 2.100e-05, eta: 1:09:33, time: 0.312, data_time: 0.047, memory: 5537, decode.loss_ce: 0.3468, decode.acc_seg: 85.4093, loss: 0.3468
2022-11-29 23:16:02,431 - mmseg - INFO - Iter [26050/40000]	lr: 2.093e-05, eta: 1:09:17, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3854, decode.acc_seg: 84.9503, loss: 0.3854
2022-11-29 23:16:15,999 - mmseg - INFO - Iter [26100/40000]	lr: 2.085e-05, eta: 1:09:02, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3488, decode.acc_seg: 86.1832, loss: 0.3488
2022-11-29 23:16:29,432 - mmseg - INFO - Iter [26150/40000]	lr: 2.078e-05, eta: 1:08:46, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4055, decode.acc_seg: 84.8242, loss: 0.4055
2022-11-29 23:16:45,233 - mmseg - INFO - Iter [26200/40000]	lr: 2.070e-05, eta: 1:08:32, time: 0.316, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5242, decode.acc_seg: 80.5058, loss: 0.5242
2022-11-29 23:16:58,806 - mmseg - INFO - Iter [26250/40000]	lr: 2.063e-05, eta: 1:08:16, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3733, decode.acc_seg: 82.5945, loss: 0.3733
2022-11-29 23:17:12,406 - mmseg - INFO - Iter [26300/40000]	lr: 2.055e-05, eta: 1:08:00, time: 0.272, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5410, decode.acc_seg: 79.3089, loss: 0.5410
2022-11-29 23:17:25,907 - mmseg - INFO - Iter [26350/40000]	lr: 2.048e-05, eta: 1:07:45, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5056, decode.acc_seg: 82.2285, loss: 0.5056
2022-11-29 23:17:42,512 - mmseg - INFO - Iter [26400/40000]	lr: 2.040e-05, eta: 1:07:31, time: 0.332, data_time: 0.049, memory: 5537, decode.loss_ce: 0.4582, decode.acc_seg: 82.4571, loss: 0.4582
2022-11-29 23:17:56,378 - mmseg - INFO - Iter [26450/40000]	lr: 2.033e-05, eta: 1:07:15, time: 0.277, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4011, decode.acc_seg: 84.4771, loss: 0.4011
2022-11-29 23:18:09,899 - mmseg - INFO - Iter [26500/40000]	lr: 2.025e-05, eta: 1:07:00, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5062, decode.acc_seg: 79.8084, loss: 0.5062
2022-11-29 23:18:25,556 - mmseg - INFO - Iter [26550/40000]	lr: 2.018e-05, eta: 1:06:45, time: 0.313, data_time: 0.049, memory: 5537, decode.loss_ce: 0.6135, decode.acc_seg: 78.1429, loss: 0.6135
2022-11-29 23:18:39,043 - mmseg - INFO - Iter [26600/40000]	lr: 2.010e-05, eta: 1:06:30, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4509, decode.acc_seg: 80.4064, loss: 0.4509
2022-11-29 23:18:52,565 - mmseg - INFO - Iter [26650/40000]	lr: 2.003e-05, eta: 1:06:14, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3269, decode.acc_seg: 86.1865, loss: 0.3269
2022-11-29 23:19:06,017 - mmseg - INFO - Iter [26700/40000]	lr: 1.995e-05, eta: 1:05:58, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4638, decode.acc_seg: 79.3077, loss: 0.4638
2022-11-29 23:19:22,357 - mmseg - INFO - Iter [26750/40000]	lr: 1.988e-05, eta: 1:05:44, time: 0.327, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4070, decode.acc_seg: 85.1240, loss: 0.4070
2022-11-29 23:19:35,914 - mmseg - INFO - Iter [26800/40000]	lr: 1.980e-05, eta: 1:05:29, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4017, decode.acc_seg: 82.3900, loss: 0.4017
2022-11-29 23:19:49,422 - mmseg - INFO - Iter [26850/40000]	lr: 1.973e-05, eta: 1:05:13, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3728, decode.acc_seg: 85.0087, loss: 0.3728
2022-11-29 23:20:02,910 - mmseg - INFO - Iter [26900/40000]	lr: 1.965e-05, eta: 1:04:58, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4520, decode.acc_seg: 82.6962, loss: 0.4520
2022-11-29 23:20:19,575 - mmseg - INFO - Iter [26950/40000]	lr: 1.958e-05, eta: 1:04:44, time: 0.333, data_time: 0.048, memory: 5537, decode.loss_ce: 0.3961, decode.acc_seg: 86.0178, loss: 0.3961
2022-11-29 23:20:35,792 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:20:35,792 - mmseg - INFO - Iter [27000/40000]	lr: 1.950e-05, eta: 1:04:29, time: 0.324, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4243, decode.acc_seg: 81.9984, loss: 0.4243
2022-11-29 23:20:52,001 - mmseg - INFO - Iter [27050/40000]	lr: 1.943e-05, eta: 1:04:15, time: 0.324, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2972, decode.acc_seg: 88.7790, loss: 0.2972
2022-11-29 23:21:07,987 - mmseg - INFO - Iter [27100/40000]	lr: 1.935e-05, eta: 1:04:01, time: 0.320, data_time: 0.047, memory: 5537, decode.loss_ce: 0.3744, decode.acc_seg: 83.6704, loss: 0.3744
2022-11-29 23:21:21,517 - mmseg - INFO - Iter [27150/40000]	lr: 1.928e-05, eta: 1:03:45, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4358, decode.acc_seg: 82.4008, loss: 0.4358
2022-11-29 23:21:35,066 - mmseg - INFO - Iter [27200/40000]	lr: 1.920e-05, eta: 1:03:30, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3390, decode.acc_seg: 85.2046, loss: 0.3390
2022-11-29 23:21:48,547 - mmseg - INFO - Iter [27250/40000]	lr: 1.913e-05, eta: 1:03:14, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5357, decode.acc_seg: 77.3598, loss: 0.5357
2022-11-29 23:22:04,154 - mmseg - INFO - Iter [27300/40000]	lr: 1.905e-05, eta: 1:03:00, time: 0.312, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4503, decode.acc_seg: 83.3749, loss: 0.4503
2022-11-29 23:22:17,550 - mmseg - INFO - Iter [27350/40000]	lr: 1.898e-05, eta: 1:02:44, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3041, decode.acc_seg: 86.9980, loss: 0.3041
2022-11-29 23:22:30,997 - mmseg - INFO - Iter [27400/40000]	lr: 1.890e-05, eta: 1:02:29, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3551, decode.acc_seg: 85.7273, loss: 0.3551
2022-11-29 23:22:44,381 - mmseg - INFO - Iter [27450/40000]	lr: 1.883e-05, eta: 1:02:13, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4338, decode.acc_seg: 84.2052, loss: 0.4338
2022-11-29 23:23:00,644 - mmseg - INFO - Iter [27500/40000]	lr: 1.875e-05, eta: 1:01:59, time: 0.325, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4053, decode.acc_seg: 84.3315, loss: 0.4053
2022-11-29 23:23:14,256 - mmseg - INFO - Iter [27550/40000]	lr: 1.868e-05, eta: 1:01:43, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3283, decode.acc_seg: 85.5112, loss: 0.3283
2022-11-29 23:23:27,728 - mmseg - INFO - Iter [27600/40000]	lr: 1.860e-05, eta: 1:01:28, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5230, decode.acc_seg: 81.3084, loss: 0.5230
2022-11-29 23:23:43,290 - mmseg - INFO - Iter [27650/40000]	lr: 1.853e-05, eta: 1:01:13, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 0.4257, decode.acc_seg: 83.1271, loss: 0.4257
2022-11-29 23:23:56,833 - mmseg - INFO - Iter [27700/40000]	lr: 1.845e-05, eta: 1:00:58, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3011, decode.acc_seg: 89.2744, loss: 0.3011
2022-11-29 23:24:10,290 - mmseg - INFO - Iter [27750/40000]	lr: 1.838e-05, eta: 1:00:42, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4160, decode.acc_seg: 82.5129, loss: 0.4160
2022-11-29 23:24:23,721 - mmseg - INFO - Iter [27800/40000]	lr: 1.830e-05, eta: 1:00:27, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3777, decode.acc_seg: 85.8562, loss: 0.3777
2022-11-29 23:24:39,742 - mmseg - INFO - Iter [27850/40000]	lr: 1.823e-05, eta: 1:00:12, time: 0.320, data_time: 0.048, memory: 5537, decode.loss_ce: 0.3144, decode.acc_seg: 86.4658, loss: 0.3144
2022-11-29 23:24:53,210 - mmseg - INFO - Iter [27900/40000]	lr: 1.815e-05, eta: 0:59:57, time: 0.269, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2948, decode.acc_seg: 87.4682, loss: 0.2948
2022-11-29 23:25:06,595 - mmseg - INFO - Iter [27950/40000]	lr: 1.808e-05, eta: 0:59:41, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3796, decode.acc_seg: 84.6073, loss: 0.3796
2022-11-29 23:25:22,085 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:25:22,085 - mmseg - INFO - Iter [28000/40000]	lr: 1.800e-05, eta: 0:59:27, time: 0.310, data_time: 0.047, memory: 5537, decode.loss_ce: 0.3192, decode.acc_seg: 86.4717, loss: 0.3192
2022-11-29 23:25:36,819 - mmseg - INFO - Iter [28050/40000]	lr: 1.793e-05, eta: 0:59:12, time: 0.295, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4195, decode.acc_seg: 85.5740, loss: 0.4195
2022-11-29 23:25:52,980 - mmseg - INFO - Iter [28100/40000]	lr: 1.785e-05, eta: 0:58:58, time: 0.323, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3636, decode.acc_seg: 84.8716, loss: 0.3636
2022-11-29 23:26:06,602 - mmseg - INFO - Iter [28150/40000]	lr: 1.778e-05, eta: 0:58:42, time: 0.272, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4444, decode.acc_seg: 83.5981, loss: 0.4444
2022-11-29 23:26:22,787 - mmseg - INFO - Iter [28200/40000]	lr: 1.770e-05, eta: 0:58:28, time: 0.324, data_time: 0.049, memory: 5537, decode.loss_ce: 0.3666, decode.acc_seg: 85.7927, loss: 0.3666
2022-11-29 23:26:36,525 - mmseg - INFO - Iter [28250/40000]	lr: 1.763e-05, eta: 0:58:13, time: 0.275, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4237, decode.acc_seg: 83.8356, loss: 0.4237
2022-11-29 23:26:50,049 - mmseg - INFO - Iter [28300/40000]	lr: 1.755e-05, eta: 0:57:57, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3575, decode.acc_seg: 83.8791, loss: 0.3575
2022-11-29 23:27:03,511 - mmseg - INFO - Iter [28350/40000]	lr: 1.748e-05, eta: 0:57:42, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4939, decode.acc_seg: 84.1863, loss: 0.4939
2022-11-29 23:27:19,095 - mmseg - INFO - Iter [28400/40000]	lr: 1.740e-05, eta: 0:57:27, time: 0.312, data_time: 0.048, memory: 5537, decode.loss_ce: 0.3685, decode.acc_seg: 85.0988, loss: 0.3685
2022-11-29 23:27:32,571 - mmseg - INFO - Iter [28450/40000]	lr: 1.733e-05, eta: 0:57:12, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3172, decode.acc_seg: 86.5825, loss: 0.3172
2022-11-29 23:27:45,978 - mmseg - INFO - Iter [28500/40000]	lr: 1.725e-05, eta: 0:56:56, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5093, decode.acc_seg: 77.5860, loss: 0.5093
2022-11-29 23:28:01,548 - mmseg - INFO - Iter [28550/40000]	lr: 1.718e-05, eta: 0:56:42, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 0.4285, decode.acc_seg: 82.3340, loss: 0.4285
2022-11-29 23:28:14,999 - mmseg - INFO - Iter [28600/40000]	lr: 1.710e-05, eta: 0:56:26, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4310, decode.acc_seg: 80.8174, loss: 0.4310
2022-11-29 23:28:28,472 - mmseg - INFO - Iter [28650/40000]	lr: 1.703e-05, eta: 0:56:11, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3467, decode.acc_seg: 87.0909, loss: 0.3467
2022-11-29 23:28:41,982 - mmseg - INFO - Iter [28700/40000]	lr: 1.695e-05, eta: 0:55:55, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3317, decode.acc_seg: 87.2505, loss: 0.3317
2022-11-29 23:28:58,308 - mmseg - INFO - Iter [28750/40000]	lr: 1.688e-05, eta: 0:55:41, time: 0.327, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4300, decode.acc_seg: 81.2507, loss: 0.4300
2022-11-29 23:29:12,348 - mmseg - INFO - Iter [28800/40000]	lr: 1.680e-05, eta: 0:55:26, time: 0.281, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2807, decode.acc_seg: 86.1243, loss: 0.2807
2022-11-29 23:29:25,847 - mmseg - INFO - Iter [28850/40000]	lr: 1.673e-05, eta: 0:55:11, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3128, decode.acc_seg: 86.8517, loss: 0.3128
2022-11-29 23:29:39,348 - mmseg - INFO - Iter [28900/40000]	lr: 1.665e-05, eta: 0:54:55, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2956, decode.acc_seg: 87.1585, loss: 0.2956
2022-11-29 23:29:54,887 - mmseg - INFO - Iter [28950/40000]	lr: 1.658e-05, eta: 0:54:41, time: 0.311, data_time: 0.047, memory: 5537, decode.loss_ce: 0.4283, decode.acc_seg: 82.9414, loss: 0.4283
2022-11-29 23:30:08,383 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:30:08,383 - mmseg - INFO - Iter [29000/40000]	lr: 1.650e-05, eta: 0:54:25, time: 0.270, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3733, decode.acc_seg: 85.3864, loss: 0.3733
2022-11-29 23:30:21,960 - mmseg - INFO - Iter [29050/40000]	lr: 1.643e-05, eta: 0:54:10, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3241, decode.acc_seg: 89.2663, loss: 0.3241
2022-11-29 23:30:37,806 - mmseg - INFO - Iter [29100/40000]	lr: 1.635e-05, eta: 0:53:56, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4135, decode.acc_seg: 84.1328, loss: 0.4135
2022-11-29 23:30:51,552 - mmseg - INFO - Iter [29150/40000]	lr: 1.628e-05, eta: 0:53:40, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4002, decode.acc_seg: 84.1324, loss: 0.4002
2022-11-29 23:31:05,059 - mmseg - INFO - Iter [29200/40000]	lr: 1.620e-05, eta: 0:53:25, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3691, decode.acc_seg: 87.1290, loss: 0.3691
2022-11-29 23:31:18,630 - mmseg - INFO - Iter [29250/40000]	lr: 1.613e-05, eta: 0:53:10, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3552, decode.acc_seg: 84.1833, loss: 0.3552
2022-11-29 23:31:35,001 - mmseg - INFO - Iter [29300/40000]	lr: 1.605e-05, eta: 0:52:55, time: 0.327, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2572, decode.acc_seg: 89.6252, loss: 0.2572
2022-11-29 23:31:48,435 - mmseg - INFO - Iter [29350/40000]	lr: 1.598e-05, eta: 0:52:40, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4016, decode.acc_seg: 83.2337, loss: 0.4016
2022-11-29 23:32:01,989 - mmseg - INFO - Iter [29400/40000]	lr: 1.590e-05, eta: 0:52:25, time: 0.271, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3257, decode.acc_seg: 86.6269, loss: 0.3257
2022-11-29 23:32:15,365 - mmseg - INFO - Iter [29450/40000]	lr: 1.583e-05, eta: 0:52:09, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3389, decode.acc_seg: 86.8520, loss: 0.3389
2022-11-29 23:32:31,339 - mmseg - INFO - Iter [29500/40000]	lr: 1.575e-05, eta: 0:51:55, time: 0.319, data_time: 0.047, memory: 5537, decode.loss_ce: 0.3866, decode.acc_seg: 85.1673, loss: 0.3866
2022-11-29 23:32:44,848 - mmseg - INFO - Iter [29550/40000]	lr: 1.568e-05, eta: 0:51:40, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3635, decode.acc_seg: 85.1489, loss: 0.3635
2022-11-29 23:32:58,269 - mmseg - INFO - Iter [29600/40000]	lr: 1.560e-05, eta: 0:51:24, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3920, decode.acc_seg: 84.3216, loss: 0.3920
2022-11-29 23:33:14,589 - mmseg - INFO - Iter [29650/40000]	lr: 1.553e-05, eta: 0:51:10, time: 0.326, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2576, decode.acc_seg: 89.5939, loss: 0.2576
2022-11-29 23:33:27,905 - mmseg - INFO - Iter [29700/40000]	lr: 1.545e-05, eta: 0:50:55, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3577, decode.acc_seg: 86.7281, loss: 0.3577
2022-11-29 23:33:41,241 - mmseg - INFO - Iter [29750/40000]	lr: 1.538e-05, eta: 0:50:39, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3716, decode.acc_seg: 83.3662, loss: 0.3716
2022-11-29 23:33:54,526 - mmseg - INFO - Iter [29800/40000]	lr: 1.530e-05, eta: 0:50:24, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4457, decode.acc_seg: 82.6835, loss: 0.4457
2022-11-29 23:34:09,901 - mmseg - INFO - Iter [29850/40000]	lr: 1.523e-05, eta: 0:50:09, time: 0.307, data_time: 0.047, memory: 5537, decode.loss_ce: 0.3128, decode.acc_seg: 87.5848, loss: 0.3128
2022-11-29 23:34:23,291 - mmseg - INFO - Iter [29900/40000]	lr: 1.515e-05, eta: 0:49:54, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3528, decode.acc_seg: 87.6384, loss: 0.3528
2022-11-29 23:34:36,608 - mmseg - INFO - Iter [29950/40000]	lr: 1.508e-05, eta: 0:49:39, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4142, decode.acc_seg: 81.8646, loss: 0.4142
2022-11-29 23:34:49,953 - mmseg - INFO - Saving checkpoint at 30000 iterations
2022-11-29 23:34:52,707 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:34:52,707 - mmseg - INFO - Iter [30000/40000]	lr: 1.500e-05, eta: 0:49:24, time: 0.322, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3009, decode.acc_seg: 89.0139, loss: 0.3009
2022-11-29 23:35:34,881 - mmseg - INFO - per class results:
2022-11-29 23:35:34,882 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 72.22 | 84.14 |
|  aeroplane  |  0.41 |  0.41 |
|   bicycle   |  0.71 |  0.79 |
|     bird    |  0.0  |  0.0  |
|     boat    |  0.03 |  0.04 |
|    bottle   |  0.0  |  0.0  |
|     bus     |  4.46 |  8.85 |
|     car     | 16.19 | 25.52 |
|     cat     |  8.92 | 17.07 |
|    chair    |  0.05 |  0.07 |
|     cow     |  4.14 |  7.52 |
| diningtable |  1.1  |  1.15 |
|     dog     |  9.79 | 40.82 |
|    horse    |  1.5  |  1.93 |
|  motorbike  | 11.26 | 16.42 |
|    person   | 18.26 | 31.57 |
| pottedplant |  2.05 |  3.55 |
|    sheep    |  3.62 |  3.92 |
|     sofa    |  1.08 |  1.11 |
|    train    |  7.89 | 18.37 |
|  tvmonitor  |  0.93 |  3.37 |
+-------------+-------+-------+
2022-11-29 23:35:34,882 - mmseg - INFO - Summary:
2022-11-29 23:35:34,882 - mmseg - INFO - 
+-------+------+------+
|  aAcc | mIoU | mAcc |
+-------+------+------+
| 65.91 | 7.84 | 12.7 |
+-------+------+------+
2022-11-29 23:35:34,884 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:35:34,884 - mmseg - INFO - Iter(val) [724]	aAcc: 0.6591, mIoU: 0.0784, mAcc: 0.1270, IoU.background: 0.7222, IoU.aeroplane: 0.0041, IoU.bicycle: 0.0071, IoU.bird: 0.0000, IoU.boat: 0.0003, IoU.bottle: 0.0000, IoU.bus: 0.0446, IoU.car: 0.1619, IoU.cat: 0.0892, IoU.chair: 0.0005, IoU.cow: 0.0414, IoU.diningtable: 0.0110, IoU.dog: 0.0979, IoU.horse: 0.0150, IoU.motorbike: 0.1126, IoU.person: 0.1826, IoU.pottedplant: 0.0205, IoU.sheep: 0.0362, IoU.sofa: 0.0108, IoU.train: 0.0789, IoU.tvmonitor: 0.0093, Acc.background: 0.8414, Acc.aeroplane: 0.0041, Acc.bicycle: 0.0079, Acc.bird: 0.0000, Acc.boat: 0.0004, Acc.bottle: 0.0000, Acc.bus: 0.0885, Acc.car: 0.2552, Acc.cat: 0.1707, Acc.chair: 0.0007, Acc.cow: 0.0752, Acc.diningtable: 0.0115, Acc.dog: 0.4082, Acc.horse: 0.0193, Acc.motorbike: 0.1642, Acc.person: 0.3157, Acc.pottedplant: 0.0355, Acc.sheep: 0.0392, Acc.sofa: 0.0111, Acc.train: 0.1837, Acc.tvmonitor: 0.0337
2022-11-29 23:35:52,594 - mmseg - INFO - Iter [30050/40000]	lr: 1.493e-05, eta: 0:49:24, time: 1.198, data_time: 0.891, memory: 5537, decode.loss_ce: 0.3027, decode.acc_seg: 89.0100, loss: 0.3027
2022-11-29 23:36:07,995 - mmseg - INFO - Iter [30100/40000]	lr: 1.485e-05, eta: 0:49:10, time: 0.308, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3761, decode.acc_seg: 83.2183, loss: 0.3761
2022-11-29 23:36:21,314 - mmseg - INFO - Iter [30150/40000]	lr: 1.478e-05, eta: 0:48:54, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2644, decode.acc_seg: 88.8749, loss: 0.2644
2022-11-29 23:36:36,811 - mmseg - INFO - Iter [30200/40000]	lr: 1.470e-05, eta: 0:48:40, time: 0.310, data_time: 0.048, memory: 5537, decode.loss_ce: 0.3349, decode.acc_seg: 85.3462, loss: 0.3349
2022-11-29 23:36:51,308 - mmseg - INFO - Iter [30250/40000]	lr: 1.463e-05, eta: 0:48:24, time: 0.290, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3872, decode.acc_seg: 86.5250, loss: 0.3872
2022-11-29 23:37:05,168 - mmseg - INFO - Iter [30300/40000]	lr: 1.455e-05, eta: 0:48:09, time: 0.277, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2547, decode.acc_seg: 89.3832, loss: 0.2547
2022-11-29 23:37:18,479 - mmseg - INFO - Iter [30350/40000]	lr: 1.448e-05, eta: 0:47:54, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3225, decode.acc_seg: 85.5027, loss: 0.3225
2022-11-29 23:37:34,451 - mmseg - INFO - Iter [30400/40000]	lr: 1.440e-05, eta: 0:47:39, time: 0.319, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4241, decode.acc_seg: 83.7054, loss: 0.4241
2022-11-29 23:37:48,659 - mmseg - INFO - Iter [30450/40000]	lr: 1.433e-05, eta: 0:47:24, time: 0.284, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2629, decode.acc_seg: 89.1854, loss: 0.2629
2022-11-29 23:38:02,023 - mmseg - INFO - Iter [30500/40000]	lr: 1.425e-05, eta: 0:47:09, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3271, decode.acc_seg: 87.6384, loss: 0.3271
2022-11-29 23:38:15,318 - mmseg - INFO - Iter [30550/40000]	lr: 1.418e-05, eta: 0:46:53, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3267, decode.acc_seg: 87.4345, loss: 0.3267
2022-11-29 23:38:30,746 - mmseg - INFO - Iter [30600/40000]	lr: 1.410e-05, eta: 0:46:39, time: 0.309, data_time: 0.048, memory: 5537, decode.loss_ce: 0.3741, decode.acc_seg: 83.8285, loss: 0.3741
2022-11-29 23:38:44,140 - mmseg - INFO - Iter [30650/40000]	lr: 1.403e-05, eta: 0:46:23, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5066, decode.acc_seg: 80.5887, loss: 0.5066
2022-11-29 23:38:57,418 - mmseg - INFO - Iter [30700/40000]	lr: 1.395e-05, eta: 0:46:08, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4561, decode.acc_seg: 83.2796, loss: 0.4561
2022-11-29 23:39:12,851 - mmseg - INFO - Iter [30750/40000]	lr: 1.388e-05, eta: 0:45:53, time: 0.309, data_time: 0.047, memory: 5537, decode.loss_ce: 0.4367, decode.acc_seg: 84.9923, loss: 0.4367
2022-11-29 23:39:26,213 - mmseg - INFO - Iter [30800/40000]	lr: 1.380e-05, eta: 0:45:38, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2914, decode.acc_seg: 87.3743, loss: 0.2914
2022-11-29 23:39:40,855 - mmseg - INFO - Iter [30850/40000]	lr: 1.373e-05, eta: 0:45:23, time: 0.293, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3758, decode.acc_seg: 85.2392, loss: 0.3758
2022-11-29 23:39:56,714 - mmseg - INFO - Iter [30900/40000]	lr: 1.365e-05, eta: 0:45:08, time: 0.317, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3557, decode.acc_seg: 83.7592, loss: 0.3557
2022-11-29 23:40:12,218 - mmseg - INFO - Iter [30950/40000]	lr: 1.358e-05, eta: 0:44:54, time: 0.310, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2567, decode.acc_seg: 89.3123, loss: 0.2567
2022-11-29 23:40:25,937 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:40:25,937 - mmseg - INFO - Iter [31000/40000]	lr: 1.350e-05, eta: 0:44:38, time: 0.274, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3112, decode.acc_seg: 87.5256, loss: 0.3112
2022-11-29 23:40:39,353 - mmseg - INFO - Iter [31050/40000]	lr: 1.343e-05, eta: 0:44:23, time: 0.268, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3143, decode.acc_seg: 86.1229, loss: 0.3143
2022-11-29 23:40:52,802 - mmseg - INFO - Iter [31100/40000]	lr: 1.335e-05, eta: 0:44:08, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2967, decode.acc_seg: 87.8277, loss: 0.2967
2022-11-29 23:41:08,208 - mmseg - INFO - Iter [31150/40000]	lr: 1.328e-05, eta: 0:43:53, time: 0.308, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2600, decode.acc_seg: 88.9704, loss: 0.2600
2022-11-29 23:41:21,536 - mmseg - INFO - Iter [31200/40000]	lr: 1.320e-05, eta: 0:43:38, time: 0.267, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3278, decode.acc_seg: 88.7228, loss: 0.3278
2022-11-29 23:41:34,941 - mmseg - INFO - Iter [31250/40000]	lr: 1.313e-05, eta: 0:43:23, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3343, decode.acc_seg: 84.8528, loss: 0.3343
2022-11-29 23:41:50,381 - mmseg - INFO - Iter [31300/40000]	lr: 1.305e-05, eta: 0:43:08, time: 0.309, data_time: 0.047, memory: 5537, decode.loss_ce: 0.1915, decode.acc_seg: 93.2611, loss: 0.1915
2022-11-29 23:42:03,829 - mmseg - INFO - Iter [31350/40000]	lr: 1.298e-05, eta: 0:42:53, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2825, decode.acc_seg: 88.8597, loss: 0.2825
2022-11-29 23:42:19,631 - mmseg - INFO - Iter [31400/40000]	lr: 1.290e-05, eta: 0:42:38, time: 0.316, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3758, decode.acc_seg: 83.6876, loss: 0.3758
2022-11-29 23:42:32,954 - mmseg - INFO - Iter [31450/40000]	lr: 1.283e-05, eta: 0:42:23, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2564, decode.acc_seg: 89.5737, loss: 0.2564
2022-11-29 23:42:48,666 - mmseg - INFO - Iter [31500/40000]	lr: 1.275e-05, eta: 0:42:08, time: 0.314, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2577, decode.acc_seg: 89.1002, loss: 0.2577
2022-11-29 23:43:02,254 - mmseg - INFO - Iter [31550/40000]	lr: 1.268e-05, eta: 0:41:53, time: 0.272, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3001, decode.acc_seg: 87.4727, loss: 0.3001
2022-11-29 23:43:15,531 - mmseg - INFO - Iter [31600/40000]	lr: 1.260e-05, eta: 0:41:37, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2556, decode.acc_seg: 89.7171, loss: 0.2556
2022-11-29 23:43:28,812 - mmseg - INFO - Iter [31650/40000]	lr: 1.253e-05, eta: 0:41:22, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3684, decode.acc_seg: 84.4278, loss: 0.3684
2022-11-29 23:43:44,822 - mmseg - INFO - Iter [31700/40000]	lr: 1.245e-05, eta: 0:41:08, time: 0.320, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2944, decode.acc_seg: 88.2285, loss: 0.2944
2022-11-29 23:43:58,845 - mmseg - INFO - Iter [31750/40000]	lr: 1.238e-05, eta: 0:40:53, time: 0.280, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3016, decode.acc_seg: 86.0207, loss: 0.3016
2022-11-29 23:44:12,088 - mmseg - INFO - Iter [31800/40000]	lr: 1.230e-05, eta: 0:40:37, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2524, decode.acc_seg: 89.3560, loss: 0.2524
2022-11-29 23:44:27,465 - mmseg - INFO - Iter [31850/40000]	lr: 1.223e-05, eta: 0:40:22, time: 0.307, data_time: 0.047, memory: 5537, decode.loss_ce: 0.3185, decode.acc_seg: 86.8208, loss: 0.3185
2022-11-29 23:44:40,827 - mmseg - INFO - Iter [31900/40000]	lr: 1.215e-05, eta: 0:40:07, time: 0.267, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5572, decode.acc_seg: 79.5757, loss: 0.5572
2022-11-29 23:44:54,123 - mmseg - INFO - Iter [31950/40000]	lr: 1.208e-05, eta: 0:39:52, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2992, decode.acc_seg: 88.6715, loss: 0.2992
2022-11-29 23:45:07,485 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:45:07,486 - mmseg - INFO - Iter [32000/40000]	lr: 1.200e-05, eta: 0:39:37, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3471, decode.acc_seg: 84.9028, loss: 0.3471
2022-11-29 23:45:23,219 - mmseg - INFO - Iter [32050/40000]	lr: 1.193e-05, eta: 0:39:22, time: 0.315, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2437, decode.acc_seg: 89.8063, loss: 0.2437
2022-11-29 23:45:37,313 - mmseg - INFO - Iter [32100/40000]	lr: 1.185e-05, eta: 0:39:07, time: 0.282, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2894, decode.acc_seg: 88.5682, loss: 0.2894
2022-11-29 23:45:50,634 - mmseg - INFO - Iter [32150/40000]	lr: 1.178e-05, eta: 0:38:52, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4028, decode.acc_seg: 82.7727, loss: 0.4028
2022-11-29 23:46:04,026 - mmseg - INFO - Iter [32200/40000]	lr: 1.170e-05, eta: 0:38:37, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3181, decode.acc_seg: 86.9486, loss: 0.3181
2022-11-29 23:46:20,741 - mmseg - INFO - Iter [32250/40000]	lr: 1.163e-05, eta: 0:38:22, time: 0.334, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2826, decode.acc_seg: 87.8608, loss: 0.2826
2022-11-29 23:46:34,288 - mmseg - INFO - Iter [32300/40000]	lr: 1.155e-05, eta: 0:38:07, time: 0.271, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2735, decode.acc_seg: 88.6977, loss: 0.2735
2022-11-29 23:46:47,614 - mmseg - INFO - Iter [32350/40000]	lr: 1.148e-05, eta: 0:37:52, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2975, decode.acc_seg: 87.8318, loss: 0.2975
2022-11-29 23:47:03,070 - mmseg - INFO - Iter [32400/40000]	lr: 1.140e-05, eta: 0:37:37, time: 0.309, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2365, decode.acc_seg: 89.2053, loss: 0.2365
2022-11-29 23:47:16,369 - mmseg - INFO - Iter [32450/40000]	lr: 1.133e-05, eta: 0:37:22, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2442, decode.acc_seg: 90.0034, loss: 0.2442
2022-11-29 23:47:29,758 - mmseg - INFO - Iter [32500/40000]	lr: 1.125e-05, eta: 0:37:07, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2495, decode.acc_seg: 88.4187, loss: 0.2495
2022-11-29 23:47:43,106 - mmseg - INFO - Iter [32550/40000]	lr: 1.118e-05, eta: 0:36:52, time: 0.267, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3405, decode.acc_seg: 85.7764, loss: 0.3405
2022-11-29 23:47:58,599 - mmseg - INFO - Iter [32600/40000]	lr: 1.110e-05, eta: 0:36:37, time: 0.310, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2078, decode.acc_seg: 91.6150, loss: 0.2078
2022-11-29 23:48:11,880 - mmseg - INFO - Iter [32650/40000]	lr: 1.103e-05, eta: 0:36:22, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2844, decode.acc_seg: 89.0854, loss: 0.2844
2022-11-29 23:48:25,174 - mmseg - INFO - Iter [32700/40000]	lr: 1.095e-05, eta: 0:36:06, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3081, decode.acc_seg: 87.7557, loss: 0.3081
2022-11-29 23:48:38,546 - mmseg - INFO - Iter [32750/40000]	lr: 1.088e-05, eta: 0:35:51, time: 0.267, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2450, decode.acc_seg: 90.0083, loss: 0.2450
2022-11-29 23:48:54,044 - mmseg - INFO - Iter [32800/40000]	lr: 1.080e-05, eta: 0:35:37, time: 0.310, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2467, decode.acc_seg: 88.5124, loss: 0.2467
2022-11-29 23:49:07,315 - mmseg - INFO - Iter [32850/40000]	lr: 1.073e-05, eta: 0:35:21, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2694, decode.acc_seg: 89.4953, loss: 0.2694
2022-11-29 23:49:20,645 - mmseg - INFO - Iter [32900/40000]	lr: 1.065e-05, eta: 0:35:06, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3022, decode.acc_seg: 86.1350, loss: 0.3022
2022-11-29 23:49:36,536 - mmseg - INFO - Iter [32950/40000]	lr: 1.058e-05, eta: 0:34:52, time: 0.318, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2780, decode.acc_seg: 89.0044, loss: 0.2780
2022-11-29 23:49:51,029 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:49:51,029 - mmseg - INFO - Iter [33000/40000]	lr: 1.050e-05, eta: 0:34:37, time: 0.290, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2909, decode.acc_seg: 88.0305, loss: 0.2909
2022-11-29 23:50:04,376 - mmseg - INFO - Iter [33050/40000]	lr: 1.043e-05, eta: 0:34:22, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3103, decode.acc_seg: 86.3500, loss: 0.3103
2022-11-29 23:50:17,754 - mmseg - INFO - Iter [33100/40000]	lr: 1.035e-05, eta: 0:34:06, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3916, decode.acc_seg: 85.6896, loss: 0.3916
2022-11-29 23:50:33,206 - mmseg - INFO - Iter [33150/40000]	lr: 1.028e-05, eta: 0:33:52, time: 0.309, data_time: 0.047, memory: 5537, decode.loss_ce: 0.3245, decode.acc_seg: 85.9779, loss: 0.3245
2022-11-29 23:50:47,882 - mmseg - INFO - Iter [33200/40000]	lr: 1.020e-05, eta: 0:33:37, time: 0.293, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2548, decode.acc_seg: 89.2304, loss: 0.2548
2022-11-29 23:51:01,236 - mmseg - INFO - Iter [33250/40000]	lr: 1.013e-05, eta: 0:33:22, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2151, decode.acc_seg: 90.8796, loss: 0.2151
2022-11-29 23:51:14,481 - mmseg - INFO - Iter [33300/40000]	lr: 1.005e-05, eta: 0:33:07, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3118, decode.acc_seg: 86.8282, loss: 0.3118
2022-11-29 23:51:30,491 - mmseg - INFO - Iter [33350/40000]	lr: 9.976e-06, eta: 0:32:52, time: 0.320, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2887, decode.acc_seg: 88.1540, loss: 0.2887
2022-11-29 23:51:44,392 - mmseg - INFO - Iter [33400/40000]	lr: 9.901e-06, eta: 0:32:37, time: 0.278, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2532, decode.acc_seg: 88.6052, loss: 0.2532
2022-11-29 23:51:57,794 - mmseg - INFO - Iter [33450/40000]	lr: 9.826e-06, eta: 0:32:22, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3108, decode.acc_seg: 86.6549, loss: 0.3108
2022-11-29 23:52:13,650 - mmseg - INFO - Iter [33500/40000]	lr: 9.752e-06, eta: 0:32:07, time: 0.317, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4296, decode.acc_seg: 82.0202, loss: 0.4296
2022-11-29 23:52:27,389 - mmseg - INFO - Iter [33550/40000]	lr: 9.676e-06, eta: 0:31:52, time: 0.275, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2516, decode.acc_seg: 89.3819, loss: 0.2516
2022-11-29 23:52:41,819 - mmseg - INFO - Iter [33600/40000]	lr: 9.601e-06, eta: 0:31:37, time: 0.289, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2350, decode.acc_seg: 89.8177, loss: 0.2350
2022-11-29 23:52:56,255 - mmseg - INFO - Iter [33650/40000]	lr: 9.527e-06, eta: 0:31:22, time: 0.289, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2971, decode.acc_seg: 87.0288, loss: 0.2971
2022-11-29 23:53:12,074 - mmseg - INFO - Iter [33700/40000]	lr: 9.452e-06, eta: 0:31:08, time: 0.316, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2182, decode.acc_seg: 91.1333, loss: 0.2182
2022-11-29 23:53:25,503 - mmseg - INFO - Iter [33750/40000]	lr: 9.377e-06, eta: 0:30:53, time: 0.269, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2480, decode.acc_seg: 89.4114, loss: 0.2480
2022-11-29 23:53:38,831 - mmseg - INFO - Iter [33800/40000]	lr: 9.301e-06, eta: 0:30:38, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3013, decode.acc_seg: 86.0121, loss: 0.3013
2022-11-29 23:53:52,204 - mmseg - INFO - Iter [33850/40000]	lr: 9.227e-06, eta: 0:30:22, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3214, decode.acc_seg: 87.2359, loss: 0.3214
2022-11-29 23:54:07,683 - mmseg - INFO - Iter [33900/40000]	lr: 9.152e-06, eta: 0:30:08, time: 0.310, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2297, decode.acc_seg: 89.7147, loss: 0.2297
2022-11-29 23:54:21,035 - mmseg - INFO - Iter [33950/40000]	lr: 9.077e-06, eta: 0:29:53, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3302, decode.acc_seg: 86.3027, loss: 0.3302
2022-11-29 23:54:34,414 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:54:34,414 - mmseg - INFO - Iter [34000/40000]	lr: 9.001e-06, eta: 0:29:38, time: 0.268, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2559, decode.acc_seg: 89.2960, loss: 0.2559
2022-11-29 23:54:49,994 - mmseg - INFO - Iter [34050/40000]	lr: 8.926e-06, eta: 0:29:23, time: 0.312, data_time: 0.048, memory: 5537, decode.loss_ce: 0.1931, decode.acc_seg: 90.6126, loss: 0.1931
2022-11-29 23:55:03,493 - mmseg - INFO - Iter [34100/40000]	lr: 8.852e-06, eta: 0:29:08, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2369, decode.acc_seg: 88.7115, loss: 0.2369
2022-11-29 23:55:16,615 - mmseg - INFO - Iter [34150/40000]	lr: 8.777e-06, eta: 0:28:53, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2515, decode.acc_seg: 91.9911, loss: 0.2515
2022-11-29 23:55:29,526 - mmseg - INFO - Iter [34200/40000]	lr: 8.701e-06, eta: 0:28:38, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2518, decode.acc_seg: 89.4194, loss: 0.2518
2022-11-29 23:55:44,588 - mmseg - INFO - Iter [34250/40000]	lr: 8.626e-06, eta: 0:28:23, time: 0.301, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2465, decode.acc_seg: 89.1902, loss: 0.2465
2022-11-29 23:55:57,496 - mmseg - INFO - Iter [34300/40000]	lr: 8.552e-06, eta: 0:28:08, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2485, decode.acc_seg: 90.4093, loss: 0.2485
2022-11-29 23:56:10,427 - mmseg - INFO - Iter [34350/40000]	lr: 8.477e-06, eta: 0:27:53, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3482, decode.acc_seg: 88.3354, loss: 0.3482
2022-11-29 23:56:23,289 - mmseg - INFO - Iter [34400/40000]	lr: 8.401e-06, eta: 0:27:37, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2956, decode.acc_seg: 87.3805, loss: 0.2956
2022-11-29 23:56:39,098 - mmseg - INFO - Iter [34450/40000]	lr: 8.326e-06, eta: 0:27:23, time: 0.316, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2629, decode.acc_seg: 89.4006, loss: 0.2629
2022-11-29 23:56:52,017 - mmseg - INFO - Iter [34500/40000]	lr: 8.252e-06, eta: 0:27:08, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3183, decode.acc_seg: 88.0783, loss: 0.3183
2022-11-29 23:57:04,907 - mmseg - INFO - Iter [34550/40000]	lr: 8.177e-06, eta: 0:26:53, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3587, decode.acc_seg: 88.1691, loss: 0.3587
2022-11-29 23:57:19,883 - mmseg - INFO - Iter [34600/40000]	lr: 8.101e-06, eta: 0:26:38, time: 0.300, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2530, decode.acc_seg: 90.5664, loss: 0.2530
2022-11-29 23:57:32,771 - mmseg - INFO - Iter [34650/40000]	lr: 8.026e-06, eta: 0:26:23, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2539, decode.acc_seg: 90.3183, loss: 0.2539
2022-11-29 23:57:45,646 - mmseg - INFO - Iter [34700/40000]	lr: 7.952e-06, eta: 0:26:08, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3503, decode.acc_seg: 84.9824, loss: 0.3503
2022-11-29 23:57:58,510 - mmseg - INFO - Iter [34750/40000]	lr: 7.877e-06, eta: 0:25:53, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2143, decode.acc_seg: 91.1483, loss: 0.2143
2022-11-29 23:58:13,522 - mmseg - INFO - Iter [34800/40000]	lr: 7.801e-06, eta: 0:25:38, time: 0.300, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2607, decode.acc_seg: 89.9044, loss: 0.2607
2022-11-29 23:58:26,412 - mmseg - INFO - Iter [34850/40000]	lr: 7.726e-06, eta: 0:25:23, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2993, decode.acc_seg: 88.5182, loss: 0.2993
2022-11-29 23:58:39,312 - mmseg - INFO - Iter [34900/40000]	lr: 7.651e-06, eta: 0:25:08, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2461, decode.acc_seg: 90.2255, loss: 0.2461
2022-11-29 23:58:52,247 - mmseg - INFO - Iter [34950/40000]	lr: 7.577e-06, eta: 0:24:53, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2979, decode.acc_seg: 87.7876, loss: 0.2979
2022-11-29 23:59:07,278 - mmseg - INFO - Saving checkpoint at 35000 iterations
2022-11-29 23:59:09,108 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:59:09,108 - mmseg - INFO - Iter [35000/40000]	lr: 7.502e-06, eta: 0:24:38, time: 0.337, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2066, decode.acc_seg: 91.9057, loss: 0.2066
2022-11-29 23:59:50,293 - mmseg - INFO - per class results:
2022-11-29 23:59:50,294 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 73.34 | 84.57 |
|  aeroplane  |  1.31 |  1.46 |
|   bicycle   |  0.77 |  0.85 |
|     bird    |  0.03 |  0.03 |
|     boat    |  1.21 |  1.69 |
|    bottle   |  0.0  |  0.0  |
|     bus     |  2.66 |  4.13 |
|     car     |  16.4 |  24.1 |
|     cat     |  5.12 |  6.42 |
|    chair    |  0.0  |  0.0  |
|     cow     |  2.27 |  3.65 |
| diningtable |  0.04 |  0.04 |
|     dog     | 13.73 | 44.13 |
|    horse    |  2.09 |  2.9  |
|  motorbike  | 10.79 | 50.41 |
|    person   | 17.62 |  43.5 |
| pottedplant |  0.21 |  0.22 |
|    sheep    |  8.09 | 12.79 |
|     sofa    |  1.6  |  1.61 |
|    train    |  2.22 |  3.44 |
|  tvmonitor  |  2.62 |  4.64 |
+-------------+-------+-------+
2022-11-29 23:59:50,294 - mmseg - INFO - Summary:
2022-11-29 23:59:50,294 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 66.77 | 7.72 | 13.84 |
+-------+------+-------+
2022-11-29 23:59:50,296 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-29 23:59:50,296 - mmseg - INFO - Iter(val) [724]	aAcc: 0.6677, mIoU: 0.0772, mAcc: 0.1384, IoU.background: 0.7334, IoU.aeroplane: 0.0131, IoU.bicycle: 0.0077, IoU.bird: 0.0003, IoU.boat: 0.0121, IoU.bottle: 0.0000, IoU.bus: 0.0266, IoU.car: 0.1640, IoU.cat: 0.0512, IoU.chair: 0.0000, IoU.cow: 0.0227, IoU.diningtable: 0.0004, IoU.dog: 0.1373, IoU.horse: 0.0209, IoU.motorbike: 0.1079, IoU.person: 0.1762, IoU.pottedplant: 0.0021, IoU.sheep: 0.0809, IoU.sofa: 0.0160, IoU.train: 0.0222, IoU.tvmonitor: 0.0262, Acc.background: 0.8457, Acc.aeroplane: 0.0146, Acc.bicycle: 0.0085, Acc.bird: 0.0003, Acc.boat: 0.0169, Acc.bottle: 0.0000, Acc.bus: 0.0413, Acc.car: 0.2410, Acc.cat: 0.0642, Acc.chair: 0.0000, Acc.cow: 0.0365, Acc.diningtable: 0.0004, Acc.dog: 0.4413, Acc.horse: 0.0290, Acc.motorbike: 0.5041, Acc.person: 0.4350, Acc.pottedplant: 0.0022, Acc.sheep: 0.1279, Acc.sofa: 0.0161, Acc.train: 0.0344, Acc.tvmonitor: 0.0464
2022-11-30 00:00:04,551 - mmseg - INFO - Iter [35050/40000]	lr: 7.426e-06, eta: 0:24:29, time: 1.109, data_time: 0.829, memory: 5537, decode.loss_ce: 0.2922, decode.acc_seg: 87.9821, loss: 0.2922
2022-11-30 00:00:17,442 - mmseg - INFO - Iter [35100/40000]	lr: 7.351e-06, eta: 0:24:14, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2385, decode.acc_seg: 90.2352, loss: 0.2385
2022-11-30 00:00:32,527 - mmseg - INFO - Iter [35150/40000]	lr: 7.277e-06, eta: 0:23:59, time: 0.302, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2470, decode.acc_seg: 87.6773, loss: 0.2470
2022-11-30 00:00:45,438 - mmseg - INFO - Iter [35200/40000]	lr: 7.202e-06, eta: 0:23:44, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2285, decode.acc_seg: 89.9693, loss: 0.2285
2022-11-30 00:00:58,338 - mmseg - INFO - Iter [35250/40000]	lr: 7.126e-06, eta: 0:23:29, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2807, decode.acc_seg: 89.1878, loss: 0.2807
2022-11-30 00:01:11,335 - mmseg - INFO - Iter [35300/40000]	lr: 7.051e-06, eta: 0:23:14, time: 0.260, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2723, decode.acc_seg: 87.2613, loss: 0.2723
2022-11-30 00:01:26,317 - mmseg - INFO - Iter [35350/40000]	lr: 6.977e-06, eta: 0:22:59, time: 0.300, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2321, decode.acc_seg: 91.7410, loss: 0.2321
2022-11-30 00:01:39,176 - mmseg - INFO - Iter [35400/40000]	lr: 6.902e-06, eta: 0:22:44, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3453, decode.acc_seg: 86.1305, loss: 0.3453
2022-11-30 00:01:52,097 - mmseg - INFO - Iter [35450/40000]	lr: 6.826e-06, eta: 0:22:29, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2261, decode.acc_seg: 90.3574, loss: 0.2261
2022-11-30 00:02:05,005 - mmseg - INFO - Iter [35500/40000]	lr: 6.751e-06, eta: 0:22:14, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2554, decode.acc_seg: 89.7049, loss: 0.2554
2022-11-30 00:02:20,037 - mmseg - INFO - Iter [35550/40000]	lr: 6.677e-06, eta: 0:21:59, time: 0.301, data_time: 0.046, memory: 5537, decode.loss_ce: 0.3298, decode.acc_seg: 86.4400, loss: 0.3298
2022-11-30 00:02:32,976 - mmseg - INFO - Iter [35600/40000]	lr: 6.602e-06, eta: 0:21:44, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2656, decode.acc_seg: 88.4262, loss: 0.2656
2022-11-30 00:02:45,899 - mmseg - INFO - Iter [35650/40000]	lr: 6.526e-06, eta: 0:21:29, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.1997, decode.acc_seg: 91.8852, loss: 0.1997
2022-11-30 00:03:00,837 - mmseg - INFO - Iter [35700/40000]	lr: 6.451e-06, eta: 0:21:14, time: 0.299, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2526, decode.acc_seg: 88.9345, loss: 0.2526
2022-11-30 00:03:13,707 - mmseg - INFO - Iter [35750/40000]	lr: 6.377e-06, eta: 0:20:59, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2894, decode.acc_seg: 88.1539, loss: 0.2894
2022-11-30 00:03:26,574 - mmseg - INFO - Iter [35800/40000]	lr: 6.302e-06, eta: 0:20:44, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2227, decode.acc_seg: 91.4077, loss: 0.2227
2022-11-30 00:03:39,509 - mmseg - INFO - Iter [35850/40000]	lr: 6.226e-06, eta: 0:20:29, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2550, decode.acc_seg: 90.1873, loss: 0.2550
2022-11-30 00:03:54,619 - mmseg - INFO - Iter [35900/40000]	lr: 6.151e-06, eta: 0:20:14, time: 0.302, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2765, decode.acc_seg: 88.5673, loss: 0.2765
2022-11-30 00:04:07,539 - mmseg - INFO - Iter [35950/40000]	lr: 6.077e-06, eta: 0:19:59, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3014, decode.acc_seg: 87.6706, loss: 0.3014
2022-11-30 00:04:20,448 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-30 00:04:20,448 - mmseg - INFO - Iter [36000/40000]	lr: 6.002e-06, eta: 0:19:44, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2816, decode.acc_seg: 89.2721, loss: 0.2816
2022-11-30 00:04:33,372 - mmseg - INFO - Iter [36050/40000]	lr: 5.926e-06, eta: 0:19:29, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3237, decode.acc_seg: 87.8842, loss: 0.3237
2022-11-30 00:04:48,413 - mmseg - INFO - Iter [36100/40000]	lr: 5.851e-06, eta: 0:19:14, time: 0.301, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2704, decode.acc_seg: 87.0622, loss: 0.2704
2022-11-30 00:05:01,360 - mmseg - INFO - Iter [36150/40000]	lr: 5.777e-06, eta: 0:18:59, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2904, decode.acc_seg: 89.5586, loss: 0.2904
2022-11-30 00:05:14,268 - mmseg - INFO - Iter [36200/40000]	lr: 5.702e-06, eta: 0:18:44, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2157, decode.acc_seg: 91.2847, loss: 0.2157
2022-11-30 00:05:29,288 - mmseg - INFO - Iter [36250/40000]	lr: 5.627e-06, eta: 0:18:30, time: 0.300, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2464, decode.acc_seg: 91.4223, loss: 0.2464
2022-11-30 00:05:42,132 - mmseg - INFO - Iter [36300/40000]	lr: 5.551e-06, eta: 0:18:15, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2335, decode.acc_seg: 91.3872, loss: 0.2335
2022-11-30 00:05:55,039 - mmseg - INFO - Iter [36350/40000]	lr: 5.476e-06, eta: 0:18:00, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3083, decode.acc_seg: 87.8478, loss: 0.3083
2022-11-30 00:06:07,922 - mmseg - INFO - Iter [36400/40000]	lr: 5.402e-06, eta: 0:17:45, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2243, decode.acc_seg: 89.6479, loss: 0.2243
2022-11-30 00:06:23,067 - mmseg - INFO - Iter [36450/40000]	lr: 5.327e-06, eta: 0:17:30, time: 0.303, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2301, decode.acc_seg: 90.7998, loss: 0.2301
2022-11-30 00:06:35,967 - mmseg - INFO - Iter [36500/40000]	lr: 5.251e-06, eta: 0:17:15, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2916, decode.acc_seg: 88.4428, loss: 0.2916
2022-11-30 00:06:48,859 - mmseg - INFO - Iter [36550/40000]	lr: 5.176e-06, eta: 0:17:00, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2671, decode.acc_seg: 89.5689, loss: 0.2671
2022-11-30 00:07:01,720 - mmseg - INFO - Iter [36600/40000]	lr: 5.102e-06, eta: 0:16:45, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2902, decode.acc_seg: 87.7837, loss: 0.2902
2022-11-30 00:07:16,762 - mmseg - INFO - Iter [36650/40000]	lr: 5.027e-06, eta: 0:16:30, time: 0.301, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2676, decode.acc_seg: 90.7715, loss: 0.2676
2022-11-30 00:07:29,652 - mmseg - INFO - Iter [36700/40000]	lr: 4.951e-06, eta: 0:16:15, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3078, decode.acc_seg: 88.9145, loss: 0.3078
2022-11-30 00:07:42,543 - mmseg - INFO - Iter [36750/40000]	lr: 4.876e-06, eta: 0:16:00, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2350, decode.acc_seg: 88.6940, loss: 0.2350
2022-11-30 00:07:57,531 - mmseg - INFO - Iter [36800/40000]	lr: 4.802e-06, eta: 0:15:46, time: 0.300, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2739, decode.acc_seg: 85.5662, loss: 0.2739
2022-11-30 00:08:10,448 - mmseg - INFO - Iter [36850/40000]	lr: 4.727e-06, eta: 0:15:31, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2029, decode.acc_seg: 90.9349, loss: 0.2029
2022-11-30 00:08:23,466 - mmseg - INFO - Iter [36900/40000]	lr: 4.651e-06, eta: 0:15:16, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3097, decode.acc_seg: 89.6430, loss: 0.3097
2022-11-30 00:08:36,492 - mmseg - INFO - Iter [36950/40000]	lr: 4.576e-06, eta: 0:15:01, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2611, decode.acc_seg: 89.2506, loss: 0.2611
2022-11-30 00:08:51,726 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-30 00:08:51,726 - mmseg - INFO - Iter [37000/40000]	lr: 4.502e-06, eta: 0:14:46, time: 0.305, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2519, decode.acc_seg: 89.5495, loss: 0.2519
2022-11-30 00:09:04,641 - mmseg - INFO - Iter [37050/40000]	lr: 4.427e-06, eta: 0:14:31, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3039, decode.acc_seg: 86.7378, loss: 0.3039
2022-11-30 00:09:17,490 - mmseg - INFO - Iter [37100/40000]	lr: 4.351e-06, eta: 0:14:16, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2186, decode.acc_seg: 90.5912, loss: 0.2186
2022-11-30 00:09:32,494 - mmseg - INFO - Iter [37150/40000]	lr: 4.276e-06, eta: 0:14:01, time: 0.300, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2427, decode.acc_seg: 90.1365, loss: 0.2427
2022-11-30 00:09:45,447 - mmseg - INFO - Iter [37200/40000]	lr: 4.202e-06, eta: 0:13:46, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2194, decode.acc_seg: 91.5729, loss: 0.2194
2022-11-30 00:09:58,388 - mmseg - INFO - Iter [37250/40000]	lr: 4.127e-06, eta: 0:13:32, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3076, decode.acc_seg: 87.7601, loss: 0.3076
2022-11-30 00:10:11,321 - mmseg - INFO - Iter [37300/40000]	lr: 4.051e-06, eta: 0:13:17, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2248, decode.acc_seg: 92.0901, loss: 0.2248
2022-11-30 00:10:26,450 - mmseg - INFO - Iter [37350/40000]	lr: 3.976e-06, eta: 0:13:02, time: 0.303, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2973, decode.acc_seg: 89.3524, loss: 0.2973
2022-11-30 00:10:39,408 - mmseg - INFO - Iter [37400/40000]	lr: 3.901e-06, eta: 0:12:47, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2098, decode.acc_seg: 91.1034, loss: 0.2098
2022-11-30 00:10:52,305 - mmseg - INFO - Iter [37450/40000]	lr: 3.827e-06, eta: 0:12:32, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2191, decode.acc_seg: 89.3127, loss: 0.2191
2022-11-30 00:11:05,210 - mmseg - INFO - Iter [37500/40000]	lr: 3.752e-06, eta: 0:12:17, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2161, decode.acc_seg: 91.9720, loss: 0.2161
2022-11-30 00:11:21,959 - mmseg - INFO - Iter [37550/40000]	lr: 3.676e-06, eta: 0:12:03, time: 0.335, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2392, decode.acc_seg: 91.3678, loss: 0.2392
2022-11-30 00:11:37,350 - mmseg - INFO - Iter [37600/40000]	lr: 3.601e-06, eta: 0:11:48, time: 0.308, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2060, decode.acc_seg: 91.6657, loss: 0.2060
2022-11-30 00:11:52,774 - mmseg - INFO - Iter [37650/40000]	lr: 3.527e-06, eta: 0:11:33, time: 0.308, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2650, decode.acc_seg: 87.2621, loss: 0.2650
2022-11-30 00:12:07,979 - mmseg - INFO - Iter [37700/40000]	lr: 3.452e-06, eta: 0:11:18, time: 0.304, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2280, decode.acc_seg: 90.9867, loss: 0.2280
2022-11-30 00:12:20,900 - mmseg - INFO - Iter [37750/40000]	lr: 3.376e-06, eta: 0:11:04, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3382, decode.acc_seg: 85.7842, loss: 0.3382
2022-11-30 00:12:33,750 - mmseg - INFO - Iter [37800/40000]	lr: 3.301e-06, eta: 0:10:49, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.1956, decode.acc_seg: 92.8603, loss: 0.1956
2022-11-30 00:12:46,651 - mmseg - INFO - Iter [37850/40000]	lr: 3.227e-06, eta: 0:10:34, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2737, decode.acc_seg: 88.3107, loss: 0.2737
2022-11-30 00:13:01,643 - mmseg - INFO - Iter [37900/40000]	lr: 3.152e-06, eta: 0:10:19, time: 0.300, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2117, decode.acc_seg: 89.8302, loss: 0.2117
2022-11-30 00:13:14,524 - mmseg - INFO - Iter [37950/40000]	lr: 3.076e-06, eta: 0:10:04, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.1892, decode.acc_seg: 92.9119, loss: 0.1892
2022-11-30 00:13:27,418 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-30 00:13:27,418 - mmseg - INFO - Iter [38000/40000]	lr: 3.001e-06, eta: 0:09:49, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3366, decode.acc_seg: 88.6141, loss: 0.3366
2022-11-30 00:13:40,356 - mmseg - INFO - Iter [38050/40000]	lr: 2.927e-06, eta: 0:09:35, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2067, decode.acc_seg: 90.7970, loss: 0.2067
2022-11-30 00:13:55,345 - mmseg - INFO - Iter [38100/40000]	lr: 2.852e-06, eta: 0:09:20, time: 0.300, data_time: 0.046, memory: 5537, decode.loss_ce: 0.1852, decode.acc_seg: 91.2207, loss: 0.1852
2022-11-30 00:14:08,210 - mmseg - INFO - Iter [38150/40000]	lr: 2.776e-06, eta: 0:09:05, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2116, decode.acc_seg: 91.2134, loss: 0.2116
2022-11-30 00:14:21,079 - mmseg - INFO - Iter [38200/40000]	lr: 2.701e-06, eta: 0:08:50, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2878, decode.acc_seg: 88.4747, loss: 0.2878
2022-11-30 00:14:36,055 - mmseg - INFO - Iter [38250/40000]	lr: 2.627e-06, eta: 0:08:35, time: 0.300, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2401, decode.acc_seg: 90.7988, loss: 0.2401
2022-11-30 00:14:48,983 - mmseg - INFO - Iter [38300/40000]	lr: 2.552e-06, eta: 0:08:21, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2265, decode.acc_seg: 90.6140, loss: 0.2265
2022-11-30 00:15:01,933 - mmseg - INFO - Iter [38350/40000]	lr: 2.476e-06, eta: 0:08:06, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2982, decode.acc_seg: 87.4497, loss: 0.2982
2022-11-30 00:15:14,853 - mmseg - INFO - Iter [38400/40000]	lr: 2.401e-06, eta: 0:07:51, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2237, decode.acc_seg: 90.2680, loss: 0.2237
2022-11-30 00:15:29,934 - mmseg - INFO - Iter [38450/40000]	lr: 2.327e-06, eta: 0:07:36, time: 0.302, data_time: 0.046, memory: 5537, decode.loss_ce: 0.1924, decode.acc_seg: 92.0930, loss: 0.1924
2022-11-30 00:15:42,871 - mmseg - INFO - Iter [38500/40000]	lr: 2.252e-06, eta: 0:07:21, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3271, decode.acc_seg: 89.8784, loss: 0.3271
2022-11-30 00:15:56,404 - mmseg - INFO - Iter [38550/40000]	lr: 2.176e-06, eta: 0:07:07, time: 0.271, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2811, decode.acc_seg: 88.5943, loss: 0.2811
2022-11-30 00:16:11,115 - mmseg - INFO - Iter [38600/40000]	lr: 2.101e-06, eta: 0:06:52, time: 0.294, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2652, decode.acc_seg: 89.6915, loss: 0.2652
2022-11-30 00:16:26,139 - mmseg - INFO - Iter [38650/40000]	lr: 2.026e-06, eta: 0:06:37, time: 0.300, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2014, decode.acc_seg: 91.5456, loss: 0.2014
2022-11-30 00:16:39,104 - mmseg - INFO - Iter [38700/40000]	lr: 1.952e-06, eta: 0:06:22, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2027, decode.acc_seg: 90.5720, loss: 0.2027
2022-11-30 00:16:51,991 - mmseg - INFO - Iter [38750/40000]	lr: 1.877e-06, eta: 0:06:08, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2893, decode.acc_seg: 88.3270, loss: 0.2893
2022-11-30 00:17:06,991 - mmseg - INFO - Iter [38800/40000]	lr: 1.801e-06, eta: 0:05:53, time: 0.300, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2444, decode.acc_seg: 88.6312, loss: 0.2444
2022-11-30 00:17:19,831 - mmseg - INFO - Iter [38850/40000]	lr: 1.726e-06, eta: 0:05:38, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2337, decode.acc_seg: 90.5290, loss: 0.2337
2022-11-30 00:17:32,745 - mmseg - INFO - Iter [38900/40000]	lr: 1.652e-06, eta: 0:05:23, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2099, decode.acc_seg: 92.0637, loss: 0.2099
2022-11-30 00:17:45,649 - mmseg - INFO - Iter [38950/40000]	lr: 1.577e-06, eta: 0:05:09, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2803, decode.acc_seg: 88.3654, loss: 0.2803
2022-11-30 00:18:00,657 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-30 00:18:00,657 - mmseg - INFO - Iter [39000/40000]	lr: 1.501e-06, eta: 0:04:54, time: 0.300, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2274, decode.acc_seg: 90.5509, loss: 0.2274
2022-11-30 00:18:13,517 - mmseg - INFO - Iter [39050/40000]	lr: 1.426e-06, eta: 0:04:39, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2177, decode.acc_seg: 91.5762, loss: 0.2177
2022-11-30 00:18:26,364 - mmseg - INFO - Iter [39100/40000]	lr: 1.352e-06, eta: 0:04:24, time: 0.257, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2720, decode.acc_seg: 89.2432, loss: 0.2720
2022-11-30 00:18:39,263 - mmseg - INFO - Iter [39150/40000]	lr: 1.277e-06, eta: 0:04:10, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.1912, decode.acc_seg: 90.7408, loss: 0.1912
2022-11-30 00:18:54,426 - mmseg - INFO - Iter [39200/40000]	lr: 1.201e-06, eta: 0:03:55, time: 0.303, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2350, decode.acc_seg: 90.3644, loss: 0.2350
2022-11-30 00:19:07,343 - mmseg - INFO - Iter [39250/40000]	lr: 1.126e-06, eta: 0:03:40, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2528, decode.acc_seg: 89.1138, loss: 0.2528
2022-11-30 00:19:20,230 - mmseg - INFO - Iter [39300/40000]	lr: 1.052e-06, eta: 0:03:25, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.1860, decode.acc_seg: 92.4393, loss: 0.1860
2022-11-30 00:19:35,344 - mmseg - INFO - Iter [39350/40000]	lr: 9.765e-07, eta: 0:03:11, time: 0.302, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2585, decode.acc_seg: 89.6007, loss: 0.2585
2022-11-30 00:19:49,376 - mmseg - INFO - Iter [39400/40000]	lr: 9.015e-07, eta: 0:02:56, time: 0.281, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2047, decode.acc_seg: 91.6398, loss: 0.2047
2022-11-30 00:20:04,823 - mmseg - INFO - Iter [39450/40000]	lr: 8.265e-07, eta: 0:02:41, time: 0.309, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2170, decode.acc_seg: 91.3985, loss: 0.2170
2022-11-30 00:20:20,300 - mmseg - INFO - Iter [39500/40000]	lr: 7.515e-07, eta: 0:02:27, time: 0.310, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2383, decode.acc_seg: 90.1497, loss: 0.2383
2022-11-30 00:20:36,680 - mmseg - INFO - Iter [39550/40000]	lr: 6.765e-07, eta: 0:02:12, time: 0.328, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2280, decode.acc_seg: 90.2025, loss: 0.2280
2022-11-30 00:20:49,615 - mmseg - INFO - Iter [39600/40000]	lr: 6.015e-07, eta: 0:01:57, time: 0.259, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2071, decode.acc_seg: 91.5165, loss: 0.2071
2022-11-30 00:21:02,501 - mmseg - INFO - Iter [39650/40000]	lr: 5.265e-07, eta: 0:01:42, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2188, decode.acc_seg: 90.7579, loss: 0.2188
2022-11-30 00:21:15,517 - mmseg - INFO - Iter [39700/40000]	lr: 4.515e-07, eta: 0:01:28, time: 0.260, data_time: 0.005, memory: 5537, decode.loss_ce: 0.3100, decode.acc_seg: 89.0807, loss: 0.3100
2022-11-30 00:21:30,510 - mmseg - INFO - Iter [39750/40000]	lr: 3.765e-07, eta: 0:01:13, time: 0.300, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2170, decode.acc_seg: 91.1753, loss: 0.2170
2022-11-30 00:21:43,386 - mmseg - INFO - Iter [39800/40000]	lr: 3.015e-07, eta: 0:00:58, time: 0.258, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2209, decode.acc_seg: 89.6325, loss: 0.2209
2022-11-30 00:21:56,313 - mmseg - INFO - Iter [39850/40000]	lr: 2.265e-07, eta: 0:00:44, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2439, decode.acc_seg: 90.5504, loss: 0.2439
2022-11-30 00:22:11,523 - mmseg - INFO - Iter [39900/40000]	lr: 1.515e-07, eta: 0:00:29, time: 0.304, data_time: 0.046, memory: 5537, decode.loss_ce: 0.2174, decode.acc_seg: 90.0919, loss: 0.2174
2022-11-30 00:22:26,935 - mmseg - INFO - Iter [39950/40000]	lr: 7.650e-08, eta: 0:00:14, time: 0.308, data_time: 0.005, memory: 5537, decode.loss_ce: 0.1759, decode.acc_seg: 92.6526, loss: 0.1759
2022-11-30 00:22:42,351 - mmseg - INFO - Saving checkpoint at 40000 iterations
2022-11-30 00:22:45,328 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-30 00:22:45,328 - mmseg - INFO - Iter [40000/40000]	lr: 1.500e-09, eta: 0:00:00, time: 0.368, data_time: 0.005, memory: 5537, decode.loss_ce: 0.2301, decode.acc_seg: 91.0786, loss: 0.2301
2022-11-30 00:23:26,547 - mmseg - INFO - per class results:
2022-11-30 00:23:26,548 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 73.16 |  85.4 |
|  aeroplane  |  6.32 |  8.08 |
|   bicycle   |  1.09 |  1.32 |
|     bird    |  0.03 |  0.05 |
|     boat    |  0.94 |  1.41 |
|    bottle   |  0.01 |  0.01 |
|     bus     |  2.05 |  3.7  |
|     car     | 15.92 | 37.83 |
|     cat     |  5.28 |  6.18 |
|    chair    |  0.88 |  0.94 |
|     cow     |  3.4  |  6.07 |
| diningtable |  0.46 |  0.47 |
|     dog     | 13.89 | 40.92 |
|    horse    |  0.92 |  0.96 |
|  motorbike  | 12.51 | 51.39 |
|    person   |  20.8 | 39.32 |
| pottedplant |  0.17 |  0.19 |
|    sheep    |  5.7  |  8.5  |
|     sofa    |  0.0  |  0.0  |
|    train    |  1.37 |  2.23 |
|  tvmonitor  |  2.52 |  7.09 |
+-------------+-------+-------+
2022-11-30 00:23:26,548 - mmseg - INFO - Summary:
2022-11-30 00:23:26,548 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 67.29 | 7.97 | 14.38 |
+-------+------+-------+
2022-11-30 00:23:26,549 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub_nopre.py
2022-11-30 00:23:26,549 - mmseg - INFO - Iter(val) [724]	aAcc: 0.6729, mIoU: 0.0797, mAcc: 0.1438, IoU.background: 0.7316, IoU.aeroplane: 0.0632, IoU.bicycle: 0.0109, IoU.bird: 0.0003, IoU.boat: 0.0094, IoU.bottle: 0.0001, IoU.bus: 0.0205, IoU.car: 0.1592, IoU.cat: 0.0528, IoU.chair: 0.0088, IoU.cow: 0.0340, IoU.diningtable: 0.0046, IoU.dog: 0.1389, IoU.horse: 0.0092, IoU.motorbike: 0.1251, IoU.person: 0.2080, IoU.pottedplant: 0.0017, IoU.sheep: 0.0570, IoU.sofa: 0.0000, IoU.train: 0.0137, IoU.tvmonitor: 0.0252, Acc.background: 0.8540, Acc.aeroplane: 0.0808, Acc.bicycle: 0.0132, Acc.bird: 0.0005, Acc.boat: 0.0141, Acc.bottle: 0.0001, Acc.bus: 0.0370, Acc.car: 0.3783, Acc.cat: 0.0618, Acc.chair: 0.0094, Acc.cow: 0.0607, Acc.diningtable: 0.0047, Acc.dog: 0.4092, Acc.horse: 0.0096, Acc.motorbike: 0.5139, Acc.person: 0.3932, Acc.pottedplant: 0.0019, Acc.sheep: 0.0850, Acc.sofa: 0.0000, Acc.train: 0.0223, Acc.tvmonitor: 0.0709
