2022-11-29 18:03:23,467 - mmseg - INFO - Multi-processing start method is `None`
2022-11-29 18:03:23,467 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>
2022-11-29 18:03:23,810 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.8 (default, Apr 13 2021, 19:58:26) [GCC 7.3.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.5, V11.5.119
GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-3)
PyTorch: 1.11.0+cu102
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.2-Product Build 20210312 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu102
OpenCV: 4.6.0
MMCV: 1.6.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 10.2
MMSegmentation: 0.24.1+
------------------------------------------------------------

2022-11-29 18:03:23,811 - mmseg - INFO - Distributed training: False
2022-11-29 18:03:24,198 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
ham_norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='MSCAN',
        embed_dims=[64, 128, 320, 512],
        mlp_ratios=[8, 8, 4, 4],
        drop_rate=0.0,
        drop_path_rate=0.3,
        depths=[3, 5, 27, 3],
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        init_cfg=dict(type='Pretrained', checkpoint='pretrained/mscan_l.pth')),
    decode_head=dict(
        type='LightHamHead',
        in_channels=[128, 320, 512],
        in_index=[1, 2, 3],
        channels=1024,
        ham_channels=1024,
        dropout_ratio=0.1,
        num_classes=21,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'PascalVOCDataset'
data_root = '/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=1,
    train=dict(
        type='PascalVOCDataset',
        data_root='/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/train.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='PascalVOCDataset',
        data_root='/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='PascalVOCDataset',
        data_root='/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/test.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=40000)
checkpoint_config = dict(by_epoch=False, interval=5000)
evaluation = dict(interval=5000, metric='mIoU')
find_unused_parameters = True
work_dir = './work_dirs/segnext.large.512x512.voc.40k'
gpu_ids = [0]
auto_resume = False

2022-11-29 18:03:24,198 - mmseg - INFO - Set random seed to 1636082973, deterministic: False
2022-11-29 18:03:24,946 - mmseg - INFO - initialize MSCAN with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/mscan_l.pth'}
2022-11-29 18:05:43,446 - mmseg - INFO - initialize LightHamHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.patch_embed1.proj.0.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.0.bias - torch.Size([32]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.1.weight - torch.Size([32]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.1.bias - torch.Size([32]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.3.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.3.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.4.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.4.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.layer_scale_1 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.layer_scale_2 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.proj_1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.proj_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0.weight - torch.Size([64, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([64, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([64, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([64, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([64, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([64, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([64, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv3.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv3.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.proj_2.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.proj_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.norm2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.norm2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.fc1.weight - torch.Size([512, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.fc1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.dwconv.dwconv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.dwconv.dwconv.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.fc2.weight - torch.Size([64, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.fc2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.layer_scale_1 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.layer_scale_2 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.proj_1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.proj_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0.weight - torch.Size([64, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([64, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([64, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([64, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([64, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([64, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([64, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv3.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv3.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.proj_2.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.proj_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.norm2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.norm2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.fc1.weight - torch.Size([512, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.fc1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.dwconv.dwconv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.dwconv.dwconv.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.fc2.weight - torch.Size([64, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.fc2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.layer_scale_1 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.layer_scale_2 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.proj_1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.proj_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0.weight - torch.Size([64, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([64, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([64, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([64, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([64, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([64, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([64, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv3.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv3.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.proj_2.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.proj_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.norm2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.norm2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.fc1.weight - torch.Size([512, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.fc1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.dwconv.dwconv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.dwconv.dwconv.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.fc2.weight - torch.Size([64, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.fc2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed2.proj.weight - torch.Size([128, 64, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed2.proj.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed2.norm.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed2.norm.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed3.proj.weight - torch.Size([320, 128, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed3.proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed3.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed3.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm3.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed4.proj.weight - torch.Size([512, 320, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed4.proj.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed4.norm.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed4.norm.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.layer_scale_1 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.layer_scale_2 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.norm1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.norm1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.proj_1.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.proj_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0.weight - torch.Size([512, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([512, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([512, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([512, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([512, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([512, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([512, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv3.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv3.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.proj_2.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.proj_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.norm2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.norm2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.fc1.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.fc1.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.dwconv.dwconv.weight - torch.Size([2048, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.dwconv.dwconv.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.fc2.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.fc2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.layer_scale_1 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.layer_scale_2 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.norm1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.norm1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.proj_1.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.proj_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0.weight - torch.Size([512, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([512, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([512, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([512, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([512, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([512, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([512, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv3.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv3.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.proj_2.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.proj_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.norm2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.norm2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.fc1.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.fc1.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.dwconv.dwconv.weight - torch.Size([2048, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.dwconv.dwconv.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.fc2.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.fc2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.layer_scale_1 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.layer_scale_2 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.norm1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.norm1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.proj_1.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.proj_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0.weight - torch.Size([512, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([512, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([512, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([512, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([512, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([512, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([512, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv3.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv3.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.proj_2.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.proj_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.norm2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.norm2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.fc1.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.fc1.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.dwconv.dwconv.weight - torch.Size([2048, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.dwconv.dwconv.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.fc2.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.fc2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm4.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm4.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

decode_head.conv_seg.weight - torch.Size([21, 1024, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([21]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.squeeze.conv.weight - torch.Size([1024, 960, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.squeeze.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.squeeze.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_in.conv.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_in.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_out.conv.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_out.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_out.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.conv.weight - torch.Size([1024, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.align.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2022-11-29 18:05:43,499 - mmseg - INFO - EncoderDecoder(
  (backbone): MSCAN(
    (patch_embed1): StemConv(
      (proj): Sequential(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU()
        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)
            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)
            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)
            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)
            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)
            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)
            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)
            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)
            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)
            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)
            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)
            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)
            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)
            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)
            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)
            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)
            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)
            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)
            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (conv0_1): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=512)
            (conv0_2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=512)
            (conv1_1): Conv2d(512, 512, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=512)
            (conv1_2): Conv2d(512, 512, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=512)
            (conv2_1): Conv2d(512, 512, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=512)
            (conv2_2): Conv2d(512, 512, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=512)
            (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (conv0_1): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=512)
            (conv0_2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=512)
            (conv1_1): Conv2d(512, 512, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=512)
            (conv1_2): Conv2d(512, 512, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=512)
            (conv2_1): Conv2d(512, 512, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=512)
            (conv2_2): Conv2d(512, 512, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=512)
            (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (conv0_1): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=512)
            (conv0_2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=512)
            (conv1_1): Conv2d(512, 512, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=512)
            (conv1_2): Conv2d(512, 512, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=512)
            (conv2_1): Conv2d(512, 512, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=512)
            (conv2_2): Conv2d(512, 512, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=512)
            (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'pretrained/mscan_l.pth'}
  (decode_head): LightHamHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(1024, 21, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (squeeze): ConvModule(
      (conv): Conv2d(960, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
    (hamburger): Hamburger(
      (ham_in): ConvModule(
        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (ham): NMF2D()
      (ham_out): ConvModule(
        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
      )
    )
    (align): ConvModule(
      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2022-11-29 18:05:43,530 - mmseg - INFO - Loaded 1464 images
2022-11-29 18:05:44,408 - mmseg - INFO - Loaded 724 images
2022-11-29 18:05:44,408 - mmseg - INFO - Start running, host: yl407@dcc-core-gpu-11, work_dir: /work/yl407/SegNeXt/work_dirs/segnext.large.512x512.voc.40k
2022-11-29 18:05:44,409 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-11-29 18:05:44,409 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters
2022-11-29 18:05:44,409 - mmseg - INFO - Checkpoints will be saved to /work/yl407/SegNeXt/work_dirs/segnext.large.512x512.voc.40k by HardDiskBackend.
2022-11-29 18:06:04,629 - mmseg - INFO - Iter [50/40000]	lr: 1.958e-06, eta: 4:26:25, time: 0.400, data_time: 0.020, memory: 5537, decode.loss_ce: 2.4302, decode.acc_seg: 38.3917, loss: 2.4302
2022-11-29 18:06:17,767 - mmseg - INFO - Iter [100/40000]	lr: 3.950e-06, eta: 3:40:24, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 1.5723, decode.acc_seg: 68.3058, loss: 1.5723
2022-11-29 18:06:30,861 - mmseg - INFO - Iter [150/40000]	lr: 5.938e-06, eta: 3:24:42, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 1.4014, decode.acc_seg: 69.1992, loss: 1.4014
2022-11-29 18:06:43,933 - mmseg - INFO - Iter [200/40000]	lr: 7.920e-06, eta: 3:16:41, time: 0.261, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3711, decode.acc_seg: 67.5504, loss: 1.3711
2022-11-29 18:06:56,995 - mmseg - INFO - Iter [250/40000]	lr: 9.898e-06, eta: 3:11:45, time: 0.261, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3709, decode.acc_seg: 65.2821, loss: 1.3709
2022-11-29 18:07:10,125 - mmseg - INFO - Iter [300/40000]	lr: 1.187e-05, eta: 3:08:33, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3684, decode.acc_seg: 66.4570, loss: 1.3684
2022-11-29 18:07:23,228 - mmseg - INFO - Iter [350/40000]	lr: 1.384e-05, eta: 3:06:09, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3604, decode.acc_seg: 64.6079, loss: 1.3604
2022-11-29 18:07:36,341 - mmseg - INFO - Iter [400/40000]	lr: 1.580e-05, eta: 3:04:18, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 1.3689, decode.acc_seg: 63.2850, loss: 1.3689
2022-11-29 18:07:49,445 - mmseg - INFO - Iter [450/40000]	lr: 1.776e-05, eta: 3:02:49, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2027, decode.acc_seg: 68.2254, loss: 1.2027
2022-11-29 18:08:03,227 - mmseg - INFO - Iter [500/40000]	lr: 1.971e-05, eta: 3:02:28, time: 0.276, data_time: 0.014, memory: 5537, decode.loss_ce: 1.1748, decode.acc_seg: 63.4747, loss: 1.1748
2022-11-29 18:08:16,424 - mmseg - INFO - Iter [550/40000]	lr: 2.166e-05, eta: 3:01:26, time: 0.264, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2251, decode.acc_seg: 62.2768, loss: 1.2251
2022-11-29 18:08:29,574 - mmseg - INFO - Iter [600/40000]	lr: 2.360e-05, eta: 3:00:30, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 1.0658, decode.acc_seg: 68.3611, loss: 1.0658
2022-11-29 18:08:42,690 - mmseg - INFO - Iter [650/40000]	lr: 2.554e-05, eta: 2:59:38, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8293, decode.acc_seg: 73.2794, loss: 0.8293
2022-11-29 18:08:55,851 - mmseg - INFO - Iter [700/40000]	lr: 2.747e-05, eta: 2:58:54, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 1.2498, decode.acc_seg: 66.2114, loss: 1.2498
2022-11-29 18:09:09,056 - mmseg - INFO - Iter [750/40000]	lr: 2.940e-05, eta: 2:58:17, time: 0.264, data_time: 0.008, memory: 5537, decode.loss_ce: 1.0546, decode.acc_seg: 68.8864, loss: 1.0546
2022-11-29 18:09:22,295 - mmseg - INFO - Iter [800/40000]	lr: 3.132e-05, eta: 2:57:44, time: 0.265, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7319, decode.acc_seg: 77.2131, loss: 0.7319
2022-11-29 18:09:35,430 - mmseg - INFO - Iter [850/40000]	lr: 3.324e-05, eta: 2:57:09, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7187, decode.acc_seg: 75.2940, loss: 0.7187
2022-11-29 18:09:48,531 - mmseg - INFO - Iter [900/40000]	lr: 3.515e-05, eta: 2:56:35, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6123, decode.acc_seg: 80.6489, loss: 0.6123
2022-11-29 18:10:01,704 - mmseg - INFO - Iter [950/40000]	lr: 3.706e-05, eta: 2:56:06, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8767, decode.acc_seg: 73.1623, loss: 0.8767
2022-11-29 18:10:14,919 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:10:14,919 - mmseg - INFO - Iter [1000/40000]	lr: 3.896e-05, eta: 2:55:40, time: 0.264, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8014, decode.acc_seg: 75.0973, loss: 0.8014
2022-11-29 18:10:28,139 - mmseg - INFO - Iter [1050/40000]	lr: 4.086e-05, eta: 2:55:15, time: 0.264, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8871, decode.acc_seg: 69.9295, loss: 0.8871
2022-11-29 18:10:41,385 - mmseg - INFO - Iter [1100/40000]	lr: 4.275e-05, eta: 2:54:53, time: 0.265, data_time: 0.007, memory: 5537, decode.loss_ce: 0.6709, decode.acc_seg: 76.7800, loss: 0.6709
2022-11-29 18:10:54,803 - mmseg - INFO - Iter [1150/40000]	lr: 4.464e-05, eta: 2:54:37, time: 0.268, data_time: 0.010, memory: 5537, decode.loss_ce: 0.8876, decode.acc_seg: 72.8480, loss: 0.8876
2022-11-29 18:11:07,999 - mmseg - INFO - Iter [1200/40000]	lr: 4.652e-05, eta: 2:54:14, time: 0.264, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7670, decode.acc_seg: 73.7586, loss: 0.7670
2022-11-29 18:11:21,129 - mmseg - INFO - Iter [1250/40000]	lr: 4.840e-05, eta: 2:53:50, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8276, decode.acc_seg: 76.6718, loss: 0.8276
2022-11-29 18:11:34,268 - mmseg - INFO - Iter [1300/40000]	lr: 5.027e-05, eta: 2:53:27, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 0.8533, decode.acc_seg: 73.4467, loss: 0.8533
2022-11-29 18:11:47,416 - mmseg - INFO - Iter [1350/40000]	lr: 5.214e-05, eta: 2:53:05, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 0.7283, decode.acc_seg: 78.1198, loss: 0.7283
2022-11-29 18:12:00,787 - mmseg - INFO - Iter [1400/40000]	lr: 5.400e-05, eta: 2:52:50, time: 0.267, data_time: 0.009, memory: 5537, decode.loss_ce: 0.6522, decode.acc_seg: 78.7385, loss: 0.6522
2022-11-29 18:12:13,908 - mmseg - INFO - Iter [1450/40000]	lr: 5.586e-05, eta: 2:52:28, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 0.9377, decode.acc_seg: 69.9659, loss: 0.9377
2022-11-29 18:12:29,346 - mmseg - INFO - Iter [1500/40000]	lr: 5.771e-05, eta: 2:53:06, time: 0.309, data_time: 0.048, memory: 5537, decode.loss_ce: 0.7105, decode.acc_seg: 77.1184, loss: 0.7105
2022-11-29 18:12:42,518 - mmseg - INFO - Iter [1550/40000]	lr: 5.768e-05, eta: 2:52:45, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5316, decode.acc_seg: 80.1412, loss: 0.5316
2022-11-29 18:12:55,648 - mmseg - INFO - Iter [1600/40000]	lr: 5.760e-05, eta: 2:52:23, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4762, decode.acc_seg: 83.2517, loss: 0.4762
2022-11-29 18:13:08,684 - mmseg - INFO - Iter [1650/40000]	lr: 5.753e-05, eta: 2:52:00, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5546, decode.acc_seg: 79.2199, loss: 0.5546
2022-11-29 18:13:21,674 - mmseg - INFO - Iter [1700/40000]	lr: 5.745e-05, eta: 2:51:36, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.9028, decode.acc_seg: 68.4889, loss: 0.9028
2022-11-29 18:13:34,716 - mmseg - INFO - Iter [1750/40000]	lr: 5.738e-05, eta: 2:51:14, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.8261, decode.acc_seg: 72.4377, loss: 0.8261
2022-11-29 18:13:47,633 - mmseg - INFO - Iter [1800/40000]	lr: 5.730e-05, eta: 2:50:49, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7792, decode.acc_seg: 74.8008, loss: 0.7792
2022-11-29 18:14:00,570 - mmseg - INFO - Iter [1850/40000]	lr: 5.723e-05, eta: 2:50:26, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7086, decode.acc_seg: 75.5217, loss: 0.7086
2022-11-29 18:14:13,499 - mmseg - INFO - Iter [1900/40000]	lr: 5.715e-05, eta: 2:50:03, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6051, decode.acc_seg: 79.7447, loss: 0.6051
2022-11-29 18:14:26,403 - mmseg - INFO - Iter [1950/40000]	lr: 5.708e-05, eta: 2:49:40, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6253, decode.acc_seg: 78.4492, loss: 0.6253
2022-11-29 18:14:39,331 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:14:39,331 - mmseg - INFO - Iter [2000/40000]	lr: 5.700e-05, eta: 2:49:18, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5853, decode.acc_seg: 78.2418, loss: 0.5853
2022-11-29 18:14:52,286 - mmseg - INFO - Iter [2050/40000]	lr: 5.693e-05, eta: 2:48:57, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7192, decode.acc_seg: 75.7804, loss: 0.7192
2022-11-29 18:15:05,278 - mmseg - INFO - Iter [2100/40000]	lr: 5.685e-05, eta: 2:48:37, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7107, decode.acc_seg: 75.2127, loss: 0.7107
2022-11-29 18:15:18,217 - mmseg - INFO - Iter [2150/40000]	lr: 5.678e-05, eta: 2:48:17, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5067, decode.acc_seg: 81.2721, loss: 0.5067
2022-11-29 18:15:31,161 - mmseg - INFO - Iter [2200/40000]	lr: 5.670e-05, eta: 2:47:57, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5972, decode.acc_seg: 79.0137, loss: 0.5972
2022-11-29 18:15:44,087 - mmseg - INFO - Iter [2250/40000]	lr: 5.663e-05, eta: 2:47:36, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5590, decode.acc_seg: 80.8305, loss: 0.5590
2022-11-29 18:15:56,936 - mmseg - INFO - Iter [2300/40000]	lr: 5.655e-05, eta: 2:47:15, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4123, decode.acc_seg: 86.4402, loss: 0.4123
2022-11-29 18:16:09,835 - mmseg - INFO - Iter [2350/40000]	lr: 5.648e-05, eta: 2:46:55, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5632, decode.acc_seg: 81.0549, loss: 0.5632
2022-11-29 18:16:22,694 - mmseg - INFO - Iter [2400/40000]	lr: 5.640e-05, eta: 2:46:35, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5538, decode.acc_seg: 81.5013, loss: 0.5538
2022-11-29 18:16:35,533 - mmseg - INFO - Iter [2450/40000]	lr: 5.633e-05, eta: 2:46:15, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6798, decode.acc_seg: 78.4390, loss: 0.6798
2022-11-29 18:16:48,385 - mmseg - INFO - Iter [2500/40000]	lr: 5.625e-05, eta: 2:45:55, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6140, decode.acc_seg: 80.3421, loss: 0.6140
2022-11-29 18:17:01,266 - mmseg - INFO - Iter [2550/40000]	lr: 5.618e-05, eta: 2:45:36, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5864, decode.acc_seg: 79.7372, loss: 0.5864
2022-11-29 18:17:14,102 - mmseg - INFO - Iter [2600/40000]	lr: 5.610e-05, eta: 2:45:17, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7594, decode.acc_seg: 78.6614, loss: 0.7594
2022-11-29 18:17:26,945 - mmseg - INFO - Iter [2650/40000]	lr: 5.603e-05, eta: 2:44:58, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7781, decode.acc_seg: 76.7207, loss: 0.7781
2022-11-29 18:17:39,918 - mmseg - INFO - Iter [2700/40000]	lr: 5.595e-05, eta: 2:44:40, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7223, decode.acc_seg: 74.5648, loss: 0.7223
2022-11-29 18:17:52,814 - mmseg - INFO - Iter [2750/40000]	lr: 5.588e-05, eta: 2:44:23, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6355, decode.acc_seg: 82.1458, loss: 0.6355
2022-11-29 18:18:05,695 - mmseg - INFO - Iter [2800/40000]	lr: 5.580e-05, eta: 2:44:05, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4314, decode.acc_seg: 84.6781, loss: 0.4314
2022-11-29 18:18:18,571 - mmseg - INFO - Iter [2850/40000]	lr: 5.573e-05, eta: 2:43:47, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5843, decode.acc_seg: 80.1016, loss: 0.5843
2022-11-29 18:18:31,435 - mmseg - INFO - Iter [2900/40000]	lr: 5.565e-05, eta: 2:43:29, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5902, decode.acc_seg: 81.7430, loss: 0.5902
2022-11-29 18:18:46,381 - mmseg - INFO - Iter [2950/40000]	lr: 5.558e-05, eta: 2:43:37, time: 0.299, data_time: 0.047, memory: 5537, decode.loss_ce: 0.5161, decode.acc_seg: 84.0866, loss: 0.5161
2022-11-29 18:18:59,232 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:18:59,232 - mmseg - INFO - Iter [3000/40000]	lr: 5.550e-05, eta: 2:43:19, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5157, decode.acc_seg: 83.4855, loss: 0.5157
2022-11-29 18:19:12,050 - mmseg - INFO - Iter [3050/40000]	lr: 5.543e-05, eta: 2:43:01, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4532, decode.acc_seg: 83.9700, loss: 0.4532
2022-11-29 18:19:27,385 - mmseg - INFO - Iter [3100/40000]	lr: 5.535e-05, eta: 2:43:12, time: 0.307, data_time: 0.054, memory: 5537, decode.loss_ce: 0.5084, decode.acc_seg: 81.5690, loss: 0.5084
2022-11-29 18:19:40,270 - mmseg - INFO - Iter [3150/40000]	lr: 5.528e-05, eta: 2:42:55, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4560, decode.acc_seg: 83.8690, loss: 0.4560
2022-11-29 18:19:53,877 - mmseg - INFO - Iter [3200/40000]	lr: 5.520e-05, eta: 2:42:45, time: 0.272, data_time: 0.018, memory: 5537, decode.loss_ce: 0.7028, decode.acc_seg: 77.4973, loss: 0.7028
2022-11-29 18:20:06,925 - mmseg - INFO - Iter [3250/40000]	lr: 5.513e-05, eta: 2:42:30, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4935, decode.acc_seg: 85.4089, loss: 0.4935
2022-11-29 18:20:19,927 - mmseg - INFO - Iter [3300/40000]	lr: 5.505e-05, eta: 2:42:13, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5454, decode.acc_seg: 82.1044, loss: 0.5454
2022-11-29 18:20:32,848 - mmseg - INFO - Iter [3350/40000]	lr: 5.498e-05, eta: 2:41:56, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4089, decode.acc_seg: 85.8504, loss: 0.4089
2022-11-29 18:20:45,738 - mmseg - INFO - Iter [3400/40000]	lr: 5.490e-05, eta: 2:41:39, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4602, decode.acc_seg: 84.3056, loss: 0.4602
2022-11-29 18:20:58,663 - mmseg - INFO - Iter [3450/40000]	lr: 5.483e-05, eta: 2:41:22, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4789, decode.acc_seg: 85.3192, loss: 0.4789
2022-11-29 18:21:11,642 - mmseg - INFO - Iter [3500/40000]	lr: 5.475e-05, eta: 2:41:06, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4839, decode.acc_seg: 81.5901, loss: 0.4839
2022-11-29 18:21:24,585 - mmseg - INFO - Iter [3550/40000]	lr: 5.468e-05, eta: 2:40:50, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6011, decode.acc_seg: 82.0916, loss: 0.6011
2022-11-29 18:21:37,614 - mmseg - INFO - Iter [3600/40000]	lr: 5.460e-05, eta: 2:40:35, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4632, decode.acc_seg: 84.3507, loss: 0.4632
2022-11-29 18:21:50,557 - mmseg - INFO - Iter [3650/40000]	lr: 5.453e-05, eta: 2:40:19, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4247, decode.acc_seg: 86.2670, loss: 0.4247
2022-11-29 18:22:03,496 - mmseg - INFO - Iter [3700/40000]	lr: 5.445e-05, eta: 2:40:02, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5063, decode.acc_seg: 81.9538, loss: 0.5063
2022-11-29 18:22:16,424 - mmseg - INFO - Iter [3750/40000]	lr: 5.438e-05, eta: 2:39:46, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5267, decode.acc_seg: 82.0512, loss: 0.5267
2022-11-29 18:22:29,312 - mmseg - INFO - Iter [3800/40000]	lr: 5.430e-05, eta: 2:39:30, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5489, decode.acc_seg: 81.7845, loss: 0.5489
2022-11-29 18:22:42,182 - mmseg - INFO - Iter [3850/40000]	lr: 5.423e-05, eta: 2:39:13, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3401, decode.acc_seg: 86.7600, loss: 0.3401
2022-11-29 18:22:55,105 - mmseg - INFO - Iter [3900/40000]	lr: 5.415e-05, eta: 2:38:58, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6943, decode.acc_seg: 79.9923, loss: 0.6943
2022-11-29 18:23:08,031 - mmseg - INFO - Iter [3950/40000]	lr: 5.408e-05, eta: 2:38:42, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5303, decode.acc_seg: 82.7417, loss: 0.5303
2022-11-29 18:23:20,958 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:23:20,958 - mmseg - INFO - Iter [4000/40000]	lr: 5.400e-05, eta: 2:38:26, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5860, decode.acc_seg: 79.5733, loss: 0.5860
2022-11-29 18:23:33,894 - mmseg - INFO - Iter [4050/40000]	lr: 5.393e-05, eta: 2:38:10, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5864, decode.acc_seg: 81.0212, loss: 0.5864
2022-11-29 18:23:46,816 - mmseg - INFO - Iter [4100/40000]	lr: 5.385e-05, eta: 2:37:55, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4960, decode.acc_seg: 82.8993, loss: 0.4960
2022-11-29 18:23:59,772 - mmseg - INFO - Iter [4150/40000]	lr: 5.378e-05, eta: 2:37:39, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5755, decode.acc_seg: 80.7022, loss: 0.5755
2022-11-29 18:24:12,621 - mmseg - INFO - Iter [4200/40000]	lr: 5.370e-05, eta: 2:37:23, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4169, decode.acc_seg: 86.0113, loss: 0.4169
2022-11-29 18:24:25,488 - mmseg - INFO - Iter [4250/40000]	lr: 5.363e-05, eta: 2:37:07, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4804, decode.acc_seg: 84.8126, loss: 0.4804
2022-11-29 18:24:38,346 - mmseg - INFO - Iter [4300/40000]	lr: 5.355e-05, eta: 2:36:52, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6759, decode.acc_seg: 81.2060, loss: 0.6759
2022-11-29 18:24:51,279 - mmseg - INFO - Iter [4350/40000]	lr: 5.348e-05, eta: 2:36:36, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.6889, decode.acc_seg: 80.4556, loss: 0.6889
2022-11-29 18:25:06,446 - mmseg - INFO - Iter [4400/40000]	lr: 5.340e-05, eta: 2:36:39, time: 0.303, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4964, decode.acc_seg: 83.9140, loss: 0.4964
2022-11-29 18:25:19,481 - mmseg - INFO - Iter [4450/40000]	lr: 5.333e-05, eta: 2:36:25, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4676, decode.acc_seg: 83.3685, loss: 0.4676
2022-11-29 18:25:32,454 - mmseg - INFO - Iter [4500/40000]	lr: 5.325e-05, eta: 2:36:10, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3945, decode.acc_seg: 85.3969, loss: 0.3945
2022-11-29 18:25:45,511 - mmseg - INFO - Iter [4550/40000]	lr: 5.318e-05, eta: 2:35:55, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3981, decode.acc_seg: 83.7759, loss: 0.3981
2022-11-29 18:25:58,459 - mmseg - INFO - Iter [4600/40000]	lr: 5.310e-05, eta: 2:35:40, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3687, decode.acc_seg: 85.7438, loss: 0.3687
2022-11-29 18:26:11,452 - mmseg - INFO - Iter [4650/40000]	lr: 5.303e-05, eta: 2:35:26, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4632, decode.acc_seg: 85.5982, loss: 0.4632
2022-11-29 18:26:24,385 - mmseg - INFO - Iter [4700/40000]	lr: 5.295e-05, eta: 2:35:10, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.7243, decode.acc_seg: 78.7743, loss: 0.7243
2022-11-29 18:26:37,310 - mmseg - INFO - Iter [4750/40000]	lr: 5.288e-05, eta: 2:34:55, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4713, decode.acc_seg: 83.5995, loss: 0.4713
2022-11-29 18:26:50,240 - mmseg - INFO - Iter [4800/40000]	lr: 5.280e-05, eta: 2:34:40, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4031, decode.acc_seg: 85.4411, loss: 0.4031
2022-11-29 18:27:03,182 - mmseg - INFO - Iter [4850/40000]	lr: 5.273e-05, eta: 2:34:25, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4030, decode.acc_seg: 85.5342, loss: 0.4030
2022-11-29 18:27:16,029 - mmseg - INFO - Iter [4900/40000]	lr: 5.265e-05, eta: 2:34:10, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3788, decode.acc_seg: 88.3478, loss: 0.3788
2022-11-29 18:27:28,953 - mmseg - INFO - Iter [4950/40000]	lr: 5.258e-05, eta: 2:33:55, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3363, decode.acc_seg: 87.5532, loss: 0.3363
2022-11-29 18:27:41,793 - mmseg - INFO - Saving checkpoint at 5000 iterations
2022-11-29 18:27:44,539 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:27:44,539 - mmseg - INFO - Iter [5000/40000]	lr: 5.250e-05, eta: 2:33:58, time: 0.312, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4171, decode.acc_seg: 87.2905, loss: 0.4171
2022-11-29 18:29:11,165 - mmseg - INFO - per class results:
2022-11-29 18:29:11,168 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 89.78 | 94.29 |
|  aeroplane  | 67.18 | 93.43 |
|   bicycle   | 22.69 | 29.14 |
|     bird    | 67.89 |  95.0 |
|     boat    | 62.18 | 86.37 |
|    bottle   | 63.77 |  76.9 |
|     bus     | 78.35 | 89.97 |
|     car     | 73.29 |  85.5 |
|     cat     | 73.13 | 74.43 |
|    chair    | 13.33 | 64.27 |
|     cow     | 55.49 | 69.36 |
| diningtable | 29.48 | 31.12 |
|     dog     | 67.36 | 91.93 |
|    horse    | 43.13 | 51.85 |
|  motorbike  | 62.42 | 87.38 |
|    person   | 74.68 | 90.34 |
| pottedplant |  38.6 | 44.73 |
|    sheep    | 63.47 | 66.81 |
|     sofa    |  8.22 |  8.4  |
|    train    | 57.11 | 67.75 |
|  tvmonitor  | 40.84 | 50.69 |
+-------------+-------+-------+
2022-11-29 18:29:11,168 - mmseg - INFO - Summary:
2022-11-29 18:29:11,168 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 88.33 | 54.87 | 69.03 |
+-------+-------+-------+
2022-11-29 18:29:11,172 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:29:11,172 - mmseg - INFO - Iter(val) [724]	aAcc: 0.8833, mIoU: 0.5487, mAcc: 0.6903, IoU.background: 0.8978, IoU.aeroplane: 0.6718, IoU.bicycle: 0.2269, IoU.bird: 0.6789, IoU.boat: 0.6218, IoU.bottle: 0.6377, IoU.bus: 0.7835, IoU.car: 0.7329, IoU.cat: 0.7313, IoU.chair: 0.1333, IoU.cow: 0.5549, IoU.diningtable: 0.2948, IoU.dog: 0.6736, IoU.horse: 0.4313, IoU.motorbike: 0.6242, IoU.person: 0.7468, IoU.pottedplant: 0.3860, IoU.sheep: 0.6347, IoU.sofa: 0.0822, IoU.train: 0.5711, IoU.tvmonitor: 0.4084, Acc.background: 0.9429, Acc.aeroplane: 0.9343, Acc.bicycle: 0.2914, Acc.bird: 0.9500, Acc.boat: 0.8637, Acc.bottle: 0.7690, Acc.bus: 0.8997, Acc.car: 0.8550, Acc.cat: 0.7443, Acc.chair: 0.6427, Acc.cow: 0.6936, Acc.diningtable: 0.3112, Acc.dog: 0.9193, Acc.horse: 0.5185, Acc.motorbike: 0.8738, Acc.person: 0.9034, Acc.pottedplant: 0.4473, Acc.sheep: 0.6681, Acc.sofa: 0.0840, Acc.train: 0.6775, Acc.tvmonitor: 0.5069
2022-11-29 18:29:24,551 - mmseg - INFO - Iter [5050/40000]	lr: 5.243e-05, eta: 2:43:46, time: 2.000, data_time: 1.739, memory: 5537, decode.loss_ce: 0.2345, decode.acc_seg: 90.9630, loss: 0.2345
2022-11-29 18:29:37,882 - mmseg - INFO - Iter [5100/40000]	lr: 5.235e-05, eta: 2:43:27, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3931, decode.acc_seg: 87.1711, loss: 0.3931
2022-11-29 18:29:51,146 - mmseg - INFO - Iter [5150/40000]	lr: 5.228e-05, eta: 2:43:08, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5005, decode.acc_seg: 81.9807, loss: 0.5005
2022-11-29 18:30:04,455 - mmseg - INFO - Iter [5200/40000]	lr: 5.220e-05, eta: 2:42:49, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4879, decode.acc_seg: 81.7535, loss: 0.4879
2022-11-29 18:30:17,682 - mmseg - INFO - Iter [5250/40000]	lr: 5.213e-05, eta: 2:42:29, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4382, decode.acc_seg: 83.4329, loss: 0.4382
2022-11-29 18:30:30,877 - mmseg - INFO - Iter [5300/40000]	lr: 5.205e-05, eta: 2:42:10, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2984, decode.acc_seg: 88.1323, loss: 0.2984
2022-11-29 18:30:44,003 - mmseg - INFO - Iter [5350/40000]	lr: 5.198e-05, eta: 2:41:50, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3456, decode.acc_seg: 88.6435, loss: 0.3456
2022-11-29 18:30:57,093 - mmseg - INFO - Iter [5400/40000]	lr: 5.190e-05, eta: 2:41:30, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4043, decode.acc_seg: 83.9341, loss: 0.4043
2022-11-29 18:31:10,252 - mmseg - INFO - Iter [5450/40000]	lr: 5.183e-05, eta: 2:41:11, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3206, decode.acc_seg: 88.0264, loss: 0.3206
2022-11-29 18:31:23,396 - mmseg - INFO - Iter [5500/40000]	lr: 5.175e-05, eta: 2:40:51, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4672, decode.acc_seg: 84.8289, loss: 0.4672
2022-11-29 18:31:36,482 - mmseg - INFO - Iter [5550/40000]	lr: 5.168e-05, eta: 2:40:32, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3274, decode.acc_seg: 87.3083, loss: 0.3274
2022-11-29 18:31:49,602 - mmseg - INFO - Iter [5600/40000]	lr: 5.160e-05, eta: 2:40:12, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4548, decode.acc_seg: 82.2509, loss: 0.4548
2022-11-29 18:32:02,700 - mmseg - INFO - Iter [5650/40000]	lr: 5.153e-05, eta: 2:39:53, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4771, decode.acc_seg: 82.8260, loss: 0.4771
2022-11-29 18:32:15,826 - mmseg - INFO - Iter [5700/40000]	lr: 5.145e-05, eta: 2:39:34, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 0.5470, decode.acc_seg: 83.8719, loss: 0.5470
2022-11-29 18:32:28,935 - mmseg - INFO - Iter [5750/40000]	lr: 5.138e-05, eta: 2:39:15, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4626, decode.acc_seg: 81.4642, loss: 0.4626
2022-11-29 18:32:42,012 - mmseg - INFO - Iter [5800/40000]	lr: 5.130e-05, eta: 2:38:56, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3224, decode.acc_seg: 90.2432, loss: 0.3224
2022-11-29 18:32:55,181 - mmseg - INFO - Iter [5850/40000]	lr: 5.123e-05, eta: 2:38:38, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3962, decode.acc_seg: 85.4532, loss: 0.3962
2022-11-29 18:33:10,467 - mmseg - INFO - Iter [5900/40000]	lr: 5.115e-05, eta: 2:38:31, time: 0.306, data_time: 0.048, memory: 5537, decode.loss_ce: 0.4087, decode.acc_seg: 86.1007, loss: 0.4087
2022-11-29 18:33:23,596 - mmseg - INFO - Iter [5950/40000]	lr: 5.108e-05, eta: 2:38:13, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3145, decode.acc_seg: 89.8945, loss: 0.3145
2022-11-29 18:33:36,849 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:33:36,849 - mmseg - INFO - Iter [6000/40000]	lr: 5.100e-05, eta: 2:37:55, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4262, decode.acc_seg: 83.6242, loss: 0.4262
2022-11-29 18:33:49,959 - mmseg - INFO - Iter [6050/40000]	lr: 5.093e-05, eta: 2:37:36, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2782, decode.acc_seg: 90.6204, loss: 0.2782
2022-11-29 18:34:03,056 - mmseg - INFO - Iter [6100/40000]	lr: 5.085e-05, eta: 2:37:18, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2980, decode.acc_seg: 90.2038, loss: 0.2980
2022-11-29 18:34:16,272 - mmseg - INFO - Iter [6150/40000]	lr: 5.078e-05, eta: 2:37:00, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2407, decode.acc_seg: 91.2070, loss: 0.2407
2022-11-29 18:34:29,457 - mmseg - INFO - Iter [6200/40000]	lr: 5.070e-05, eta: 2:36:42, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3295, decode.acc_seg: 88.8150, loss: 0.3295
2022-11-29 18:34:42,567 - mmseg - INFO - Iter [6250/40000]	lr: 5.063e-05, eta: 2:36:24, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2775, decode.acc_seg: 91.4765, loss: 0.2775
2022-11-29 18:34:55,669 - mmseg - INFO - Iter [6300/40000]	lr: 5.055e-05, eta: 2:36:06, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4523, decode.acc_seg: 87.1909, loss: 0.4523
2022-11-29 18:35:08,808 - mmseg - INFO - Iter [6350/40000]	lr: 5.048e-05, eta: 2:35:48, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5453, decode.acc_seg: 84.3975, loss: 0.5453
2022-11-29 18:35:21,903 - mmseg - INFO - Iter [6400/40000]	lr: 5.040e-05, eta: 2:35:30, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4042, decode.acc_seg: 85.2998, loss: 0.4042
2022-11-29 18:35:34,996 - mmseg - INFO - Iter [6450/40000]	lr: 5.033e-05, eta: 2:35:12, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2905, decode.acc_seg: 89.6149, loss: 0.2905
2022-11-29 18:35:48,155 - mmseg - INFO - Iter [6500/40000]	lr: 5.025e-05, eta: 2:34:54, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3543, decode.acc_seg: 87.2690, loss: 0.3543
2022-11-29 18:36:01,314 - mmseg - INFO - Iter [6550/40000]	lr: 5.018e-05, eta: 2:34:37, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3986, decode.acc_seg: 86.2533, loss: 0.3986
2022-11-29 18:36:14,513 - mmseg - INFO - Iter [6600/40000]	lr: 5.010e-05, eta: 2:34:19, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3630, decode.acc_seg: 87.3207, loss: 0.3630
2022-11-29 18:36:27,716 - mmseg - INFO - Iter [6650/40000]	lr: 5.003e-05, eta: 2:34:02, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2938, decode.acc_seg: 90.1423, loss: 0.2938
2022-11-29 18:36:40,910 - mmseg - INFO - Iter [6700/40000]	lr: 4.995e-05, eta: 2:33:45, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4569, decode.acc_seg: 85.4086, loss: 0.4569
2022-11-29 18:36:54,084 - mmseg - INFO - Iter [6750/40000]	lr: 4.988e-05, eta: 2:33:28, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3928, decode.acc_seg: 87.2853, loss: 0.3928
2022-11-29 18:37:07,271 - mmseg - INFO - Iter [6800/40000]	lr: 4.980e-05, eta: 2:33:11, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3638, decode.acc_seg: 85.9052, loss: 0.3638
2022-11-29 18:37:20,473 - mmseg - INFO - Iter [6850/40000]	lr: 4.973e-05, eta: 2:32:54, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3587, decode.acc_seg: 87.6359, loss: 0.3587
2022-11-29 18:37:33,671 - mmseg - INFO - Iter [6900/40000]	lr: 4.965e-05, eta: 2:32:37, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3611, decode.acc_seg: 87.1763, loss: 0.3611
2022-11-29 18:37:46,967 - mmseg - INFO - Iter [6950/40000]	lr: 4.958e-05, eta: 2:32:20, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3611, decode.acc_seg: 87.6108, loss: 0.3611
2022-11-29 18:38:00,177 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:38:00,177 - mmseg - INFO - Iter [7000/40000]	lr: 4.950e-05, eta: 2:32:04, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3505, decode.acc_seg: 87.5968, loss: 0.3505
2022-11-29 18:38:13,376 - mmseg - INFO - Iter [7050/40000]	lr: 4.943e-05, eta: 2:31:47, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2356, decode.acc_seg: 92.5226, loss: 0.2356
2022-11-29 18:38:26,602 - mmseg - INFO - Iter [7100/40000]	lr: 4.935e-05, eta: 2:31:30, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3764, decode.acc_seg: 88.1064, loss: 0.3764
2022-11-29 18:38:39,822 - mmseg - INFO - Iter [7150/40000]	lr: 4.928e-05, eta: 2:31:14, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5423, decode.acc_seg: 79.4926, loss: 0.5423
2022-11-29 18:38:53,047 - mmseg - INFO - Iter [7200/40000]	lr: 4.920e-05, eta: 2:30:57, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4944, decode.acc_seg: 81.5527, loss: 0.4944
2022-11-29 18:39:06,278 - mmseg - INFO - Iter [7250/40000]	lr: 4.913e-05, eta: 2:30:41, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4438, decode.acc_seg: 82.9935, loss: 0.4438
2022-11-29 18:39:19,453 - mmseg - INFO - Iter [7300/40000]	lr: 4.905e-05, eta: 2:30:24, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4793, decode.acc_seg: 85.9405, loss: 0.4793
2022-11-29 18:39:34,887 - mmseg - INFO - Iter [7350/40000]	lr: 4.898e-05, eta: 2:30:18, time: 0.309, data_time: 0.048, memory: 5537, decode.loss_ce: 0.3140, decode.acc_seg: 89.7129, loss: 0.3140
2022-11-29 18:39:48,165 - mmseg - INFO - Iter [7400/40000]	lr: 4.890e-05, eta: 2:30:02, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3137, decode.acc_seg: 90.4306, loss: 0.3137
2022-11-29 18:40:01,375 - mmseg - INFO - Iter [7450/40000]	lr: 4.883e-05, eta: 2:29:45, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4404, decode.acc_seg: 86.0391, loss: 0.4404
2022-11-29 18:40:14,538 - mmseg - INFO - Iter [7500/40000]	lr: 4.875e-05, eta: 2:29:29, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2662, decode.acc_seg: 89.6591, loss: 0.2662
2022-11-29 18:40:27,699 - mmseg - INFO - Iter [7550/40000]	lr: 4.868e-05, eta: 2:29:12, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2781, decode.acc_seg: 89.2836, loss: 0.2781
2022-11-29 18:40:40,884 - mmseg - INFO - Iter [7600/40000]	lr: 4.860e-05, eta: 2:28:56, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2993, decode.acc_seg: 89.7783, loss: 0.2993
2022-11-29 18:40:54,054 - mmseg - INFO - Iter [7650/40000]	lr: 4.853e-05, eta: 2:28:39, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4631, decode.acc_seg: 87.0223, loss: 0.4631
2022-11-29 18:41:07,230 - mmseg - INFO - Iter [7700/40000]	lr: 4.845e-05, eta: 2:28:23, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2854, decode.acc_seg: 90.7448, loss: 0.2854
2022-11-29 18:41:20,354 - mmseg - INFO - Iter [7750/40000]	lr: 4.838e-05, eta: 2:28:06, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2725, decode.acc_seg: 89.4066, loss: 0.2725
2022-11-29 18:41:33,516 - mmseg - INFO - Iter [7800/40000]	lr: 4.830e-05, eta: 2:27:50, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3128, decode.acc_seg: 88.4022, loss: 0.3128
2022-11-29 18:41:46,783 - mmseg - INFO - Iter [7850/40000]	lr: 4.823e-05, eta: 2:27:34, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4195, decode.acc_seg: 85.5427, loss: 0.4195
2022-11-29 18:41:59,940 - mmseg - INFO - Iter [7900/40000]	lr: 4.815e-05, eta: 2:27:18, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3481, decode.acc_seg: 87.2400, loss: 0.3481
2022-11-29 18:42:13,169 - mmseg - INFO - Iter [7950/40000]	lr: 4.808e-05, eta: 2:27:02, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3452, decode.acc_seg: 86.6870, loss: 0.3452
2022-11-29 18:42:26,374 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:42:26,375 - mmseg - INFO - Iter [8000/40000]	lr: 4.800e-05, eta: 2:26:46, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3319, decode.acc_seg: 87.5860, loss: 0.3319
2022-11-29 18:42:39,618 - mmseg - INFO - Iter [8050/40000]	lr: 4.793e-05, eta: 2:26:30, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2190, decode.acc_seg: 91.9785, loss: 0.2190
2022-11-29 18:42:52,837 - mmseg - INFO - Iter [8100/40000]	lr: 4.785e-05, eta: 2:26:14, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3678, decode.acc_seg: 87.4314, loss: 0.3678
2022-11-29 18:43:06,056 - mmseg - INFO - Iter [8150/40000]	lr: 4.778e-05, eta: 2:25:59, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4320, decode.acc_seg: 85.7225, loss: 0.4320
2022-11-29 18:43:19,245 - mmseg - INFO - Iter [8200/40000]	lr: 4.770e-05, eta: 2:25:43, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3131, decode.acc_seg: 87.4317, loss: 0.3131
2022-11-29 18:43:32,447 - mmseg - INFO - Iter [8250/40000]	lr: 4.763e-05, eta: 2:25:27, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3138, decode.acc_seg: 87.8373, loss: 0.3138
2022-11-29 18:43:45,635 - mmseg - INFO - Iter [8300/40000]	lr: 4.755e-05, eta: 2:25:11, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4156, decode.acc_seg: 84.2615, loss: 0.4156
2022-11-29 18:43:58,818 - mmseg - INFO - Iter [8350/40000]	lr: 4.748e-05, eta: 2:24:55, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4063, decode.acc_seg: 86.5655, loss: 0.4063
2022-11-29 18:44:12,042 - mmseg - INFO - Iter [8400/40000]	lr: 4.740e-05, eta: 2:24:39, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2915, decode.acc_seg: 89.9155, loss: 0.2915
2022-11-29 18:44:25,256 - mmseg - INFO - Iter [8450/40000]	lr: 4.733e-05, eta: 2:24:24, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2487, decode.acc_seg: 91.9547, loss: 0.2487
2022-11-29 18:44:38,452 - mmseg - INFO - Iter [8500/40000]	lr: 4.725e-05, eta: 2:24:08, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3860, decode.acc_seg: 87.2228, loss: 0.3860
2022-11-29 18:44:51,705 - mmseg - INFO - Iter [8550/40000]	lr: 4.718e-05, eta: 2:23:52, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4603, decode.acc_seg: 85.8996, loss: 0.4603
2022-11-29 18:45:04,911 - mmseg - INFO - Iter [8600/40000]	lr: 4.710e-05, eta: 2:23:37, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3458, decode.acc_seg: 86.2803, loss: 0.3458
2022-11-29 18:45:18,029 - mmseg - INFO - Iter [8650/40000]	lr: 4.703e-05, eta: 2:23:21, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3759, decode.acc_seg: 84.8279, loss: 0.3759
2022-11-29 18:45:31,186 - mmseg - INFO - Iter [8700/40000]	lr: 4.695e-05, eta: 2:23:05, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4028, decode.acc_seg: 86.6779, loss: 0.4028
2022-11-29 18:45:44,338 - mmseg - INFO - Iter [8750/40000]	lr: 4.688e-05, eta: 2:22:49, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2753, decode.acc_seg: 90.4152, loss: 0.2753
2022-11-29 18:45:59,743 - mmseg - INFO - Iter [8800/40000]	lr: 4.680e-05, eta: 2:22:42, time: 0.308, data_time: 0.047, memory: 5537, decode.loss_ce: 0.3538, decode.acc_seg: 87.7509, loss: 0.3538
2022-11-29 18:46:13,104 - mmseg - INFO - Iter [8850/40000]	lr: 4.673e-05, eta: 2:22:27, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2046, decode.acc_seg: 93.7335, loss: 0.2046
2022-11-29 18:46:26,441 - mmseg - INFO - Iter [8900/40000]	lr: 4.665e-05, eta: 2:22:12, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2588, decode.acc_seg: 90.5099, loss: 0.2588
2022-11-29 18:46:39,612 - mmseg - INFO - Iter [8950/40000]	lr: 4.658e-05, eta: 2:21:56, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3255, decode.acc_seg: 88.4086, loss: 0.3255
2022-11-29 18:46:52,772 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:46:52,772 - mmseg - INFO - Iter [9000/40000]	lr: 4.650e-05, eta: 2:21:40, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2687, decode.acc_seg: 90.0741, loss: 0.2687
2022-11-29 18:47:05,958 - mmseg - INFO - Iter [9050/40000]	lr: 4.643e-05, eta: 2:21:25, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3637, decode.acc_seg: 86.4071, loss: 0.3637
2022-11-29 18:47:19,094 - mmseg - INFO - Iter [9100/40000]	lr: 4.635e-05, eta: 2:21:09, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2143, decode.acc_seg: 91.8850, loss: 0.2143
2022-11-29 18:47:32,266 - mmseg - INFO - Iter [9150/40000]	lr: 4.628e-05, eta: 2:20:54, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3114, decode.acc_seg: 89.7812, loss: 0.3114
2022-11-29 18:47:45,367 - mmseg - INFO - Iter [9200/40000]	lr: 4.620e-05, eta: 2:20:38, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2560, decode.acc_seg: 90.0844, loss: 0.2560
2022-11-29 18:47:58,535 - mmseg - INFO - Iter [9250/40000]	lr: 4.613e-05, eta: 2:20:23, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1735, decode.acc_seg: 94.0542, loss: 0.1735
2022-11-29 18:48:11,857 - mmseg - INFO - Iter [9300/40000]	lr: 4.605e-05, eta: 2:20:08, time: 0.266, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2040, decode.acc_seg: 92.5326, loss: 0.2040
2022-11-29 18:48:25,133 - mmseg - INFO - Iter [9350/40000]	lr: 4.598e-05, eta: 2:19:53, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2377, decode.acc_seg: 90.7016, loss: 0.2377
2022-11-29 18:48:38,352 - mmseg - INFO - Iter [9400/40000]	lr: 4.590e-05, eta: 2:19:37, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3137, decode.acc_seg: 89.2252, loss: 0.3137
2022-11-29 18:48:51,572 - mmseg - INFO - Iter [9450/40000]	lr: 4.583e-05, eta: 2:19:22, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2534, decode.acc_seg: 90.8537, loss: 0.2534
2022-11-29 18:49:04,871 - mmseg - INFO - Iter [9500/40000]	lr: 4.575e-05, eta: 2:19:07, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3123, decode.acc_seg: 89.9753, loss: 0.3123
2022-11-29 18:49:18,090 - mmseg - INFO - Iter [9550/40000]	lr: 4.568e-05, eta: 2:18:52, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3787, decode.acc_seg: 87.2712, loss: 0.3787
2022-11-29 18:49:31,331 - mmseg - INFO - Iter [9600/40000]	lr: 4.560e-05, eta: 2:18:37, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3016, decode.acc_seg: 88.3328, loss: 0.3016
2022-11-29 18:49:44,570 - mmseg - INFO - Iter [9650/40000]	lr: 4.553e-05, eta: 2:18:22, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3335, decode.acc_seg: 89.1854, loss: 0.3335
2022-11-29 18:49:57,891 - mmseg - INFO - Iter [9700/40000]	lr: 4.545e-05, eta: 2:18:07, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.5280, decode.acc_seg: 83.0745, loss: 0.5280
2022-11-29 18:50:11,108 - mmseg - INFO - Iter [9750/40000]	lr: 4.538e-05, eta: 2:17:52, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3950, decode.acc_seg: 87.3312, loss: 0.3950
2022-11-29 18:50:24,327 - mmseg - INFO - Iter [9800/40000]	lr: 4.530e-05, eta: 2:17:37, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3202, decode.acc_seg: 88.6450, loss: 0.3202
2022-11-29 18:50:37,565 - mmseg - INFO - Iter [9850/40000]	lr: 4.523e-05, eta: 2:17:22, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3741, decode.acc_seg: 88.6268, loss: 0.3741
2022-11-29 18:50:50,865 - mmseg - INFO - Iter [9900/40000]	lr: 4.515e-05, eta: 2:17:07, time: 0.266, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3423, decode.acc_seg: 89.0211, loss: 0.3423
2022-11-29 18:51:04,137 - mmseg - INFO - Iter [9950/40000]	lr: 4.508e-05, eta: 2:16:52, time: 0.265, data_time: 0.007, memory: 5537, decode.loss_ce: 0.4093, decode.acc_seg: 85.8385, loss: 0.4093
2022-11-29 18:51:17,394 - mmseg - INFO - Saving checkpoint at 10000 iterations
2022-11-29 18:51:20,026 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:51:20,027 - mmseg - INFO - Iter [10000/40000]	lr: 4.500e-05, eta: 2:16:45, time: 0.318, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2867, decode.acc_seg: 91.0363, loss: 0.2867
2022-11-29 18:52:01,858 - mmseg - INFO - per class results:
2022-11-29 18:52:01,860 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 91.35 | 96.08 |
|  aeroplane  | 67.55 | 85.87 |
|   bicycle   | 42.06 | 66.37 |
|     bird    | 65.05 | 66.58 |
|     boat    | 64.65 | 88.33 |
|    bottle   | 60.95 | 72.86 |
|     bus     | 81.78 |  94.4 |
|     car     | 45.19 | 87.62 |
|     cat     | 73.79 | 76.42 |
|    chair    | 15.22 | 16.67 |
|     cow     | 43.56 | 72.89 |
| diningtable | 54.19 | 70.06 |
|     dog     | 67.09 | 80.83 |
|    horse    | 49.66 | 52.17 |
|  motorbike  | 64.87 | 85.86 |
|    person   | 79.69 | 91.52 |
| pottedplant | 34.69 | 39.39 |
|    sheep    | 37.48 | 38.92 |
|     sofa    | 24.66 | 27.39 |
|    train    | 68.68 | 78.43 |
|  tvmonitor  |  50.9 | 70.74 |
+-------------+-------+-------+
2022-11-29 18:52:01,860 - mmseg - INFO - Summary:
2022-11-29 18:52:01,860 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 90.05 | 56.34 | 69.5 |
+-------+-------+------+
2022-11-29 18:52:01,862 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:52:01,862 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9005, mIoU: 0.5634, mAcc: 0.6950, IoU.background: 0.9135, IoU.aeroplane: 0.6755, IoU.bicycle: 0.4206, IoU.bird: 0.6505, IoU.boat: 0.6465, IoU.bottle: 0.6095, IoU.bus: 0.8178, IoU.car: 0.4519, IoU.cat: 0.7379, IoU.chair: 0.1522, IoU.cow: 0.4356, IoU.diningtable: 0.5419, IoU.dog: 0.6709, IoU.horse: 0.4966, IoU.motorbike: 0.6487, IoU.person: 0.7969, IoU.pottedplant: 0.3469, IoU.sheep: 0.3748, IoU.sofa: 0.2466, IoU.train: 0.6868, IoU.tvmonitor: 0.5090, Acc.background: 0.9608, Acc.aeroplane: 0.8587, Acc.bicycle: 0.6637, Acc.bird: 0.6658, Acc.boat: 0.8833, Acc.bottle: 0.7286, Acc.bus: 0.9440, Acc.car: 0.8762, Acc.cat: 0.7642, Acc.chair: 0.1667, Acc.cow: 0.7289, Acc.diningtable: 0.7006, Acc.dog: 0.8083, Acc.horse: 0.5217, Acc.motorbike: 0.8586, Acc.person: 0.9152, Acc.pottedplant: 0.3939, Acc.sheep: 0.3892, Acc.sofa: 0.2739, Acc.train: 0.7843, Acc.tvmonitor: 0.7074
2022-11-29 18:52:15,130 - mmseg - INFO - Iter [10050/40000]	lr: 4.493e-05, eta: 2:18:35, time: 1.102, data_time: 0.843, memory: 5537, decode.loss_ce: 0.3790, decode.acc_seg: 86.7646, loss: 0.3790
2022-11-29 18:52:28,340 - mmseg - INFO - Iter [10100/40000]	lr: 4.485e-05, eta: 2:18:19, time: 0.264, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3738, decode.acc_seg: 84.7104, loss: 0.3738
2022-11-29 18:52:41,546 - mmseg - INFO - Iter [10150/40000]	lr: 4.478e-05, eta: 2:18:03, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2719, decode.acc_seg: 90.5046, loss: 0.2719
2022-11-29 18:52:54,706 - mmseg - INFO - Iter [10200/40000]	lr: 4.470e-05, eta: 2:17:47, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2321, decode.acc_seg: 92.3943, loss: 0.2321
2022-11-29 18:53:09,911 - mmseg - INFO - Iter [10250/40000]	lr: 4.463e-05, eta: 2:17:37, time: 0.304, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2025, decode.acc_seg: 92.5079, loss: 0.2025
2022-11-29 18:53:23,125 - mmseg - INFO - Iter [10300/40000]	lr: 4.455e-05, eta: 2:17:22, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3514, decode.acc_seg: 86.9721, loss: 0.3514
2022-11-29 18:53:36,276 - mmseg - INFO - Iter [10350/40000]	lr: 4.448e-05, eta: 2:17:06, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3803, decode.acc_seg: 89.3034, loss: 0.3803
2022-11-29 18:53:49,389 - mmseg - INFO - Iter [10400/40000]	lr: 4.440e-05, eta: 2:16:50, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3528, decode.acc_seg: 90.2293, loss: 0.3528
2022-11-29 18:54:02,491 - mmseg - INFO - Iter [10450/40000]	lr: 4.433e-05, eta: 2:16:34, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2795, decode.acc_seg: 91.0042, loss: 0.2795
2022-11-29 18:54:15,618 - mmseg - INFO - Iter [10500/40000]	lr: 4.425e-05, eta: 2:16:18, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2290, decode.acc_seg: 90.7811, loss: 0.2290
2022-11-29 18:54:28,905 - mmseg - INFO - Iter [10550/40000]	lr: 4.418e-05, eta: 2:16:02, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2479, decode.acc_seg: 90.5272, loss: 0.2479
2022-11-29 18:54:42,111 - mmseg - INFO - Iter [10600/40000]	lr: 4.410e-05, eta: 2:15:46, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2769, decode.acc_seg: 90.7710, loss: 0.2769
2022-11-29 18:54:55,320 - mmseg - INFO - Iter [10650/40000]	lr: 4.403e-05, eta: 2:15:31, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3178, decode.acc_seg: 89.8435, loss: 0.3178
2022-11-29 18:55:08,552 - mmseg - INFO - Iter [10700/40000]	lr: 4.395e-05, eta: 2:15:15, time: 0.265, data_time: 0.007, memory: 5537, decode.loss_ce: 0.1822, decode.acc_seg: 93.3438, loss: 0.1822
2022-11-29 18:55:21,754 - mmseg - INFO - Iter [10750/40000]	lr: 4.388e-05, eta: 2:15:00, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2465, decode.acc_seg: 91.4423, loss: 0.2465
2022-11-29 18:55:34,981 - mmseg - INFO - Iter [10800/40000]	lr: 4.380e-05, eta: 2:14:44, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2489, decode.acc_seg: 89.6839, loss: 0.2489
2022-11-29 18:55:48,256 - mmseg - INFO - Iter [10850/40000]	lr: 4.373e-05, eta: 2:14:29, time: 0.266, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2993, decode.acc_seg: 88.7549, loss: 0.2993
2022-11-29 18:56:01,521 - mmseg - INFO - Iter [10900/40000]	lr: 4.365e-05, eta: 2:14:13, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2320, decode.acc_seg: 91.1198, loss: 0.2320
2022-11-29 18:56:14,768 - mmseg - INFO - Iter [10950/40000]	lr: 4.358e-05, eta: 2:13:58, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1854, decode.acc_seg: 92.9209, loss: 0.1854
2022-11-29 18:56:27,979 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 18:56:27,979 - mmseg - INFO - Iter [11000/40000]	lr: 4.350e-05, eta: 2:13:42, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2541, decode.acc_seg: 90.4653, loss: 0.2541
2022-11-29 18:56:41,243 - mmseg - INFO - Iter [11050/40000]	lr: 4.343e-05, eta: 2:13:27, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2463, decode.acc_seg: 91.3263, loss: 0.2463
2022-11-29 18:56:54,377 - mmseg - INFO - Iter [11100/40000]	lr: 4.335e-05, eta: 2:13:12, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3547, decode.acc_seg: 88.0400, loss: 0.3547
2022-11-29 18:57:07,576 - mmseg - INFO - Iter [11150/40000]	lr: 4.328e-05, eta: 2:12:56, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1900, decode.acc_seg: 93.5317, loss: 0.1900
2022-11-29 18:57:20,813 - mmseg - INFO - Iter [11200/40000]	lr: 4.320e-05, eta: 2:12:41, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3496, decode.acc_seg: 87.7062, loss: 0.3496
2022-11-29 18:57:33,957 - mmseg - INFO - Iter [11250/40000]	lr: 4.313e-05, eta: 2:12:25, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2195, decode.acc_seg: 91.8757, loss: 0.2195
2022-11-29 18:57:47,091 - mmseg - INFO - Iter [11300/40000]	lr: 4.305e-05, eta: 2:12:10, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2820, decode.acc_seg: 89.6317, loss: 0.2820
2022-11-29 18:58:00,187 - mmseg - INFO - Iter [11350/40000]	lr: 4.298e-05, eta: 2:11:54, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2674, decode.acc_seg: 91.0462, loss: 0.2674
2022-11-29 18:58:13,288 - mmseg - INFO - Iter [11400/40000]	lr: 4.290e-05, eta: 2:11:38, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3094, decode.acc_seg: 88.1722, loss: 0.3094
2022-11-29 18:58:26,410 - mmseg - INFO - Iter [11450/40000]	lr: 4.283e-05, eta: 2:11:23, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3241, decode.acc_seg: 89.8095, loss: 0.3241
2022-11-29 18:58:39,501 - mmseg - INFO - Iter [11500/40000]	lr: 4.275e-05, eta: 2:11:07, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3275, decode.acc_seg: 88.3002, loss: 0.3275
2022-11-29 18:58:52,604 - mmseg - INFO - Iter [11550/40000]	lr: 4.268e-05, eta: 2:10:52, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3337, decode.acc_seg: 89.5840, loss: 0.3337
2022-11-29 18:59:05,708 - mmseg - INFO - Iter [11600/40000]	lr: 4.260e-05, eta: 2:10:36, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2193, decode.acc_seg: 91.3884, loss: 0.2193
2022-11-29 18:59:18,800 - mmseg - INFO - Iter [11650/40000]	lr: 4.253e-05, eta: 2:10:21, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1697, decode.acc_seg: 93.5624, loss: 0.1697
2022-11-29 18:59:31,907 - mmseg - INFO - Iter [11700/40000]	lr: 4.245e-05, eta: 2:10:05, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3052, decode.acc_seg: 89.6083, loss: 0.3052
2022-11-29 18:59:47,158 - mmseg - INFO - Iter [11750/40000]	lr: 4.238e-05, eta: 2:09:55, time: 0.305, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2619, decode.acc_seg: 91.1152, loss: 0.2619
2022-11-29 19:00:00,277 - mmseg - INFO - Iter [11800/40000]	lr: 4.230e-05, eta: 2:09:40, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1938, decode.acc_seg: 92.9079, loss: 0.1938
2022-11-29 19:00:13,419 - mmseg - INFO - Iter [11850/40000]	lr: 4.223e-05, eta: 2:09:24, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2088, decode.acc_seg: 91.8372, loss: 0.2088
2022-11-29 19:00:26,517 - mmseg - INFO - Iter [11900/40000]	lr: 4.215e-05, eta: 2:09:09, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1840, decode.acc_seg: 93.7269, loss: 0.1840
2022-11-29 19:00:39,644 - mmseg - INFO - Iter [11950/40000]	lr: 4.208e-05, eta: 2:08:53, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2344, decode.acc_seg: 92.1010, loss: 0.2344
2022-11-29 19:00:52,743 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:00:52,743 - mmseg - INFO - Iter [12000/40000]	lr: 4.200e-05, eta: 2:08:38, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1810, decode.acc_seg: 93.7839, loss: 0.1810
2022-11-29 19:01:05,935 - mmseg - INFO - Iter [12050/40000]	lr: 4.193e-05, eta: 2:08:23, time: 0.264, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2337, decode.acc_seg: 88.8580, loss: 0.2337
2022-11-29 19:01:19,102 - mmseg - INFO - Iter [12100/40000]	lr: 4.185e-05, eta: 2:08:08, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2131, decode.acc_seg: 91.6084, loss: 0.2131
2022-11-29 19:01:32,582 - mmseg - INFO - Iter [12150/40000]	lr: 4.178e-05, eta: 2:07:53, time: 0.270, data_time: 0.007, memory: 5537, decode.loss_ce: 0.1906, decode.acc_seg: 92.5685, loss: 0.1906
2022-11-29 19:01:45,814 - mmseg - INFO - Iter [12200/40000]	lr: 4.170e-05, eta: 2:07:38, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1608, decode.acc_seg: 93.4125, loss: 0.1608
2022-11-29 19:01:58,991 - mmseg - INFO - Iter [12250/40000]	lr: 4.163e-05, eta: 2:07:23, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1962, decode.acc_seg: 93.1366, loss: 0.1962
2022-11-29 19:02:12,191 - mmseg - INFO - Iter [12300/40000]	lr: 4.155e-05, eta: 2:07:08, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1651, decode.acc_seg: 92.7392, loss: 0.1651
2022-11-29 19:02:25,414 - mmseg - INFO - Iter [12350/40000]	lr: 4.148e-05, eta: 2:06:53, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2554, decode.acc_seg: 91.4825, loss: 0.2554
2022-11-29 19:02:38,600 - mmseg - INFO - Iter [12400/40000]	lr: 4.140e-05, eta: 2:06:38, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2475, decode.acc_seg: 89.8539, loss: 0.2475
2022-11-29 19:02:51,795 - mmseg - INFO - Iter [12450/40000]	lr: 4.133e-05, eta: 2:06:23, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3014, decode.acc_seg: 90.2862, loss: 0.3014
2022-11-29 19:03:04,991 - mmseg - INFO - Iter [12500/40000]	lr: 4.125e-05, eta: 2:06:08, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3140, decode.acc_seg: 90.7450, loss: 0.3140
2022-11-29 19:03:18,182 - mmseg - INFO - Iter [12550/40000]	lr: 4.118e-05, eta: 2:05:53, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2302, decode.acc_seg: 92.1324, loss: 0.2302
2022-11-29 19:03:31,368 - mmseg - INFO - Iter [12600/40000]	lr: 4.110e-05, eta: 2:05:38, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2241, decode.acc_seg: 91.4025, loss: 0.2241
2022-11-29 19:03:44,610 - mmseg - INFO - Iter [12650/40000]	lr: 4.103e-05, eta: 2:05:23, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2489, decode.acc_seg: 91.0039, loss: 0.2489
2022-11-29 19:03:57,814 - mmseg - INFO - Iter [12700/40000]	lr: 4.095e-05, eta: 2:05:08, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3676, decode.acc_seg: 85.7555, loss: 0.3676
2022-11-29 19:04:11,042 - mmseg - INFO - Iter [12750/40000]	lr: 4.088e-05, eta: 2:04:53, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3671, decode.acc_seg: 87.9564, loss: 0.3671
2022-11-29 19:04:24,221 - mmseg - INFO - Iter [12800/40000]	lr: 4.080e-05, eta: 2:04:38, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2296, decode.acc_seg: 92.0157, loss: 0.2296
2022-11-29 19:04:37,436 - mmseg - INFO - Iter [12850/40000]	lr: 4.073e-05, eta: 2:04:23, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2046, decode.acc_seg: 91.4928, loss: 0.2046
2022-11-29 19:04:50,652 - mmseg - INFO - Iter [12900/40000]	lr: 4.065e-05, eta: 2:04:09, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.4109, decode.acc_seg: 83.8868, loss: 0.4109
2022-11-29 19:05:03,877 - mmseg - INFO - Iter [12950/40000]	lr: 4.058e-05, eta: 2:03:54, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3219, decode.acc_seg: 89.7067, loss: 0.3219
2022-11-29 19:05:17,094 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:05:17,095 - mmseg - INFO - Iter [13000/40000]	lr: 4.050e-05, eta: 2:03:39, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3434, decode.acc_seg: 87.8183, loss: 0.3434
2022-11-29 19:05:30,423 - mmseg - INFO - Iter [13050/40000]	lr: 4.043e-05, eta: 2:03:24, time: 0.267, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2932, decode.acc_seg: 89.0313, loss: 0.2932
2022-11-29 19:05:43,681 - mmseg - INFO - Iter [13100/40000]	lr: 4.035e-05, eta: 2:03:10, time: 0.265, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2140, decode.acc_seg: 92.4086, loss: 0.2140
2022-11-29 19:05:56,910 - mmseg - INFO - Iter [13150/40000]	lr: 4.028e-05, eta: 2:02:55, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2784, decode.acc_seg: 88.7589, loss: 0.2784
2022-11-29 19:06:12,225 - mmseg - INFO - Iter [13200/40000]	lr: 4.020e-05, eta: 2:02:44, time: 0.306, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2247, decode.acc_seg: 91.9274, loss: 0.2247
2022-11-29 19:06:25,538 - mmseg - INFO - Iter [13250/40000]	lr: 4.013e-05, eta: 2:02:30, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1447, decode.acc_seg: 94.6817, loss: 0.1447
2022-11-29 19:06:38,790 - mmseg - INFO - Iter [13300/40000]	lr: 4.005e-05, eta: 2:02:15, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1973, decode.acc_seg: 92.9252, loss: 0.1973
2022-11-29 19:06:51,968 - mmseg - INFO - Iter [13350/40000]	lr: 3.998e-05, eta: 2:02:00, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1431, decode.acc_seg: 93.8596, loss: 0.1431
2022-11-29 19:07:05,114 - mmseg - INFO - Iter [13400/40000]	lr: 3.990e-05, eta: 2:01:45, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1845, decode.acc_seg: 92.2972, loss: 0.1845
2022-11-29 19:07:18,245 - mmseg - INFO - Iter [13450/40000]	lr: 3.983e-05, eta: 2:01:30, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3210, decode.acc_seg: 89.5087, loss: 0.3210
2022-11-29 19:07:31,383 - mmseg - INFO - Iter [13500/40000]	lr: 3.975e-05, eta: 2:01:15, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2327, decode.acc_seg: 91.8801, loss: 0.2327
2022-11-29 19:07:44,536 - mmseg - INFO - Iter [13550/40000]	lr: 3.968e-05, eta: 2:01:01, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2602, decode.acc_seg: 91.2011, loss: 0.2602
2022-11-29 19:07:57,651 - mmseg - INFO - Iter [13600/40000]	lr: 3.960e-05, eta: 2:00:46, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2899, decode.acc_seg: 90.2351, loss: 0.2899
2022-11-29 19:08:10,789 - mmseg - INFO - Iter [13650/40000]	lr: 3.953e-05, eta: 2:00:31, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2138, decode.acc_seg: 92.6736, loss: 0.2138
2022-11-29 19:08:23,949 - mmseg - INFO - Iter [13700/40000]	lr: 3.945e-05, eta: 2:00:16, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2002, decode.acc_seg: 92.1562, loss: 0.2002
2022-11-29 19:08:37,071 - mmseg - INFO - Iter [13750/40000]	lr: 3.938e-05, eta: 2:00:01, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1316, decode.acc_seg: 95.3070, loss: 0.1316
2022-11-29 19:08:50,310 - mmseg - INFO - Iter [13800/40000]	lr: 3.930e-05, eta: 1:59:46, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2847, decode.acc_seg: 90.6989, loss: 0.2847
2022-11-29 19:09:03,534 - mmseg - INFO - Iter [13850/40000]	lr: 3.923e-05, eta: 1:59:32, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1905, decode.acc_seg: 93.2695, loss: 0.1905
2022-11-29 19:09:16,762 - mmseg - INFO - Iter [13900/40000]	lr: 3.915e-05, eta: 1:59:17, time: 0.265, data_time: 0.007, memory: 5537, decode.loss_ce: 0.1711, decode.acc_seg: 94.1224, loss: 0.1711
2022-11-29 19:09:29,998 - mmseg - INFO - Iter [13950/40000]	lr: 3.908e-05, eta: 1:59:03, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1849, decode.acc_seg: 93.2594, loss: 0.1849
2022-11-29 19:09:43,288 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:09:43,288 - mmseg - INFO - Iter [14000/40000]	lr: 3.900e-05, eta: 1:58:48, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2787, decode.acc_seg: 90.4726, loss: 0.2787
2022-11-29 19:09:56,446 - mmseg - INFO - Iter [14050/40000]	lr: 3.893e-05, eta: 1:58:33, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3082, decode.acc_seg: 89.1115, loss: 0.3082
2022-11-29 19:10:09,652 - mmseg - INFO - Iter [14100/40000]	lr: 3.885e-05, eta: 1:58:19, time: 0.264, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3978, decode.acc_seg: 88.8957, loss: 0.3978
2022-11-29 19:10:22,812 - mmseg - INFO - Iter [14150/40000]	lr: 3.878e-05, eta: 1:58:04, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 0.3309, decode.acc_seg: 89.3751, loss: 0.3309
2022-11-29 19:10:36,090 - mmseg - INFO - Iter [14200/40000]	lr: 3.870e-05, eta: 1:57:50, time: 0.266, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2986, decode.acc_seg: 89.7743, loss: 0.2986
2022-11-29 19:10:49,324 - mmseg - INFO - Iter [14250/40000]	lr: 3.863e-05, eta: 1:57:35, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3499, decode.acc_seg: 90.0582, loss: 0.3499
2022-11-29 19:11:02,602 - mmseg - INFO - Iter [14300/40000]	lr: 3.855e-05, eta: 1:57:21, time: 0.266, data_time: 0.008, memory: 5537, decode.loss_ce: 0.2318, decode.acc_seg: 92.8326, loss: 0.2318
2022-11-29 19:11:15,827 - mmseg - INFO - Iter [14350/40000]	lr: 3.848e-05, eta: 1:57:06, time: 0.264, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2593, decode.acc_seg: 91.3384, loss: 0.2593
2022-11-29 19:11:28,987 - mmseg - INFO - Iter [14400/40000]	lr: 3.840e-05, eta: 1:56:51, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3292, decode.acc_seg: 88.8889, loss: 0.3292
2022-11-29 19:11:42,184 - mmseg - INFO - Iter [14450/40000]	lr: 3.833e-05, eta: 1:56:37, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1988, decode.acc_seg: 92.8047, loss: 0.1988
2022-11-29 19:11:55,337 - mmseg - INFO - Iter [14500/40000]	lr: 3.825e-05, eta: 1:56:22, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2188, decode.acc_seg: 91.2734, loss: 0.2188
2022-11-29 19:12:08,531 - mmseg - INFO - Iter [14550/40000]	lr: 3.818e-05, eta: 1:56:08, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2094, decode.acc_seg: 92.6466, loss: 0.2094
2022-11-29 19:12:21,706 - mmseg - INFO - Iter [14600/40000]	lr: 3.810e-05, eta: 1:55:53, time: 0.264, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2260, decode.acc_seg: 92.3951, loss: 0.2260
2022-11-29 19:12:36,970 - mmseg - INFO - Iter [14650/40000]	lr: 3.803e-05, eta: 1:55:42, time: 0.305, data_time: 0.048, memory: 5537, decode.loss_ce: 0.2657, decode.acc_seg: 91.5198, loss: 0.2657
2022-11-29 19:12:50,073 - mmseg - INFO - Iter [14700/40000]	lr: 3.795e-05, eta: 1:55:27, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2474, decode.acc_seg: 91.0526, loss: 0.2474
2022-11-29 19:13:03,154 - mmseg - INFO - Iter [14750/40000]	lr: 3.788e-05, eta: 1:55:13, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2343, decode.acc_seg: 91.2802, loss: 0.2343
2022-11-29 19:13:16,237 - mmseg - INFO - Iter [14800/40000]	lr: 3.780e-05, eta: 1:54:58, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2633, decode.acc_seg: 90.6919, loss: 0.2633
2022-11-29 19:13:29,334 - mmseg - INFO - Iter [14850/40000]	lr: 3.773e-05, eta: 1:54:43, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1887, decode.acc_seg: 93.2737, loss: 0.1887
2022-11-29 19:13:42,529 - mmseg - INFO - Iter [14900/40000]	lr: 3.765e-05, eta: 1:54:29, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2794, decode.acc_seg: 89.2417, loss: 0.2794
2022-11-29 19:13:55,618 - mmseg - INFO - Iter [14950/40000]	lr: 3.758e-05, eta: 1:54:14, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2506, decode.acc_seg: 91.6988, loss: 0.2506
2022-11-29 19:14:08,713 - mmseg - INFO - Saving checkpoint at 15000 iterations
2022-11-29 19:14:10,547 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:14:10,548 - mmseg - INFO - Iter [15000/40000]	lr: 3.750e-05, eta: 1:54:02, time: 0.299, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2673, decode.acc_seg: 91.3725, loss: 0.2673
2022-11-29 19:14:52,511 - mmseg - INFO - per class results:
2022-11-29 19:14:52,512 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  91.8 | 96.31 |
|  aeroplane  | 81.14 | 92.17 |
|   bicycle   | 53.73 | 70.36 |
|     bird    | 84.88 | 90.92 |
|     boat    | 55.86 |  72.5 |
|    bottle   | 68.37 | 77.14 |
|     bus     | 75.94 | 81.78 |
|     car     |  71.6 | 85.85 |
|     cat     |  85.4 | 91.47 |
|    chair    | 33.74 | 46.71 |
|     cow     | 50.32 | 51.96 |
| diningtable | 50.53 | 55.21 |
|     dog     | 70.04 | 88.87 |
|    horse    | 53.52 | 68.42 |
|  motorbike  | 73.53 | 94.77 |
|    person   | 78.78 | 93.23 |
| pottedplant | 38.22 | 43.99 |
|    sheep    |  63.7 | 69.44 |
|     sofa    | 51.25 | 61.01 |
|    train    | 74.18 | 86.03 |
|  tvmonitor  | 46.06 | 60.02 |
+-------------+-------+-------+
2022-11-29 19:14:52,512 - mmseg - INFO - Summary:
2022-11-29 19:14:52,512 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 91.74 | 64.41 | 75.15 |
+-------+-------+-------+
2022-11-29 19:14:52,514 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:14:52,514 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9174, mIoU: 0.6441, mAcc: 0.7515, IoU.background: 0.9180, IoU.aeroplane: 0.8114, IoU.bicycle: 0.5373, IoU.bird: 0.8488, IoU.boat: 0.5586, IoU.bottle: 0.6837, IoU.bus: 0.7594, IoU.car: 0.7160, IoU.cat: 0.8540, IoU.chair: 0.3374, IoU.cow: 0.5032, IoU.diningtable: 0.5053, IoU.dog: 0.7004, IoU.horse: 0.5352, IoU.motorbike: 0.7353, IoU.person: 0.7878, IoU.pottedplant: 0.3822, IoU.sheep: 0.6370, IoU.sofa: 0.5125, IoU.train: 0.7418, IoU.tvmonitor: 0.4606, Acc.background: 0.9631, Acc.aeroplane: 0.9217, Acc.bicycle: 0.7036, Acc.bird: 0.9092, Acc.boat: 0.7250, Acc.bottle: 0.7714, Acc.bus: 0.8178, Acc.car: 0.8585, Acc.cat: 0.9147, Acc.chair: 0.4671, Acc.cow: 0.5196, Acc.diningtable: 0.5521, Acc.dog: 0.8887, Acc.horse: 0.6842, Acc.motorbike: 0.9477, Acc.person: 0.9323, Acc.pottedplant: 0.4399, Acc.sheep: 0.6944, Acc.sofa: 0.6101, Acc.train: 0.8603, Acc.tvmonitor: 0.6002
2022-11-29 19:15:05,985 - mmseg - INFO - Iter [15050/40000]	lr: 3.743e-05, eta: 1:54:58, time: 1.109, data_time: 0.846, memory: 5537, decode.loss_ce: 0.2002, decode.acc_seg: 93.3626, loss: 0.2002
2022-11-29 19:15:19,131 - mmseg - INFO - Iter [15100/40000]	lr: 3.735e-05, eta: 1:54:43, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2871, decode.acc_seg: 90.5283, loss: 0.2871
2022-11-29 19:15:32,311 - mmseg - INFO - Iter [15150/40000]	lr: 3.728e-05, eta: 1:54:28, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1956, decode.acc_seg: 92.6648, loss: 0.1956
2022-11-29 19:15:45,539 - mmseg - INFO - Iter [15200/40000]	lr: 3.720e-05, eta: 1:54:13, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3009, decode.acc_seg: 90.3214, loss: 0.3009
2022-11-29 19:15:58,730 - mmseg - INFO - Iter [15250/40000]	lr: 3.713e-05, eta: 1:53:58, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2179, decode.acc_seg: 91.5454, loss: 0.2179
2022-11-29 19:16:12,122 - mmseg - INFO - Iter [15300/40000]	lr: 3.705e-05, eta: 1:53:44, time: 0.268, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2737, decode.acc_seg: 88.3090, loss: 0.2737
2022-11-29 19:16:25,283 - mmseg - INFO - Iter [15350/40000]	lr: 3.698e-05, eta: 1:53:29, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2437, decode.acc_seg: 91.4109, loss: 0.2437
2022-11-29 19:16:38,506 - mmseg - INFO - Iter [15400/40000]	lr: 3.690e-05, eta: 1:53:14, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1603, decode.acc_seg: 94.2045, loss: 0.1603
2022-11-29 19:16:51,739 - mmseg - INFO - Iter [15450/40000]	lr: 3.683e-05, eta: 1:53:00, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2068, decode.acc_seg: 93.2819, loss: 0.2068
2022-11-29 19:17:05,065 - mmseg - INFO - Iter [15500/40000]	lr: 3.675e-05, eta: 1:52:45, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1095, decode.acc_seg: 95.6928, loss: 0.1095
2022-11-29 19:17:18,306 - mmseg - INFO - Iter [15550/40000]	lr: 3.668e-05, eta: 1:52:30, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1831, decode.acc_seg: 93.2355, loss: 0.1831
2022-11-29 19:17:31,521 - mmseg - INFO - Iter [15600/40000]	lr: 3.660e-05, eta: 1:52:16, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1654, decode.acc_seg: 93.4009, loss: 0.1654
2022-11-29 19:17:44,777 - mmseg - INFO - Iter [15650/40000]	lr: 3.653e-05, eta: 1:52:01, time: 0.265, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2468, decode.acc_seg: 89.8469, loss: 0.2468
2022-11-29 19:17:57,933 - mmseg - INFO - Iter [15700/40000]	lr: 3.645e-05, eta: 1:51:46, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1930, decode.acc_seg: 92.2421, loss: 0.1930
2022-11-29 19:18:11,049 - mmseg - INFO - Iter [15750/40000]	lr: 3.638e-05, eta: 1:51:31, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1671, decode.acc_seg: 94.3682, loss: 0.1671
2022-11-29 19:18:24,179 - mmseg - INFO - Iter [15800/40000]	lr: 3.630e-05, eta: 1:51:16, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2402, decode.acc_seg: 90.7668, loss: 0.2402
2022-11-29 19:18:37,280 - mmseg - INFO - Iter [15850/40000]	lr: 3.623e-05, eta: 1:51:02, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2696, decode.acc_seg: 89.7911, loss: 0.2696
2022-11-29 19:18:50,465 - mmseg - INFO - Iter [15900/40000]	lr: 3.615e-05, eta: 1:50:47, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1518, decode.acc_seg: 94.7180, loss: 0.1518
2022-11-29 19:19:03,732 - mmseg - INFO - Iter [15950/40000]	lr: 3.608e-05, eta: 1:50:32, time: 0.265, data_time: 0.008, memory: 5537, decode.loss_ce: 0.3811, decode.acc_seg: 90.0357, loss: 0.3811
2022-11-29 19:19:16,910 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:19:16,910 - mmseg - INFO - Iter [16000/40000]	lr: 3.600e-05, eta: 1:50:18, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3723, decode.acc_seg: 89.8797, loss: 0.3723
2022-11-29 19:19:30,099 - mmseg - INFO - Iter [16050/40000]	lr: 3.593e-05, eta: 1:50:03, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1690, decode.acc_seg: 94.3893, loss: 0.1690
2022-11-29 19:19:43,280 - mmseg - INFO - Iter [16100/40000]	lr: 3.585e-05, eta: 1:49:48, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2658, decode.acc_seg: 91.7539, loss: 0.2658
2022-11-29 19:19:58,558 - mmseg - INFO - Iter [16150/40000]	lr: 3.578e-05, eta: 1:49:37, time: 0.306, data_time: 0.048, memory: 5537, decode.loss_ce: 0.3331, decode.acc_seg: 89.1429, loss: 0.3331
2022-11-29 19:20:11,798 - mmseg - INFO - Iter [16200/40000]	lr: 3.570e-05, eta: 1:49:22, time: 0.265, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2800, decode.acc_seg: 91.1571, loss: 0.2800
2022-11-29 19:20:25,026 - mmseg - INFO - Iter [16250/40000]	lr: 3.563e-05, eta: 1:49:07, time: 0.265, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2511, decode.acc_seg: 90.2329, loss: 0.2511
2022-11-29 19:20:38,273 - mmseg - INFO - Iter [16300/40000]	lr: 3.555e-05, eta: 1:48:53, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3031, decode.acc_seg: 88.8672, loss: 0.3031
2022-11-29 19:20:51,517 - mmseg - INFO - Iter [16350/40000]	lr: 3.548e-05, eta: 1:48:38, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2521, decode.acc_seg: 91.8823, loss: 0.2521
2022-11-29 19:21:04,795 - mmseg - INFO - Iter [16400/40000]	lr: 3.540e-05, eta: 1:48:24, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2579, decode.acc_seg: 90.2785, loss: 0.2579
2022-11-29 19:21:17,971 - mmseg - INFO - Iter [16450/40000]	lr: 3.533e-05, eta: 1:48:09, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 0.1467, decode.acc_seg: 94.8591, loss: 0.1467
2022-11-29 19:21:31,137 - mmseg - INFO - Iter [16500/40000]	lr: 3.525e-05, eta: 1:47:55, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2195, decode.acc_seg: 91.5370, loss: 0.2195
2022-11-29 19:21:44,278 - mmseg - INFO - Iter [16550/40000]	lr: 3.518e-05, eta: 1:47:40, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1528, decode.acc_seg: 94.6855, loss: 0.1528
2022-11-29 19:21:57,417 - mmseg - INFO - Iter [16600/40000]	lr: 3.510e-05, eta: 1:47:25, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1889, decode.acc_seg: 92.2380, loss: 0.1889
2022-11-29 19:22:10,583 - mmseg - INFO - Iter [16650/40000]	lr: 3.503e-05, eta: 1:47:11, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1337, decode.acc_seg: 95.2529, loss: 0.1337
2022-11-29 19:22:23,729 - mmseg - INFO - Iter [16700/40000]	lr: 3.495e-05, eta: 1:46:56, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2405, decode.acc_seg: 90.7249, loss: 0.2405
2022-11-29 19:22:36,805 - mmseg - INFO - Iter [16750/40000]	lr: 3.488e-05, eta: 1:46:41, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2605, decode.acc_seg: 90.9075, loss: 0.2605
2022-11-29 19:22:49,898 - mmseg - INFO - Iter [16800/40000]	lr: 3.480e-05, eta: 1:46:26, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2267, decode.acc_seg: 93.3969, loss: 0.2267
2022-11-29 19:23:02,993 - mmseg - INFO - Iter [16850/40000]	lr: 3.473e-05, eta: 1:46:12, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1675, decode.acc_seg: 92.9418, loss: 0.1675
2022-11-29 19:23:16,086 - mmseg - INFO - Iter [16900/40000]	lr: 3.465e-05, eta: 1:45:57, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1873, decode.acc_seg: 93.7434, loss: 0.1873
2022-11-29 19:23:29,164 - mmseg - INFO - Iter [16950/40000]	lr: 3.458e-05, eta: 1:45:42, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2089, decode.acc_seg: 92.7222, loss: 0.2089
2022-11-29 19:23:42,308 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:23:42,308 - mmseg - INFO - Iter [17000/40000]	lr: 3.450e-05, eta: 1:45:28, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2220, decode.acc_seg: 92.8744, loss: 0.2220
2022-11-29 19:23:55,498 - mmseg - INFO - Iter [17050/40000]	lr: 3.443e-05, eta: 1:45:13, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2173, decode.acc_seg: 93.3102, loss: 0.2173
2022-11-29 19:24:08,679 - mmseg - INFO - Iter [17100/40000]	lr: 3.435e-05, eta: 1:44:59, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2349, decode.acc_seg: 90.9346, loss: 0.2349
2022-11-29 19:24:21,995 - mmseg - INFO - Iter [17150/40000]	lr: 3.428e-05, eta: 1:44:44, time: 0.266, data_time: 0.007, memory: 5537, decode.loss_ce: 0.2579, decode.acc_seg: 90.9914, loss: 0.2579
2022-11-29 19:24:35,202 - mmseg - INFO - Iter [17200/40000]	lr: 3.420e-05, eta: 1:44:30, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2444, decode.acc_seg: 90.9007, loss: 0.2444
2022-11-29 19:24:48,465 - mmseg - INFO - Iter [17250/40000]	lr: 3.413e-05, eta: 1:44:16, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2464, decode.acc_seg: 92.2606, loss: 0.2464
2022-11-29 19:25:01,608 - mmseg - INFO - Iter [17300/40000]	lr: 3.405e-05, eta: 1:44:01, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1843, decode.acc_seg: 93.5259, loss: 0.1843
2022-11-29 19:25:14,768 - mmseg - INFO - Iter [17350/40000]	lr: 3.398e-05, eta: 1:43:46, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1862, decode.acc_seg: 92.9545, loss: 0.1862
2022-11-29 19:25:27,809 - mmseg - INFO - Iter [17400/40000]	lr: 3.390e-05, eta: 1:43:32, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1806, decode.acc_seg: 92.9725, loss: 0.1806
2022-11-29 19:25:40,843 - mmseg - INFO - Iter [17450/40000]	lr: 3.383e-05, eta: 1:43:17, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1817, decode.acc_seg: 94.2427, loss: 0.1817
2022-11-29 19:25:53,827 - mmseg - INFO - Iter [17500/40000]	lr: 3.375e-05, eta: 1:43:02, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2456, decode.acc_seg: 89.4166, loss: 0.2456
2022-11-29 19:26:06,876 - mmseg - INFO - Iter [17550/40000]	lr: 3.368e-05, eta: 1:42:48, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2656, decode.acc_seg: 90.6995, loss: 0.2656
2022-11-29 19:26:22,064 - mmseg - INFO - Iter [17600/40000]	lr: 3.360e-05, eta: 1:42:36, time: 0.304, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2020, decode.acc_seg: 92.6816, loss: 0.2020
2022-11-29 19:26:35,058 - mmseg - INFO - Iter [17650/40000]	lr: 3.353e-05, eta: 1:42:21, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1546, decode.acc_seg: 93.8862, loss: 0.1546
2022-11-29 19:26:48,057 - mmseg - INFO - Iter [17700/40000]	lr: 3.345e-05, eta: 1:42:07, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1178, decode.acc_seg: 95.5104, loss: 0.1178
2022-11-29 19:27:01,079 - mmseg - INFO - Iter [17750/40000]	lr: 3.338e-05, eta: 1:41:52, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0945, decode.acc_seg: 96.4867, loss: 0.0945
2022-11-29 19:27:14,057 - mmseg - INFO - Iter [17800/40000]	lr: 3.330e-05, eta: 1:41:37, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2654, decode.acc_seg: 91.8178, loss: 0.2654
2022-11-29 19:27:27,082 - mmseg - INFO - Iter [17850/40000]	lr: 3.323e-05, eta: 1:41:23, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1293, decode.acc_seg: 94.5803, loss: 0.1293
2022-11-29 19:27:40,098 - mmseg - INFO - Iter [17900/40000]	lr: 3.315e-05, eta: 1:41:08, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1430, decode.acc_seg: 94.5982, loss: 0.1430
2022-11-29 19:27:53,033 - mmseg - INFO - Iter [17950/40000]	lr: 3.308e-05, eta: 1:40:53, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2163, decode.acc_seg: 90.1314, loss: 0.2163
2022-11-29 19:28:06,077 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:28:06,077 - mmseg - INFO - Iter [18000/40000]	lr: 3.300e-05, eta: 1:40:39, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1867, decode.acc_seg: 93.2541, loss: 0.1867
2022-11-29 19:28:19,085 - mmseg - INFO - Iter [18050/40000]	lr: 3.293e-05, eta: 1:40:24, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1307, decode.acc_seg: 94.8032, loss: 0.1307
2022-11-29 19:28:32,098 - mmseg - INFO - Iter [18100/40000]	lr: 3.285e-05, eta: 1:40:10, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2063, decode.acc_seg: 93.0104, loss: 0.2063
2022-11-29 19:28:45,101 - mmseg - INFO - Iter [18150/40000]	lr: 3.278e-05, eta: 1:39:55, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1368, decode.acc_seg: 95.1563, loss: 0.1368
2022-11-29 19:28:58,105 - mmseg - INFO - Iter [18200/40000]	lr: 3.270e-05, eta: 1:39:40, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2185, decode.acc_seg: 89.7626, loss: 0.2185
2022-11-29 19:29:11,218 - mmseg - INFO - Iter [18250/40000]	lr: 3.263e-05, eta: 1:39:26, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1801, decode.acc_seg: 93.8685, loss: 0.1801
2022-11-29 19:29:24,218 - mmseg - INFO - Iter [18300/40000]	lr: 3.255e-05, eta: 1:39:11, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.3558, decode.acc_seg: 89.9428, loss: 0.3558
2022-11-29 19:29:37,243 - mmseg - INFO - Iter [18350/40000]	lr: 3.248e-05, eta: 1:38:57, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1465, decode.acc_seg: 94.4340, loss: 0.1465
2022-11-29 19:29:50,275 - mmseg - INFO - Iter [18400/40000]	lr: 3.240e-05, eta: 1:38:42, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1895, decode.acc_seg: 92.5816, loss: 0.1895
2022-11-29 19:30:03,350 - mmseg - INFO - Iter [18450/40000]	lr: 3.233e-05, eta: 1:38:28, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1652, decode.acc_seg: 93.6467, loss: 0.1652
2022-11-29 19:30:16,454 - mmseg - INFO - Iter [18500/40000]	lr: 3.225e-05, eta: 1:38:13, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1632, decode.acc_seg: 94.2785, loss: 0.1632
2022-11-29 19:30:29,536 - mmseg - INFO - Iter [18550/40000]	lr: 3.218e-05, eta: 1:37:59, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 0.0756, decode.acc_seg: 97.2346, loss: 0.0756
2022-11-29 19:30:42,501 - mmseg - INFO - Iter [18600/40000]	lr: 3.210e-05, eta: 1:37:45, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2068, decode.acc_seg: 94.0036, loss: 0.2068
2022-11-29 19:30:55,537 - mmseg - INFO - Iter [18650/40000]	lr: 3.203e-05, eta: 1:37:30, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1299, decode.acc_seg: 94.6980, loss: 0.1299
2022-11-29 19:31:08,620 - mmseg - INFO - Iter [18700/40000]	lr: 3.195e-05, eta: 1:37:16, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2573, decode.acc_seg: 91.2192, loss: 0.2573
2022-11-29 19:31:21,646 - mmseg - INFO - Iter [18750/40000]	lr: 3.188e-05, eta: 1:37:01, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1158, decode.acc_seg: 95.6352, loss: 0.1158
2022-11-29 19:31:34,616 - mmseg - INFO - Iter [18800/40000]	lr: 3.180e-05, eta: 1:36:47, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1850, decode.acc_seg: 92.5583, loss: 0.1850
2022-11-29 19:31:47,575 - mmseg - INFO - Iter [18850/40000]	lr: 3.173e-05, eta: 1:36:32, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2040, decode.acc_seg: 93.0000, loss: 0.2040
2022-11-29 19:32:00,525 - mmseg - INFO - Iter [18900/40000]	lr: 3.165e-05, eta: 1:36:18, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2767, decode.acc_seg: 91.5307, loss: 0.2767
2022-11-29 19:32:13,730 - mmseg - INFO - Iter [18950/40000]	lr: 3.158e-05, eta: 1:36:03, time: 0.264, data_time: 0.011, memory: 5537, decode.loss_ce: 0.1335, decode.acc_seg: 94.8201, loss: 0.1335
2022-11-29 19:32:26,711 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:32:26,711 - mmseg - INFO - Iter [19000/40000]	lr: 3.150e-05, eta: 1:35:49, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1931, decode.acc_seg: 93.3637, loss: 0.1931
2022-11-29 19:32:41,771 - mmseg - INFO - Iter [19050/40000]	lr: 3.143e-05, eta: 1:35:37, time: 0.301, data_time: 0.048, memory: 5537, decode.loss_ce: 0.1163, decode.acc_seg: 93.6004, loss: 0.1163
2022-11-29 19:32:54,725 - mmseg - INFO - Iter [19100/40000]	lr: 3.135e-05, eta: 1:35:22, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1491, decode.acc_seg: 94.2743, loss: 0.1491
2022-11-29 19:33:07,675 - mmseg - INFO - Iter [19150/40000]	lr: 3.128e-05, eta: 1:35:08, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1320, decode.acc_seg: 95.7222, loss: 0.1320
2022-11-29 19:33:20,833 - mmseg - INFO - Iter [19200/40000]	lr: 3.120e-05, eta: 1:34:53, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1360, decode.acc_seg: 94.6439, loss: 0.1360
2022-11-29 19:33:33,812 - mmseg - INFO - Iter [19250/40000]	lr: 3.113e-05, eta: 1:34:39, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1841, decode.acc_seg: 93.3836, loss: 0.1841
2022-11-29 19:33:46,786 - mmseg - INFO - Iter [19300/40000]	lr: 3.105e-05, eta: 1:34:25, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2927, decode.acc_seg: 90.7078, loss: 0.2927
2022-11-29 19:33:59,738 - mmseg - INFO - Iter [19350/40000]	lr: 3.098e-05, eta: 1:34:10, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1376, decode.acc_seg: 94.8462, loss: 0.1376
2022-11-29 19:34:12,684 - mmseg - INFO - Iter [19400/40000]	lr: 3.090e-05, eta: 1:33:56, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2243, decode.acc_seg: 92.7678, loss: 0.2243
2022-11-29 19:34:25,609 - mmseg - INFO - Iter [19450/40000]	lr: 3.083e-05, eta: 1:33:41, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1164, decode.acc_seg: 95.2128, loss: 0.1164
2022-11-29 19:34:38,609 - mmseg - INFO - Iter [19500/40000]	lr: 3.075e-05, eta: 1:33:27, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2384, decode.acc_seg: 91.0919, loss: 0.2384
2022-11-29 19:34:51,619 - mmseg - INFO - Iter [19550/40000]	lr: 3.068e-05, eta: 1:33:12, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1416, decode.acc_seg: 94.4700, loss: 0.1416
2022-11-29 19:35:04,641 - mmseg - INFO - Iter [19600/40000]	lr: 3.060e-05, eta: 1:32:58, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1587, decode.acc_seg: 93.9546, loss: 0.1587
2022-11-29 19:35:17,639 - mmseg - INFO - Iter [19650/40000]	lr: 3.053e-05, eta: 1:32:44, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1224, decode.acc_seg: 95.1683, loss: 0.1224
2022-11-29 19:35:30,629 - mmseg - INFO - Iter [19700/40000]	lr: 3.045e-05, eta: 1:32:29, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2189, decode.acc_seg: 92.6971, loss: 0.2189
2022-11-29 19:35:43,629 - mmseg - INFO - Iter [19750/40000]	lr: 3.038e-05, eta: 1:32:15, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2190, decode.acc_seg: 93.5776, loss: 0.2190
2022-11-29 19:35:56,657 - mmseg - INFO - Iter [19800/40000]	lr: 3.030e-05, eta: 1:32:01, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1616, decode.acc_seg: 94.4905, loss: 0.1616
2022-11-29 19:36:09,693 - mmseg - INFO - Iter [19850/40000]	lr: 3.023e-05, eta: 1:31:46, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1455, decode.acc_seg: 94.7328, loss: 0.1455
2022-11-29 19:36:22,739 - mmseg - INFO - Iter [19900/40000]	lr: 3.015e-05, eta: 1:31:32, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2030, decode.acc_seg: 92.2916, loss: 0.2030
2022-11-29 19:36:35,784 - mmseg - INFO - Iter [19950/40000]	lr: 3.008e-05, eta: 1:31:18, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2372, decode.acc_seg: 90.6632, loss: 0.2372
2022-11-29 19:36:48,822 - mmseg - INFO - Saving checkpoint at 20000 iterations
2022-11-29 19:36:51,760 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:36:51,760 - mmseg - INFO - Iter [20000/40000]	lr: 3.000e-05, eta: 1:31:06, time: 0.320, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1343, decode.acc_seg: 95.0397, loss: 0.1343
2022-11-29 19:37:33,359 - mmseg - INFO - per class results:
2022-11-29 19:37:33,360 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 92.27 | 97.41 |
|  aeroplane  | 80.11 | 90.55 |
|   bicycle   | 56.37 | 68.13 |
|     bird    | 82.79 | 90.01 |
|     boat    | 72.06 |  88.4 |
|    bottle   | 66.93 | 79.17 |
|     bus     | 61.29 | 68.14 |
|     car     | 59.16 | 75.99 |
|     cat     | 83.51 | 93.71 |
|    chair    |  33.1 | 41.46 |
|     cow     | 74.49 | 76.55 |
| diningtable | 51.87 | 56.03 |
|     dog     |  74.0 | 89.83 |
|    horse    | 76.37 | 84.12 |
|  motorbike  |  74.1 | 78.91 |
|    person   | 81.43 | 92.05 |
| pottedplant | 48.56 | 61.99 |
|    sheep    | 71.83 | 78.92 |
|     sofa    | 39.96 | 46.47 |
|    train    | 71.99 | 74.32 |
|  tvmonitor  | 48.91 | 53.87 |
+-------------+-------+-------+
2022-11-29 19:37:33,360 - mmseg - INFO - Summary:
2022-11-29 19:37:33,360 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 92.22 | 66.72 | 75.53 |
+-------+-------+-------+
2022-11-29 19:37:33,362 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:37:33,362 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9222, mIoU: 0.6672, mAcc: 0.7553, IoU.background: 0.9227, IoU.aeroplane: 0.8011, IoU.bicycle: 0.5637, IoU.bird: 0.8279, IoU.boat: 0.7206, IoU.bottle: 0.6693, IoU.bus: 0.6129, IoU.car: 0.5916, IoU.cat: 0.8351, IoU.chair: 0.3310, IoU.cow: 0.7449, IoU.diningtable: 0.5187, IoU.dog: 0.7400, IoU.horse: 0.7637, IoU.motorbike: 0.7410, IoU.person: 0.8143, IoU.pottedplant: 0.4856, IoU.sheep: 0.7183, IoU.sofa: 0.3996, IoU.train: 0.7199, IoU.tvmonitor: 0.4891, Acc.background: 0.9741, Acc.aeroplane: 0.9055, Acc.bicycle: 0.6813, Acc.bird: 0.9001, Acc.boat: 0.8840, Acc.bottle: 0.7917, Acc.bus: 0.6814, Acc.car: 0.7599, Acc.cat: 0.9371, Acc.chair: 0.4146, Acc.cow: 0.7655, Acc.diningtable: 0.5603, Acc.dog: 0.8983, Acc.horse: 0.8412, Acc.motorbike: 0.7891, Acc.person: 0.9205, Acc.pottedplant: 0.6199, Acc.sheep: 0.7892, Acc.sofa: 0.4647, Acc.train: 0.7432, Acc.tvmonitor: 0.5387
2022-11-29 19:37:46,405 - mmseg - INFO - Iter [20050/40000]	lr: 2.993e-05, eta: 1:31:33, time: 1.093, data_time: 0.838, memory: 5537, decode.loss_ce: 0.2063, decode.acc_seg: 94.0523, loss: 0.2063
2022-11-29 19:37:59,370 - mmseg - INFO - Iter [20100/40000]	lr: 2.985e-05, eta: 1:31:19, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2122, decode.acc_seg: 92.2030, loss: 0.2122
2022-11-29 19:38:12,308 - mmseg - INFO - Iter [20150/40000]	lr: 2.978e-05, eta: 1:31:04, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1373, decode.acc_seg: 94.9475, loss: 0.1373
2022-11-29 19:38:25,248 - mmseg - INFO - Iter [20200/40000]	lr: 2.970e-05, eta: 1:30:50, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1124, decode.acc_seg: 95.4405, loss: 0.1124
2022-11-29 19:38:38,221 - mmseg - INFO - Iter [20250/40000]	lr: 2.963e-05, eta: 1:30:35, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1407, decode.acc_seg: 94.0518, loss: 0.1407
2022-11-29 19:38:51,255 - mmseg - INFO - Iter [20300/40000]	lr: 2.955e-05, eta: 1:30:21, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1830, decode.acc_seg: 92.6548, loss: 0.1830
2022-11-29 19:39:04,192 - mmseg - INFO - Iter [20350/40000]	lr: 2.948e-05, eta: 1:30:06, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2218, decode.acc_seg: 92.2137, loss: 0.2218
2022-11-29 19:39:17,109 - mmseg - INFO - Iter [20400/40000]	lr: 2.940e-05, eta: 1:29:52, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2148, decode.acc_seg: 93.1579, loss: 0.2148
2022-11-29 19:39:30,177 - mmseg - INFO - Iter [20450/40000]	lr: 2.933e-05, eta: 1:29:37, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2440, decode.acc_seg: 91.2039, loss: 0.2440
2022-11-29 19:39:45,305 - mmseg - INFO - Iter [20500/40000]	lr: 2.925e-05, eta: 1:29:25, time: 0.303, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2880, decode.acc_seg: 93.1486, loss: 0.2880
2022-11-29 19:39:58,460 - mmseg - INFO - Iter [20550/40000]	lr: 2.918e-05, eta: 1:29:10, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0957, decode.acc_seg: 96.4489, loss: 0.0957
2022-11-29 19:40:11,467 - mmseg - INFO - Iter [20600/40000]	lr: 2.910e-05, eta: 1:28:56, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1080, decode.acc_seg: 96.0146, loss: 0.1080
2022-11-29 19:40:24,396 - mmseg - INFO - Iter [20650/40000]	lr: 2.903e-05, eta: 1:28:41, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0785, decode.acc_seg: 96.5794, loss: 0.0785
2022-11-29 19:40:37,370 - mmseg - INFO - Iter [20700/40000]	lr: 2.895e-05, eta: 1:28:27, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1292, decode.acc_seg: 94.5102, loss: 0.1292
2022-11-29 19:40:50,473 - mmseg - INFO - Iter [20750/40000]	lr: 2.888e-05, eta: 1:28:13, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1450, decode.acc_seg: 93.8860, loss: 0.1450
2022-11-29 19:41:03,499 - mmseg - INFO - Iter [20800/40000]	lr: 2.880e-05, eta: 1:27:58, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1513, decode.acc_seg: 94.5247, loss: 0.1513
2022-11-29 19:41:16,538 - mmseg - INFO - Iter [20850/40000]	lr: 2.873e-05, eta: 1:27:44, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2994, decode.acc_seg: 91.9149, loss: 0.2994
2022-11-29 19:41:29,569 - mmseg - INFO - Iter [20900/40000]	lr: 2.865e-05, eta: 1:27:29, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1142, decode.acc_seg: 95.4300, loss: 0.1142
2022-11-29 19:41:42,591 - mmseg - INFO - Iter [20950/40000]	lr: 2.858e-05, eta: 1:27:15, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1486, decode.acc_seg: 94.4573, loss: 0.1486
2022-11-29 19:41:55,566 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:41:55,566 - mmseg - INFO - Iter [21000/40000]	lr: 2.850e-05, eta: 1:27:01, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2956, decode.acc_seg: 89.5815, loss: 0.2956
2022-11-29 19:42:08,495 - mmseg - INFO - Iter [21050/40000]	lr: 2.843e-05, eta: 1:26:46, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1209, decode.acc_seg: 94.9357, loss: 0.1209
2022-11-29 19:42:21,426 - mmseg - INFO - Iter [21100/40000]	lr: 2.835e-05, eta: 1:26:32, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1751, decode.acc_seg: 93.4106, loss: 0.1751
2022-11-29 19:42:34,380 - mmseg - INFO - Iter [21150/40000]	lr: 2.828e-05, eta: 1:26:17, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1729, decode.acc_seg: 93.7478, loss: 0.1729
2022-11-29 19:42:47,337 - mmseg - INFO - Iter [21200/40000]	lr: 2.820e-05, eta: 1:26:03, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1755, decode.acc_seg: 94.2376, loss: 0.1755
2022-11-29 19:43:00,320 - mmseg - INFO - Iter [21250/40000]	lr: 2.813e-05, eta: 1:25:48, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1651, decode.acc_seg: 93.9056, loss: 0.1651
2022-11-29 19:43:13,290 - mmseg - INFO - Iter [21300/40000]	lr: 2.805e-05, eta: 1:25:34, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1427, decode.acc_seg: 93.7597, loss: 0.1427
2022-11-29 19:43:26,256 - mmseg - INFO - Iter [21350/40000]	lr: 2.798e-05, eta: 1:25:20, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1372, decode.acc_seg: 94.4384, loss: 0.1372
2022-11-29 19:43:39,169 - mmseg - INFO - Iter [21400/40000]	lr: 2.790e-05, eta: 1:25:05, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1647, decode.acc_seg: 93.0191, loss: 0.1647
2022-11-29 19:43:52,086 - mmseg - INFO - Iter [21450/40000]	lr: 2.783e-05, eta: 1:24:51, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1650, decode.acc_seg: 93.9084, loss: 0.1650
2022-11-29 19:44:04,996 - mmseg - INFO - Iter [21500/40000]	lr: 2.775e-05, eta: 1:24:36, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1341, decode.acc_seg: 94.5870, loss: 0.1341
2022-11-29 19:44:17,898 - mmseg - INFO - Iter [21550/40000]	lr: 2.768e-05, eta: 1:24:22, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2112, decode.acc_seg: 91.2916, loss: 0.2112
2022-11-29 19:44:30,816 - mmseg - INFO - Iter [21600/40000]	lr: 2.760e-05, eta: 1:24:07, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1346, decode.acc_seg: 95.7985, loss: 0.1346
2022-11-29 19:44:43,885 - mmseg - INFO - Iter [21650/40000]	lr: 2.753e-05, eta: 1:23:53, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0860, decode.acc_seg: 96.8959, loss: 0.0860
2022-11-29 19:44:56,807 - mmseg - INFO - Iter [21700/40000]	lr: 2.745e-05, eta: 1:23:39, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0783, decode.acc_seg: 97.4809, loss: 0.0783
2022-11-29 19:45:10,739 - mmseg - INFO - Iter [21750/40000]	lr: 2.738e-05, eta: 1:23:25, time: 0.279, data_time: 0.020, memory: 5537, decode.loss_ce: 0.1098, decode.acc_seg: 95.5535, loss: 0.1098
2022-11-29 19:45:23,778 - mmseg - INFO - Iter [21800/40000]	lr: 2.730e-05, eta: 1:23:11, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1830, decode.acc_seg: 93.3603, loss: 0.1830
2022-11-29 19:45:36,827 - mmseg - INFO - Iter [21850/40000]	lr: 2.723e-05, eta: 1:22:57, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2648, decode.acc_seg: 91.0352, loss: 0.2648
2022-11-29 19:45:49,748 - mmseg - INFO - Iter [21900/40000]	lr: 2.715e-05, eta: 1:22:42, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1040, decode.acc_seg: 96.3106, loss: 0.1040
2022-11-29 19:46:02,693 - mmseg - INFO - Iter [21950/40000]	lr: 2.708e-05, eta: 1:22:28, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1914, decode.acc_seg: 92.4845, loss: 0.1914
2022-11-29 19:46:17,844 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:46:17,845 - mmseg - INFO - Iter [22000/40000]	lr: 2.700e-05, eta: 1:22:16, time: 0.303, data_time: 0.047, memory: 5537, decode.loss_ce: 0.1720, decode.acc_seg: 92.7029, loss: 0.1720
2022-11-29 19:46:30,862 - mmseg - INFO - Iter [22050/40000]	lr: 2.693e-05, eta: 1:22:01, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1711, decode.acc_seg: 93.1542, loss: 0.1711
2022-11-29 19:46:43,809 - mmseg - INFO - Iter [22100/40000]	lr: 2.685e-05, eta: 1:21:47, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0959, decode.acc_seg: 96.5919, loss: 0.0959
2022-11-29 19:46:56,713 - mmseg - INFO - Iter [22150/40000]	lr: 2.678e-05, eta: 1:21:33, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1526, decode.acc_seg: 93.1445, loss: 0.1526
2022-11-29 19:47:09,675 - mmseg - INFO - Iter [22200/40000]	lr: 2.670e-05, eta: 1:21:18, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1255, decode.acc_seg: 95.9748, loss: 0.1255
2022-11-29 19:47:22,613 - mmseg - INFO - Iter [22250/40000]	lr: 2.663e-05, eta: 1:21:04, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1104, decode.acc_seg: 95.8363, loss: 0.1104
2022-11-29 19:47:35,551 - mmseg - INFO - Iter [22300/40000]	lr: 2.655e-05, eta: 1:20:50, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1563, decode.acc_seg: 94.9119, loss: 0.1563
2022-11-29 19:47:48,509 - mmseg - INFO - Iter [22350/40000]	lr: 2.648e-05, eta: 1:20:35, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1280, decode.acc_seg: 95.0657, loss: 0.1280
2022-11-29 19:48:01,449 - mmseg - INFO - Iter [22400/40000]	lr: 2.640e-05, eta: 1:20:21, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1450, decode.acc_seg: 94.6518, loss: 0.1450
2022-11-29 19:48:14,386 - mmseg - INFO - Iter [22450/40000]	lr: 2.633e-05, eta: 1:20:07, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1398, decode.acc_seg: 94.2294, loss: 0.1398
2022-11-29 19:48:27,340 - mmseg - INFO - Iter [22500/40000]	lr: 2.625e-05, eta: 1:19:52, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1279, decode.acc_seg: 94.9703, loss: 0.1279
2022-11-29 19:48:40,298 - mmseg - INFO - Iter [22550/40000]	lr: 2.618e-05, eta: 1:19:38, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1069, decode.acc_seg: 95.6383, loss: 0.1069
2022-11-29 19:48:53,355 - mmseg - INFO - Iter [22600/40000]	lr: 2.610e-05, eta: 1:19:24, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1108, decode.acc_seg: 95.5528, loss: 0.1108
2022-11-29 19:49:06,337 - mmseg - INFO - Iter [22650/40000]	lr: 2.603e-05, eta: 1:19:10, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1939, decode.acc_seg: 91.9512, loss: 0.1939
2022-11-29 19:49:19,436 - mmseg - INFO - Iter [22700/40000]	lr: 2.595e-05, eta: 1:18:56, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1124, decode.acc_seg: 95.9929, loss: 0.1124
2022-11-29 19:49:32,594 - mmseg - INFO - Iter [22750/40000]	lr: 2.588e-05, eta: 1:18:42, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1259, decode.acc_seg: 94.3225, loss: 0.1259
2022-11-29 19:49:45,597 - mmseg - INFO - Iter [22800/40000]	lr: 2.580e-05, eta: 1:18:27, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1603, decode.acc_seg: 93.8789, loss: 0.1603
2022-11-29 19:49:58,552 - mmseg - INFO - Iter [22850/40000]	lr: 2.573e-05, eta: 1:18:13, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1685, decode.acc_seg: 95.5155, loss: 0.1685
2022-11-29 19:50:11,561 - mmseg - INFO - Iter [22900/40000]	lr: 2.565e-05, eta: 1:17:59, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1907, decode.acc_seg: 92.5446, loss: 0.1907
2022-11-29 19:50:24,518 - mmseg - INFO - Iter [22950/40000]	lr: 2.558e-05, eta: 1:17:45, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1384, decode.acc_seg: 94.8064, loss: 0.1384
2022-11-29 19:50:37,469 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:50:37,469 - mmseg - INFO - Iter [23000/40000]	lr: 2.550e-05, eta: 1:17:31, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1596, decode.acc_seg: 94.0353, loss: 0.1596
2022-11-29 19:50:50,457 - mmseg - INFO - Iter [23050/40000]	lr: 2.543e-05, eta: 1:17:16, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1157, decode.acc_seg: 95.2197, loss: 0.1157
2022-11-29 19:51:03,463 - mmseg - INFO - Iter [23100/40000]	lr: 2.535e-05, eta: 1:17:02, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1151, decode.acc_seg: 95.7065, loss: 0.1151
2022-11-29 19:51:16,750 - mmseg - INFO - Iter [23150/40000]	lr: 2.528e-05, eta: 1:16:48, time: 0.266, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1063, decode.acc_seg: 95.8444, loss: 0.1063
2022-11-29 19:51:29,916 - mmseg - INFO - Iter [23200/40000]	lr: 2.520e-05, eta: 1:16:34, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1469, decode.acc_seg: 94.7450, loss: 0.1469
2022-11-29 19:51:43,044 - mmseg - INFO - Iter [23250/40000]	lr: 2.513e-05, eta: 1:16:20, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1182, decode.acc_seg: 95.7966, loss: 0.1182
2022-11-29 19:51:55,988 - mmseg - INFO - Iter [23300/40000]	lr: 2.505e-05, eta: 1:16:06, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1560, decode.acc_seg: 94.8211, loss: 0.1560
2022-11-29 19:52:09,053 - mmseg - INFO - Iter [23350/40000]	lr: 2.498e-05, eta: 1:15:52, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1395, decode.acc_seg: 93.8381, loss: 0.1395
2022-11-29 19:52:22,170 - mmseg - INFO - Iter [23400/40000]	lr: 2.490e-05, eta: 1:15:38, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1772, decode.acc_seg: 93.4160, loss: 0.1772
2022-11-29 19:52:37,336 - mmseg - INFO - Iter [23450/40000]	lr: 2.483e-05, eta: 1:15:25, time: 0.303, data_time: 0.047, memory: 5537, decode.loss_ce: 0.2671, decode.acc_seg: 92.2753, loss: 0.2671
2022-11-29 19:52:50,599 - mmseg - INFO - Iter [23500/40000]	lr: 2.475e-05, eta: 1:15:11, time: 0.265, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1092, decode.acc_seg: 95.7122, loss: 0.1092
2022-11-29 19:53:03,725 - mmseg - INFO - Iter [23550/40000]	lr: 2.468e-05, eta: 1:14:57, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1250, decode.acc_seg: 94.4189, loss: 0.1250
2022-11-29 19:53:16,755 - mmseg - INFO - Iter [23600/40000]	lr: 2.460e-05, eta: 1:14:43, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1263, decode.acc_seg: 95.5174, loss: 0.1263
2022-11-29 19:53:29,730 - mmseg - INFO - Iter [23650/40000]	lr: 2.453e-05, eta: 1:14:29, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1188, decode.acc_seg: 94.9482, loss: 0.1188
2022-11-29 19:53:42,639 - mmseg - INFO - Iter [23700/40000]	lr: 2.445e-05, eta: 1:14:15, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1202, decode.acc_seg: 95.5365, loss: 0.1202
2022-11-29 19:53:55,547 - mmseg - INFO - Iter [23750/40000]	lr: 2.438e-05, eta: 1:14:00, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1665, decode.acc_seg: 95.3521, loss: 0.1665
2022-11-29 19:54:08,474 - mmseg - INFO - Iter [23800/40000]	lr: 2.430e-05, eta: 1:13:46, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1275, decode.acc_seg: 95.4276, loss: 0.1275
2022-11-29 19:54:21,394 - mmseg - INFO - Iter [23850/40000]	lr: 2.423e-05, eta: 1:13:32, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1168, decode.acc_seg: 96.0110, loss: 0.1168
2022-11-29 19:54:34,439 - mmseg - INFO - Iter [23900/40000]	lr: 2.415e-05, eta: 1:13:18, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1147, decode.acc_seg: 95.7119, loss: 0.1147
2022-11-29 19:54:47,451 - mmseg - INFO - Iter [23950/40000]	lr: 2.408e-05, eta: 1:13:04, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1335, decode.acc_seg: 94.8073, loss: 0.1335
2022-11-29 19:55:00,484 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:55:00,484 - mmseg - INFO - Iter [24000/40000]	lr: 2.400e-05, eta: 1:12:50, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2813, decode.acc_seg: 90.2916, loss: 0.2813
2022-11-29 19:55:13,481 - mmseg - INFO - Iter [24050/40000]	lr: 2.393e-05, eta: 1:12:36, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1196, decode.acc_seg: 95.3103, loss: 0.1196
2022-11-29 19:55:26,480 - mmseg - INFO - Iter [24100/40000]	lr: 2.385e-05, eta: 1:12:22, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1509, decode.acc_seg: 94.1042, loss: 0.1509
2022-11-29 19:55:39,504 - mmseg - INFO - Iter [24150/40000]	lr: 2.378e-05, eta: 1:12:08, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1391, decode.acc_seg: 94.4325, loss: 0.1391
2022-11-29 19:55:52,512 - mmseg - INFO - Iter [24200/40000]	lr: 2.370e-05, eta: 1:11:54, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1076, decode.acc_seg: 96.2121, loss: 0.1076
2022-11-29 19:56:05,563 - mmseg - INFO - Iter [24250/40000]	lr: 2.363e-05, eta: 1:11:39, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1517, decode.acc_seg: 94.2137, loss: 0.1517
2022-11-29 19:56:18,589 - mmseg - INFO - Iter [24300/40000]	lr: 2.355e-05, eta: 1:11:25, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1154, decode.acc_seg: 95.5089, loss: 0.1154
2022-11-29 19:56:31,610 - mmseg - INFO - Iter [24350/40000]	lr: 2.348e-05, eta: 1:11:11, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2343, decode.acc_seg: 90.3069, loss: 0.2343
2022-11-29 19:56:44,592 - mmseg - INFO - Iter [24400/40000]	lr: 2.340e-05, eta: 1:10:57, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1683, decode.acc_seg: 93.9503, loss: 0.1683
2022-11-29 19:56:57,665 - mmseg - INFO - Iter [24450/40000]	lr: 2.333e-05, eta: 1:10:43, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2239, decode.acc_seg: 92.4914, loss: 0.2239
2022-11-29 19:57:10,716 - mmseg - INFO - Iter [24500/40000]	lr: 2.325e-05, eta: 1:10:29, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1767, decode.acc_seg: 92.8675, loss: 0.1767
2022-11-29 19:57:23,766 - mmseg - INFO - Iter [24550/40000]	lr: 2.318e-05, eta: 1:10:15, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1160, decode.acc_seg: 96.1711, loss: 0.1160
2022-11-29 19:57:36,878 - mmseg - INFO - Iter [24600/40000]	lr: 2.310e-05, eta: 1:10:01, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1370, decode.acc_seg: 94.4266, loss: 0.1370
2022-11-29 19:57:49,893 - mmseg - INFO - Iter [24650/40000]	lr: 2.303e-05, eta: 1:09:47, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1249, decode.acc_seg: 95.1405, loss: 0.1249
2022-11-29 19:58:02,907 - mmseg - INFO - Iter [24700/40000]	lr: 2.295e-05, eta: 1:09:33, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0928, decode.acc_seg: 96.8158, loss: 0.0928
2022-11-29 19:58:15,885 - mmseg - INFO - Iter [24750/40000]	lr: 2.288e-05, eta: 1:09:19, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0965, decode.acc_seg: 96.4724, loss: 0.0965
2022-11-29 19:58:28,929 - mmseg - INFO - Iter [24800/40000]	lr: 2.280e-05, eta: 1:09:05, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0672, decode.acc_seg: 97.4066, loss: 0.0672
2022-11-29 19:58:41,945 - mmseg - INFO - Iter [24850/40000]	lr: 2.273e-05, eta: 1:08:51, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0799, decode.acc_seg: 97.0643, loss: 0.0799
2022-11-29 19:58:57,030 - mmseg - INFO - Iter [24900/40000]	lr: 2.265e-05, eta: 1:08:38, time: 0.302, data_time: 0.047, memory: 5537, decode.loss_ce: 0.1529, decode.acc_seg: 93.9255, loss: 0.1529
2022-11-29 19:59:09,981 - mmseg - INFO - Iter [24950/40000]	lr: 2.258e-05, eta: 1:08:24, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0790, decode.acc_seg: 96.6983, loss: 0.0790
2022-11-29 19:59:22,885 - mmseg - INFO - Saving checkpoint at 25000 iterations
2022-11-29 19:59:25,570 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 19:59:25,570 - mmseg - INFO - Iter [25000/40000]	lr: 2.250e-05, eta: 1:08:12, time: 0.312, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1161, decode.acc_seg: 95.2258, loss: 0.1161
2022-11-29 20:00:07,009 - mmseg - INFO - per class results:
2022-11-29 20:00:07,011 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 93.14 | 96.27 |
|  aeroplane  | 85.66 | 91.61 |
|   bicycle   | 65.96 | 77.04 |
|     bird    | 82.38 | 89.35 |
|     boat    | 71.12 | 80.37 |
|    bottle   | 69.86 | 84.86 |
|     bus     | 88.39 | 93.39 |
|     car     | 85.02 | 89.31 |
|     cat     |  72.4 |  74.1 |
|    chair    | 33.77 | 42.19 |
|     cow     | 78.77 | 88.61 |
| diningtable | 58.61 | 64.01 |
|     dog     |  57.3 | 96.87 |
|    horse    | 61.59 | 65.35 |
|  motorbike  | 84.09 | 91.85 |
|    person   |  81.1 | 94.51 |
| pottedplant | 46.88 | 62.84 |
|    sheep    | 78.34 | 87.65 |
|     sofa    | 49.56 | 61.57 |
|    train    | 76.02 | 91.86 |
|  tvmonitor  | 52.17 | 62.48 |
+-------------+-------+-------+
2022-11-29 20:00:07,011 - mmseg - INFO - Summary:
2022-11-29 20:00:07,011 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 92.76 | 70.1 | 80.29 |
+-------+------+-------+
2022-11-29 20:00:07,013 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:00:07,013 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9276, mIoU: 0.7010, mAcc: 0.8029, IoU.background: 0.9314, IoU.aeroplane: 0.8566, IoU.bicycle: 0.6596, IoU.bird: 0.8238, IoU.boat: 0.7112, IoU.bottle: 0.6986, IoU.bus: 0.8839, IoU.car: 0.8502, IoU.cat: 0.7240, IoU.chair: 0.3377, IoU.cow: 0.7877, IoU.diningtable: 0.5861, IoU.dog: 0.5730, IoU.horse: 0.6159, IoU.motorbike: 0.8409, IoU.person: 0.8110, IoU.pottedplant: 0.4688, IoU.sheep: 0.7834, IoU.sofa: 0.4956, IoU.train: 0.7602, IoU.tvmonitor: 0.5217, Acc.background: 0.9627, Acc.aeroplane: 0.9161, Acc.bicycle: 0.7704, Acc.bird: 0.8935, Acc.boat: 0.8037, Acc.bottle: 0.8486, Acc.bus: 0.9339, Acc.car: 0.8931, Acc.cat: 0.7410, Acc.chair: 0.4219, Acc.cow: 0.8861, Acc.diningtable: 0.6401, Acc.dog: 0.9687, Acc.horse: 0.6535, Acc.motorbike: 0.9185, Acc.person: 0.9451, Acc.pottedplant: 0.6284, Acc.sheep: 0.8765, Acc.sofa: 0.6157, Acc.train: 0.9186, Acc.tvmonitor: 0.6248
2022-11-29 20:00:20,138 - mmseg - INFO - Iter [25050/40000]	lr: 2.243e-05, eta: 1:08:23, time: 1.091, data_time: 0.835, memory: 5537, decode.loss_ce: 0.0899, decode.acc_seg: 96.1984, loss: 0.0899
2022-11-29 20:00:33,129 - mmseg - INFO - Iter [25100/40000]	lr: 2.235e-05, eta: 1:08:08, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0564, decode.acc_seg: 97.7257, loss: 0.0564
2022-11-29 20:00:46,169 - mmseg - INFO - Iter [25150/40000]	lr: 2.228e-05, eta: 1:07:54, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2568, decode.acc_seg: 93.0234, loss: 0.2568
2022-11-29 20:00:59,200 - mmseg - INFO - Iter [25200/40000]	lr: 2.220e-05, eta: 1:07:40, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0975, decode.acc_seg: 95.8240, loss: 0.0975
2022-11-29 20:01:12,353 - mmseg - INFO - Iter [25250/40000]	lr: 2.213e-05, eta: 1:07:26, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1200, decode.acc_seg: 95.2642, loss: 0.1200
2022-11-29 20:01:25,382 - mmseg - INFO - Iter [25300/40000]	lr: 2.205e-05, eta: 1:07:12, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1791, decode.acc_seg: 92.9759, loss: 0.1791
2022-11-29 20:01:38,416 - mmseg - INFO - Iter [25350/40000]	lr: 2.198e-05, eta: 1:06:58, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1565, decode.acc_seg: 94.1687, loss: 0.1565
2022-11-29 20:01:51,417 - mmseg - INFO - Iter [25400/40000]	lr: 2.190e-05, eta: 1:06:44, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1175, decode.acc_seg: 95.4474, loss: 0.1175
2022-11-29 20:02:04,427 - mmseg - INFO - Iter [25450/40000]	lr: 2.183e-05, eta: 1:06:30, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1201, decode.acc_seg: 95.3254, loss: 0.1201
2022-11-29 20:02:17,417 - mmseg - INFO - Iter [25500/40000]	lr: 2.175e-05, eta: 1:06:16, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0967, decode.acc_seg: 95.8324, loss: 0.0967
2022-11-29 20:02:30,407 - mmseg - INFO - Iter [25550/40000]	lr: 2.168e-05, eta: 1:06:01, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0923, decode.acc_seg: 96.2302, loss: 0.0923
2022-11-29 20:02:43,410 - mmseg - INFO - Iter [25600/40000]	lr: 2.160e-05, eta: 1:05:47, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1045, decode.acc_seg: 95.5537, loss: 0.1045
2022-11-29 20:02:56,410 - mmseg - INFO - Iter [25650/40000]	lr: 2.153e-05, eta: 1:05:33, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1786, decode.acc_seg: 92.9936, loss: 0.1786
2022-11-29 20:03:09,442 - mmseg - INFO - Iter [25700/40000]	lr: 2.145e-05, eta: 1:05:19, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1635, decode.acc_seg: 93.9028, loss: 0.1635
2022-11-29 20:03:22,429 - mmseg - INFO - Iter [25750/40000]	lr: 2.138e-05, eta: 1:05:05, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1114, decode.acc_seg: 95.7973, loss: 0.1114
2022-11-29 20:03:35,429 - mmseg - INFO - Iter [25800/40000]	lr: 2.130e-05, eta: 1:04:51, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1131, decode.acc_seg: 95.4515, loss: 0.1131
2022-11-29 20:03:48,434 - mmseg - INFO - Iter [25850/40000]	lr: 2.123e-05, eta: 1:04:37, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1123, decode.acc_seg: 93.6141, loss: 0.1123
2022-11-29 20:04:01,469 - mmseg - INFO - Iter [25900/40000]	lr: 2.115e-05, eta: 1:04:23, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1751, decode.acc_seg: 95.2597, loss: 0.1751
2022-11-29 20:04:14,568 - mmseg - INFO - Iter [25950/40000]	lr: 2.108e-05, eta: 1:04:09, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0996, decode.acc_seg: 95.8454, loss: 0.0996
2022-11-29 20:04:27,587 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:04:27,587 - mmseg - INFO - Iter [26000/40000]	lr: 2.100e-05, eta: 1:03:55, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1471, decode.acc_seg: 94.3611, loss: 0.1471
2022-11-29 20:04:40,598 - mmseg - INFO - Iter [26050/40000]	lr: 2.093e-05, eta: 1:03:41, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2504, decode.acc_seg: 93.1717, loss: 0.2504
2022-11-29 20:04:53,642 - mmseg - INFO - Iter [26100/40000]	lr: 2.085e-05, eta: 1:03:27, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1560, decode.acc_seg: 93.7481, loss: 0.1560
2022-11-29 20:05:06,671 - mmseg - INFO - Iter [26150/40000]	lr: 2.078e-05, eta: 1:03:13, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1495, decode.acc_seg: 94.8222, loss: 0.1495
2022-11-29 20:05:19,677 - mmseg - INFO - Iter [26200/40000]	lr: 2.070e-05, eta: 1:02:59, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1736, decode.acc_seg: 93.1031, loss: 0.1736
2022-11-29 20:05:32,673 - mmseg - INFO - Iter [26250/40000]	lr: 2.063e-05, eta: 1:02:44, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1487, decode.acc_seg: 94.5309, loss: 0.1487
2022-11-29 20:05:45,704 - mmseg - INFO - Iter [26300/40000]	lr: 2.055e-05, eta: 1:02:30, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1952, decode.acc_seg: 92.6301, loss: 0.1952
2022-11-29 20:05:58,703 - mmseg - INFO - Iter [26350/40000]	lr: 2.048e-05, eta: 1:02:16, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1552, decode.acc_seg: 93.1313, loss: 0.1552
2022-11-29 20:06:13,960 - mmseg - INFO - Iter [26400/40000]	lr: 2.040e-05, eta: 1:02:04, time: 0.305, data_time: 0.050, memory: 5537, decode.loss_ce: 0.1086, decode.acc_seg: 96.4961, loss: 0.1086
2022-11-29 20:06:26,968 - mmseg - INFO - Iter [26450/40000]	lr: 2.033e-05, eta: 1:01:49, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0893, decode.acc_seg: 96.3377, loss: 0.0893
2022-11-29 20:06:39,955 - mmseg - INFO - Iter [26500/40000]	lr: 2.025e-05, eta: 1:01:35, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0886, decode.acc_seg: 95.9424, loss: 0.0886
2022-11-29 20:06:52,952 - mmseg - INFO - Iter [26550/40000]	lr: 2.018e-05, eta: 1:01:21, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0843, decode.acc_seg: 96.3943, loss: 0.0843
2022-11-29 20:07:05,957 - mmseg - INFO - Iter [26600/40000]	lr: 2.010e-05, eta: 1:01:07, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1022, decode.acc_seg: 95.9504, loss: 0.1022
2022-11-29 20:07:18,969 - mmseg - INFO - Iter [26650/40000]	lr: 2.003e-05, eta: 1:00:53, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0906, decode.acc_seg: 96.1013, loss: 0.0906
2022-11-29 20:07:31,934 - mmseg - INFO - Iter [26700/40000]	lr: 1.995e-05, eta: 1:00:39, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1183, decode.acc_seg: 95.6228, loss: 0.1183
2022-11-29 20:07:44,899 - mmseg - INFO - Iter [26750/40000]	lr: 1.988e-05, eta: 1:00:25, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0719, decode.acc_seg: 97.3389, loss: 0.0719
2022-11-29 20:07:57,876 - mmseg - INFO - Iter [26800/40000]	lr: 1.980e-05, eta: 1:00:11, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1388, decode.acc_seg: 95.7953, loss: 0.1388
2022-11-29 20:08:10,895 - mmseg - INFO - Iter [26850/40000]	lr: 1.973e-05, eta: 0:59:57, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1040, decode.acc_seg: 95.8225, loss: 0.1040
2022-11-29 20:08:23,956 - mmseg - INFO - Iter [26900/40000]	lr: 1.965e-05, eta: 0:59:43, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0751, decode.acc_seg: 97.1684, loss: 0.0751
2022-11-29 20:08:36,941 - mmseg - INFO - Iter [26950/40000]	lr: 1.958e-05, eta: 0:59:29, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0744, decode.acc_seg: 97.0091, loss: 0.0744
2022-11-29 20:08:49,969 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:08:49,969 - mmseg - INFO - Iter [27000/40000]	lr: 1.950e-05, eta: 0:59:15, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0973, decode.acc_seg: 96.3616, loss: 0.0973
2022-11-29 20:09:03,143 - mmseg - INFO - Iter [27050/40000]	lr: 1.943e-05, eta: 0:59:01, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1213, decode.acc_seg: 94.9070, loss: 0.1213
2022-11-29 20:09:16,286 - mmseg - INFO - Iter [27100/40000]	lr: 1.935e-05, eta: 0:58:47, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0930, decode.acc_seg: 96.3466, loss: 0.0930
2022-11-29 20:09:29,354 - mmseg - INFO - Iter [27150/40000]	lr: 1.928e-05, eta: 0:58:33, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1101, decode.acc_seg: 95.1778, loss: 0.1101
2022-11-29 20:09:42,357 - mmseg - INFO - Iter [27200/40000]	lr: 1.920e-05, eta: 0:58:19, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1144, decode.acc_seg: 95.6239, loss: 0.1144
2022-11-29 20:09:55,368 - mmseg - INFO - Iter [27250/40000]	lr: 1.913e-05, eta: 0:58:05, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1430, decode.acc_seg: 94.4273, loss: 0.1430
2022-11-29 20:10:08,538 - mmseg - INFO - Iter [27300/40000]	lr: 1.905e-05, eta: 0:57:52, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1603, decode.acc_seg: 94.6900, loss: 0.1603
2022-11-29 20:10:21,697 - mmseg - INFO - Iter [27350/40000]	lr: 1.898e-05, eta: 0:57:38, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0888, decode.acc_seg: 96.1065, loss: 0.0888
2022-11-29 20:10:34,783 - mmseg - INFO - Iter [27400/40000]	lr: 1.890e-05, eta: 0:57:24, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1256, decode.acc_seg: 95.4002, loss: 0.1256
2022-11-29 20:10:47,862 - mmseg - INFO - Iter [27450/40000]	lr: 1.883e-05, eta: 0:57:10, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1105, decode.acc_seg: 95.2270, loss: 0.1105
2022-11-29 20:11:00,946 - mmseg - INFO - Iter [27500/40000]	lr: 1.875e-05, eta: 0:56:56, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1168, decode.acc_seg: 95.5931, loss: 0.1168
2022-11-29 20:11:14,071 - mmseg - INFO - Iter [27550/40000]	lr: 1.868e-05, eta: 0:56:42, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1137, decode.acc_seg: 95.6973, loss: 0.1137
2022-11-29 20:11:27,146 - mmseg - INFO - Iter [27600/40000]	lr: 1.860e-05, eta: 0:56:28, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1152, decode.acc_seg: 95.3546, loss: 0.1152
2022-11-29 20:11:40,183 - mmseg - INFO - Iter [27650/40000]	lr: 1.853e-05, eta: 0:56:14, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1242, decode.acc_seg: 95.2259, loss: 0.1242
2022-11-29 20:11:53,246 - mmseg - INFO - Iter [27700/40000]	lr: 1.845e-05, eta: 0:56:00, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0814, decode.acc_seg: 96.7925, loss: 0.0814
2022-11-29 20:12:06,304 - mmseg - INFO - Iter [27750/40000]	lr: 1.838e-05, eta: 0:55:46, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1540, decode.acc_seg: 94.8160, loss: 0.1540
2022-11-29 20:12:19,450 - mmseg - INFO - Iter [27800/40000]	lr: 1.830e-05, eta: 0:55:32, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0954, decode.acc_seg: 96.4178, loss: 0.0954
2022-11-29 20:12:34,650 - mmseg - INFO - Iter [27850/40000]	lr: 1.823e-05, eta: 0:55:19, time: 0.304, data_time: 0.047, memory: 5537, decode.loss_ce: 0.1027, decode.acc_seg: 95.7260, loss: 0.1027
2022-11-29 20:12:47,722 - mmseg - INFO - Iter [27900/40000]	lr: 1.815e-05, eta: 0:55:05, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1079, decode.acc_seg: 95.6801, loss: 0.1079
2022-11-29 20:13:00,756 - mmseg - INFO - Iter [27950/40000]	lr: 1.808e-05, eta: 0:54:51, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0934, decode.acc_seg: 97.0624, loss: 0.0934
2022-11-29 20:13:13,785 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:13:13,785 - mmseg - INFO - Iter [28000/40000]	lr: 1.800e-05, eta: 0:54:38, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1148, decode.acc_seg: 95.8319, loss: 0.1148
2022-11-29 20:13:26,821 - mmseg - INFO - Iter [28050/40000]	lr: 1.793e-05, eta: 0:54:24, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0939, decode.acc_seg: 96.0474, loss: 0.0939
2022-11-29 20:13:39,846 - mmseg - INFO - Iter [28100/40000]	lr: 1.785e-05, eta: 0:54:10, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0947, decode.acc_seg: 96.6206, loss: 0.0947
2022-11-29 20:13:52,920 - mmseg - INFO - Iter [28150/40000]	lr: 1.778e-05, eta: 0:53:56, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0587, decode.acc_seg: 97.8256, loss: 0.0587
2022-11-29 20:14:05,946 - mmseg - INFO - Iter [28200/40000]	lr: 1.770e-05, eta: 0:53:42, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1053, decode.acc_seg: 96.0017, loss: 0.1053
2022-11-29 20:14:18,996 - mmseg - INFO - Iter [28250/40000]	lr: 1.763e-05, eta: 0:53:28, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0807, decode.acc_seg: 96.9237, loss: 0.0807
2022-11-29 20:14:32,082 - mmseg - INFO - Iter [28300/40000]	lr: 1.755e-05, eta: 0:53:14, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1413, decode.acc_seg: 94.4625, loss: 0.1413
2022-11-29 20:14:45,150 - mmseg - INFO - Iter [28350/40000]	lr: 1.748e-05, eta: 0:53:00, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2293, decode.acc_seg: 91.6078, loss: 0.2293
2022-11-29 20:14:58,247 - mmseg - INFO - Iter [28400/40000]	lr: 1.740e-05, eta: 0:52:46, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0644, decode.acc_seg: 98.0024, loss: 0.0644
2022-11-29 20:15:11,370 - mmseg - INFO - Iter [28450/40000]	lr: 1.733e-05, eta: 0:52:32, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1478, decode.acc_seg: 94.8654, loss: 0.1478
2022-11-29 20:15:24,428 - mmseg - INFO - Iter [28500/40000]	lr: 1.725e-05, eta: 0:52:19, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1055, decode.acc_seg: 95.6542, loss: 0.1055
2022-11-29 20:15:37,492 - mmseg - INFO - Iter [28550/40000]	lr: 1.718e-05, eta: 0:52:05, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1018, decode.acc_seg: 96.1778, loss: 0.1018
2022-11-29 20:15:50,561 - mmseg - INFO - Iter [28600/40000]	lr: 1.710e-05, eta: 0:51:51, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0782, decode.acc_seg: 97.1278, loss: 0.0782
2022-11-29 20:16:03,660 - mmseg - INFO - Iter [28650/40000]	lr: 1.703e-05, eta: 0:51:37, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1258, decode.acc_seg: 96.2003, loss: 0.1258
2022-11-29 20:16:16,786 - mmseg - INFO - Iter [28700/40000]	lr: 1.695e-05, eta: 0:51:23, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1157, decode.acc_seg: 96.4060, loss: 0.1157
2022-11-29 20:16:29,993 - mmseg - INFO - Iter [28750/40000]	lr: 1.688e-05, eta: 0:51:09, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1117, decode.acc_seg: 95.8997, loss: 0.1117
2022-11-29 20:16:43,077 - mmseg - INFO - Iter [28800/40000]	lr: 1.680e-05, eta: 0:50:55, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1128, decode.acc_seg: 95.3314, loss: 0.1128
2022-11-29 20:16:56,149 - mmseg - INFO - Iter [28850/40000]	lr: 1.673e-05, eta: 0:50:42, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0997, decode.acc_seg: 96.3442, loss: 0.0997
2022-11-29 20:17:09,226 - mmseg - INFO - Iter [28900/40000]	lr: 1.665e-05, eta: 0:50:28, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1130, decode.acc_seg: 96.2655, loss: 0.1130
2022-11-29 20:17:22,287 - mmseg - INFO - Iter [28950/40000]	lr: 1.658e-05, eta: 0:50:14, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0624, decode.acc_seg: 97.4510, loss: 0.0624
2022-11-29 20:17:35,349 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:17:35,349 - mmseg - INFO - Iter [29000/40000]	lr: 1.650e-05, eta: 0:50:00, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0960, decode.acc_seg: 96.4934, loss: 0.0960
2022-11-29 20:17:48,418 - mmseg - INFO - Iter [29050/40000]	lr: 1.643e-05, eta: 0:49:46, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1476, decode.acc_seg: 95.3849, loss: 0.1476
2022-11-29 20:18:01,466 - mmseg - INFO - Iter [29100/40000]	lr: 1.635e-05, eta: 0:49:32, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0849, decode.acc_seg: 96.8685, loss: 0.0849
2022-11-29 20:18:14,535 - mmseg - INFO - Iter [29150/40000]	lr: 1.628e-05, eta: 0:49:18, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1227, decode.acc_seg: 95.5387, loss: 0.1227
2022-11-29 20:18:27,592 - mmseg - INFO - Iter [29200/40000]	lr: 1.620e-05, eta: 0:49:05, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0786, decode.acc_seg: 96.5347, loss: 0.0786
2022-11-29 20:18:40,728 - mmseg - INFO - Iter [29250/40000]	lr: 1.613e-05, eta: 0:48:51, time: 0.263, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0733, decode.acc_seg: 95.6596, loss: 0.0733
2022-11-29 20:18:55,958 - mmseg - INFO - Iter [29300/40000]	lr: 1.605e-05, eta: 0:48:38, time: 0.305, data_time: 0.047, memory: 5537, decode.loss_ce: 0.1026, decode.acc_seg: 96.7055, loss: 0.1026
2022-11-29 20:19:09,076 - mmseg - INFO - Iter [29350/40000]	lr: 1.598e-05, eta: 0:48:24, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.2107, decode.acc_seg: 95.2821, loss: 0.2107
2022-11-29 20:19:22,274 - mmseg - INFO - Iter [29400/40000]	lr: 1.590e-05, eta: 0:48:10, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0890, decode.acc_seg: 96.5026, loss: 0.0890
2022-11-29 20:19:35,337 - mmseg - INFO - Iter [29450/40000]	lr: 1.583e-05, eta: 0:47:56, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1325, decode.acc_seg: 94.4904, loss: 0.1325
2022-11-29 20:19:48,409 - mmseg - INFO - Iter [29500/40000]	lr: 1.575e-05, eta: 0:47:42, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1290, decode.acc_seg: 95.6391, loss: 0.1290
2022-11-29 20:20:01,506 - mmseg - INFO - Iter [29550/40000]	lr: 1.568e-05, eta: 0:47:29, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1084, decode.acc_seg: 95.6413, loss: 0.1084
2022-11-29 20:20:14,621 - mmseg - INFO - Iter [29600/40000]	lr: 1.560e-05, eta: 0:47:15, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0917, decode.acc_seg: 96.3213, loss: 0.0917
2022-11-29 20:20:27,825 - mmseg - INFO - Iter [29650/40000]	lr: 1.553e-05, eta: 0:47:01, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0553, decode.acc_seg: 97.9095, loss: 0.0553
2022-11-29 20:20:40,919 - mmseg - INFO - Iter [29700/40000]	lr: 1.545e-05, eta: 0:46:47, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1505, decode.acc_seg: 93.7674, loss: 0.1505
2022-11-29 20:20:53,935 - mmseg - INFO - Iter [29750/40000]	lr: 1.538e-05, eta: 0:46:33, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1055, decode.acc_seg: 94.7044, loss: 0.1055
2022-11-29 20:21:06,990 - mmseg - INFO - Iter [29800/40000]	lr: 1.530e-05, eta: 0:46:20, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0971, decode.acc_seg: 96.3878, loss: 0.0971
2022-11-29 20:21:20,017 - mmseg - INFO - Iter [29850/40000]	lr: 1.523e-05, eta: 0:46:06, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0899, decode.acc_seg: 96.6892, loss: 0.0899
2022-11-29 20:21:33,031 - mmseg - INFO - Iter [29900/40000]	lr: 1.515e-05, eta: 0:45:52, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0946, decode.acc_seg: 96.1331, loss: 0.0946
2022-11-29 20:21:46,093 - mmseg - INFO - Iter [29950/40000]	lr: 1.508e-05, eta: 0:45:38, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1021, decode.acc_seg: 96.3841, loss: 0.1021
2022-11-29 20:21:59,121 - mmseg - INFO - Saving checkpoint at 30000 iterations
2022-11-29 20:22:01,604 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:22:01,604 - mmseg - INFO - Iter [30000/40000]	lr: 1.500e-05, eta: 0:45:25, time: 0.310, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0703, decode.acc_seg: 97.1345, loss: 0.0703
2022-11-29 20:22:43,328 - mmseg - INFO - per class results:
2022-11-29 20:22:43,329 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 93.61 | 97.39 |
|  aeroplane  | 83.62 | 89.73 |
|   bicycle   | 68.45 | 84.97 |
|     bird    | 86.37 | 91.63 |
|     boat    | 73.65 | 76.51 |
|    bottle   | 75.71 |  86.3 |
|     bus     | 92.09 | 95.05 |
|     car     | 82.44 | 86.32 |
|     cat     | 89.18 | 90.91 |
|    chair    | 35.71 | 48.27 |
|     cow     | 82.24 | 93.83 |
| diningtable | 61.12 |  66.7 |
|     dog     | 85.24 | 90.14 |
|    horse    |  84.2 | 91.56 |
|  motorbike  | 81.91 | 95.58 |
|    person   | 84.19 | 93.92 |
| pottedplant | 55.08 |  63.1 |
|    sheep    | 79.67 | 82.47 |
|     sofa    | 50.78 | 56.75 |
|    train    | 73.38 | 92.96 |
|  tvmonitor  | 54.82 | 65.81 |
+-------------+-------+-------+
2022-11-29 20:22:43,329 - mmseg - INFO - Summary:
2022-11-29 20:22:43,330 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.15 | 74.93 | 82.85 |
+-------+-------+-------+
2022-11-29 20:22:43,331 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:22:43,332 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9415, mIoU: 0.7493, mAcc: 0.8285, IoU.background: 0.9361, IoU.aeroplane: 0.8362, IoU.bicycle: 0.6845, IoU.bird: 0.8637, IoU.boat: 0.7365, IoU.bottle: 0.7571, IoU.bus: 0.9209, IoU.car: 0.8244, IoU.cat: 0.8918, IoU.chair: 0.3571, IoU.cow: 0.8224, IoU.diningtable: 0.6112, IoU.dog: 0.8524, IoU.horse: 0.8420, IoU.motorbike: 0.8191, IoU.person: 0.8419, IoU.pottedplant: 0.5508, IoU.sheep: 0.7967, IoU.sofa: 0.5078, IoU.train: 0.7338, IoU.tvmonitor: 0.5482, Acc.background: 0.9739, Acc.aeroplane: 0.8973, Acc.bicycle: 0.8497, Acc.bird: 0.9163, Acc.boat: 0.7651, Acc.bottle: 0.8630, Acc.bus: 0.9505, Acc.car: 0.8632, Acc.cat: 0.9091, Acc.chair: 0.4827, Acc.cow: 0.9383, Acc.diningtable: 0.6670, Acc.dog: 0.9014, Acc.horse: 0.9156, Acc.motorbike: 0.9558, Acc.person: 0.9392, Acc.pottedplant: 0.6310, Acc.sheep: 0.8247, Acc.sofa: 0.5675, Acc.train: 0.9296, Acc.tvmonitor: 0.6581
2022-11-29 20:22:56,447 - mmseg - INFO - Iter [30050/40000]	lr: 1.493e-05, eta: 0:45:25, time: 1.097, data_time: 0.841, memory: 5537, decode.loss_ce: 0.1215, decode.acc_seg: 95.6722, loss: 0.1215
2022-11-29 20:23:09,462 - mmseg - INFO - Iter [30100/40000]	lr: 1.485e-05, eta: 0:45:11, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1082, decode.acc_seg: 96.1906, loss: 0.1082
2022-11-29 20:23:22,494 - mmseg - INFO - Iter [30150/40000]	lr: 1.478e-05, eta: 0:44:57, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0991, decode.acc_seg: 95.7791, loss: 0.0991
2022-11-29 20:23:35,683 - mmseg - INFO - Iter [30200/40000]	lr: 1.470e-05, eta: 0:44:43, time: 0.264, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0731, decode.acc_seg: 97.1723, loss: 0.0731
2022-11-29 20:23:48,682 - mmseg - INFO - Iter [30250/40000]	lr: 1.463e-05, eta: 0:44:29, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0474, decode.acc_seg: 97.8991, loss: 0.0474
2022-11-29 20:24:01,727 - mmseg - INFO - Iter [30300/40000]	lr: 1.455e-05, eta: 0:44:16, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0565, decode.acc_seg: 97.7579, loss: 0.0565
2022-11-29 20:24:14,754 - mmseg - INFO - Iter [30350/40000]	lr: 1.448e-05, eta: 0:44:02, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1046, decode.acc_seg: 96.5527, loss: 0.1046
2022-11-29 20:24:27,760 - mmseg - INFO - Iter [30400/40000]	lr: 1.440e-05, eta: 0:43:48, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1563, decode.acc_seg: 94.0049, loss: 0.1563
2022-11-29 20:24:40,798 - mmseg - INFO - Iter [30450/40000]	lr: 1.433e-05, eta: 0:43:34, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1135, decode.acc_seg: 95.7048, loss: 0.1135
2022-11-29 20:24:53,848 - mmseg - INFO - Iter [30500/40000]	lr: 1.425e-05, eta: 0:43:20, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1248, decode.acc_seg: 95.5954, loss: 0.1248
2022-11-29 20:25:06,846 - mmseg - INFO - Iter [30550/40000]	lr: 1.418e-05, eta: 0:43:06, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1138, decode.acc_seg: 94.4039, loss: 0.1138
2022-11-29 20:25:19,820 - mmseg - INFO - Iter [30600/40000]	lr: 1.410e-05, eta: 0:42:52, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0778, decode.acc_seg: 96.9292, loss: 0.0778
2022-11-29 20:25:32,832 - mmseg - INFO - Iter [30650/40000]	lr: 1.403e-05, eta: 0:42:38, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0904, decode.acc_seg: 96.2280, loss: 0.0904
2022-11-29 20:25:45,837 - mmseg - INFO - Iter [30700/40000]	lr: 1.395e-05, eta: 0:42:24, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0925, decode.acc_seg: 96.5059, loss: 0.0925
2022-11-29 20:26:00,977 - mmseg - INFO - Iter [30750/40000]	lr: 1.388e-05, eta: 0:42:11, time: 0.303, data_time: 0.048, memory: 5537, decode.loss_ce: 0.0684, decode.acc_seg: 97.4928, loss: 0.0684
2022-11-29 20:26:14,051 - mmseg - INFO - Iter [30800/40000]	lr: 1.380e-05, eta: 0:41:57, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1377, decode.acc_seg: 96.2182, loss: 0.1377
2022-11-29 20:26:27,083 - mmseg - INFO - Iter [30850/40000]	lr: 1.373e-05, eta: 0:41:43, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1303, decode.acc_seg: 95.2429, loss: 0.1303
2022-11-29 20:26:40,108 - mmseg - INFO - Iter [30900/40000]	lr: 1.365e-05, eta: 0:41:30, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0993, decode.acc_seg: 96.2964, loss: 0.0993
2022-11-29 20:26:53,129 - mmseg - INFO - Iter [30950/40000]	lr: 1.358e-05, eta: 0:41:16, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1254, decode.acc_seg: 95.2280, loss: 0.1254
2022-11-29 20:27:06,165 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:27:06,165 - mmseg - INFO - Iter [31000/40000]	lr: 1.350e-05, eta: 0:41:02, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1467, decode.acc_seg: 95.0133, loss: 0.1467
2022-11-29 20:27:19,260 - mmseg - INFO - Iter [31050/40000]	lr: 1.343e-05, eta: 0:40:48, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0942, decode.acc_seg: 96.1354, loss: 0.0942
2022-11-29 20:27:32,263 - mmseg - INFO - Iter [31100/40000]	lr: 1.335e-05, eta: 0:40:34, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1236, decode.acc_seg: 95.5040, loss: 0.1236
2022-11-29 20:27:45,346 - mmseg - INFO - Iter [31150/40000]	lr: 1.328e-05, eta: 0:40:20, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0859, decode.acc_seg: 96.6810, loss: 0.0859
2022-11-29 20:27:58,338 - mmseg - INFO - Iter [31200/40000]	lr: 1.320e-05, eta: 0:40:06, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1025, decode.acc_seg: 96.7986, loss: 0.1025
2022-11-29 20:28:11,328 - mmseg - INFO - Iter [31250/40000]	lr: 1.313e-05, eta: 0:39:52, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0621, decode.acc_seg: 97.6192, loss: 0.0621
2022-11-29 20:28:24,309 - mmseg - INFO - Iter [31300/40000]	lr: 1.305e-05, eta: 0:39:39, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0874, decode.acc_seg: 96.2579, loss: 0.0874
2022-11-29 20:28:37,315 - mmseg - INFO - Iter [31350/40000]	lr: 1.298e-05, eta: 0:39:25, time: 0.260, data_time: 0.007, memory: 5537, decode.loss_ce: 0.1487, decode.acc_seg: 94.7568, loss: 0.1487
2022-11-29 20:28:50,234 - mmseg - INFO - Iter [31400/40000]	lr: 1.290e-05, eta: 0:39:11, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0510, decode.acc_seg: 98.0146, loss: 0.0510
2022-11-29 20:29:03,131 - mmseg - INFO - Iter [31450/40000]	lr: 1.283e-05, eta: 0:38:57, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0838, decode.acc_seg: 96.7817, loss: 0.0838
2022-11-29 20:29:16,060 - mmseg - INFO - Iter [31500/40000]	lr: 1.275e-05, eta: 0:38:43, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1089, decode.acc_seg: 96.1178, loss: 0.1089
2022-11-29 20:29:29,032 - mmseg - INFO - Iter [31550/40000]	lr: 1.268e-05, eta: 0:38:29, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1187, decode.acc_seg: 95.9585, loss: 0.1187
2022-11-29 20:29:41,975 - mmseg - INFO - Iter [31600/40000]	lr: 1.260e-05, eta: 0:38:15, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0893, decode.acc_seg: 96.5719, loss: 0.0893
2022-11-29 20:29:54,925 - mmseg - INFO - Iter [31650/40000]	lr: 1.253e-05, eta: 0:38:02, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1363, decode.acc_seg: 94.8080, loss: 0.1363
2022-11-29 20:30:08,023 - mmseg - INFO - Iter [31700/40000]	lr: 1.245e-05, eta: 0:37:48, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0936, decode.acc_seg: 96.2976, loss: 0.0936
2022-11-29 20:30:21,126 - mmseg - INFO - Iter [31750/40000]	lr: 1.238e-05, eta: 0:37:34, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0739, decode.acc_seg: 97.5809, loss: 0.0739
2022-11-29 20:30:34,125 - mmseg - INFO - Iter [31800/40000]	lr: 1.230e-05, eta: 0:37:20, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0731, decode.acc_seg: 97.0243, loss: 0.0731
2022-11-29 20:30:47,129 - mmseg - INFO - Iter [31850/40000]	lr: 1.223e-05, eta: 0:37:06, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1208, decode.acc_seg: 95.1537, loss: 0.1208
2022-11-29 20:31:00,131 - mmseg - INFO - Iter [31900/40000]	lr: 1.215e-05, eta: 0:36:52, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0686, decode.acc_seg: 97.2051, loss: 0.0686
2022-11-29 20:31:13,216 - mmseg - INFO - Iter [31950/40000]	lr: 1.208e-05, eta: 0:36:39, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1134, decode.acc_seg: 95.8428, loss: 0.1134
2022-11-29 20:31:26,223 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:31:26,223 - mmseg - INFO - Iter [32000/40000]	lr: 1.200e-05, eta: 0:36:25, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0627, decode.acc_seg: 97.4174, loss: 0.0627
2022-11-29 20:31:39,237 - mmseg - INFO - Iter [32050/40000]	lr: 1.193e-05, eta: 0:36:11, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1215, decode.acc_seg: 96.1419, loss: 0.1215
2022-11-29 20:31:52,214 - mmseg - INFO - Iter [32100/40000]	lr: 1.185e-05, eta: 0:35:57, time: 0.260, data_time: 0.007, memory: 5537, decode.loss_ce: 0.0769, decode.acc_seg: 96.9329, loss: 0.0769
2022-11-29 20:32:05,197 - mmseg - INFO - Iter [32150/40000]	lr: 1.178e-05, eta: 0:35:43, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1635, decode.acc_seg: 94.4158, loss: 0.1635
2022-11-29 20:32:18,234 - mmseg - INFO - Iter [32200/40000]	lr: 1.170e-05, eta: 0:35:30, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0766, decode.acc_seg: 97.0820, loss: 0.0766
2022-11-29 20:32:33,342 - mmseg - INFO - Iter [32250/40000]	lr: 1.163e-05, eta: 0:35:16, time: 0.302, data_time: 0.048, memory: 5537, decode.loss_ce: 0.0767, decode.acc_seg: 96.9467, loss: 0.0767
2022-11-29 20:32:46,398 - mmseg - INFO - Iter [32300/40000]	lr: 1.155e-05, eta: 0:35:02, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0569, decode.acc_seg: 97.5183, loss: 0.0569
2022-11-29 20:32:59,343 - mmseg - INFO - Iter [32350/40000]	lr: 1.148e-05, eta: 0:34:49, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1202, decode.acc_seg: 95.8180, loss: 0.1202
2022-11-29 20:33:12,292 - mmseg - INFO - Iter [32400/40000]	lr: 1.140e-05, eta: 0:34:35, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0967, decode.acc_seg: 96.0778, loss: 0.0967
2022-11-29 20:33:25,222 - mmseg - INFO - Iter [32450/40000]	lr: 1.133e-05, eta: 0:34:21, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1195, decode.acc_seg: 95.8887, loss: 0.1195
2022-11-29 20:33:38,198 - mmseg - INFO - Iter [32500/40000]	lr: 1.125e-05, eta: 0:34:07, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0800, decode.acc_seg: 96.9339, loss: 0.0800
2022-11-29 20:33:51,152 - mmseg - INFO - Iter [32550/40000]	lr: 1.118e-05, eta: 0:33:53, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0675, decode.acc_seg: 97.1474, loss: 0.0675
2022-11-29 20:34:04,099 - mmseg - INFO - Iter [32600/40000]	lr: 1.110e-05, eta: 0:33:40, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0916, decode.acc_seg: 96.2713, loss: 0.0916
2022-11-29 20:34:17,047 - mmseg - INFO - Iter [32650/40000]	lr: 1.103e-05, eta: 0:33:26, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0834, decode.acc_seg: 96.7955, loss: 0.0834
2022-11-29 20:34:30,091 - mmseg - INFO - Iter [32700/40000]	lr: 1.095e-05, eta: 0:33:12, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1022, decode.acc_seg: 96.0219, loss: 0.1022
2022-11-29 20:34:43,124 - mmseg - INFO - Iter [32750/40000]	lr: 1.088e-05, eta: 0:32:58, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0858, decode.acc_seg: 96.0941, loss: 0.0858
2022-11-29 20:34:56,153 - mmseg - INFO - Iter [32800/40000]	lr: 1.080e-05, eta: 0:32:44, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0565, decode.acc_seg: 97.8691, loss: 0.0565
2022-11-29 20:35:09,228 - mmseg - INFO - Iter [32850/40000]	lr: 1.073e-05, eta: 0:32:31, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0731, decode.acc_seg: 97.1817, loss: 0.0731
2022-11-29 20:35:22,228 - mmseg - INFO - Iter [32900/40000]	lr: 1.065e-05, eta: 0:32:17, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0686, decode.acc_seg: 97.3971, loss: 0.0686
2022-11-29 20:35:35,231 - mmseg - INFO - Iter [32950/40000]	lr: 1.058e-05, eta: 0:32:03, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0923, decode.acc_seg: 96.3945, loss: 0.0923
2022-11-29 20:35:48,307 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:35:48,307 - mmseg - INFO - Iter [33000/40000]	lr: 1.050e-05, eta: 0:31:49, time: 0.262, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0576, decode.acc_seg: 97.9483, loss: 0.0576
2022-11-29 20:36:01,267 - mmseg - INFO - Iter [33050/40000]	lr: 1.043e-05, eta: 0:31:35, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0845, decode.acc_seg: 96.5445, loss: 0.0845
2022-11-29 20:36:14,280 - mmseg - INFO - Iter [33100/40000]	lr: 1.035e-05, eta: 0:31:22, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1023, decode.acc_seg: 95.5618, loss: 0.1023
2022-11-29 20:36:27,228 - mmseg - INFO - Iter [33150/40000]	lr: 1.028e-05, eta: 0:31:08, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0873, decode.acc_seg: 96.3442, loss: 0.0873
2022-11-29 20:36:40,148 - mmseg - INFO - Iter [33200/40000]	lr: 1.020e-05, eta: 0:30:54, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1013, decode.acc_seg: 95.8694, loss: 0.1013
2022-11-29 20:36:53,006 - mmseg - INFO - Iter [33250/40000]	lr: 1.013e-05, eta: 0:30:40, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1049, decode.acc_seg: 96.1437, loss: 0.1049
2022-11-29 20:37:05,873 - mmseg - INFO - Iter [33300/40000]	lr: 1.005e-05, eta: 0:30:27, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1247, decode.acc_seg: 95.7259, loss: 0.1247
2022-11-29 20:37:18,766 - mmseg - INFO - Iter [33350/40000]	lr: 9.976e-06, eta: 0:30:13, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0750, decode.acc_seg: 96.4845, loss: 0.0750
2022-11-29 20:37:31,730 - mmseg - INFO - Iter [33400/40000]	lr: 9.901e-06, eta: 0:29:59, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0781, decode.acc_seg: 97.4012, loss: 0.0781
2022-11-29 20:37:44,584 - mmseg - INFO - Iter [33450/40000]	lr: 9.826e-06, eta: 0:29:45, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0881, decode.acc_seg: 96.4497, loss: 0.0881
2022-11-29 20:37:57,437 - mmseg - INFO - Iter [33500/40000]	lr: 9.752e-06, eta: 0:29:31, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0668, decode.acc_seg: 97.4684, loss: 0.0668
2022-11-29 20:38:10,384 - mmseg - INFO - Iter [33550/40000]	lr: 9.676e-06, eta: 0:29:18, time: 0.259, data_time: 0.007, memory: 5537, decode.loss_ce: 0.0789, decode.acc_seg: 96.7610, loss: 0.0789
2022-11-29 20:38:23,301 - mmseg - INFO - Iter [33600/40000]	lr: 9.601e-06, eta: 0:29:04, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0991, decode.acc_seg: 95.9971, loss: 0.0991
2022-11-29 20:38:36,223 - mmseg - INFO - Iter [33650/40000]	lr: 9.527e-06, eta: 0:28:50, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1088, decode.acc_seg: 95.1761, loss: 0.1088
2022-11-29 20:38:51,155 - mmseg - INFO - Iter [33700/40000]	lr: 9.452e-06, eta: 0:28:37, time: 0.299, data_time: 0.047, memory: 5537, decode.loss_ce: 0.1026, decode.acc_seg: 95.2047, loss: 0.1026
2022-11-29 20:39:03,950 - mmseg - INFO - Iter [33750/40000]	lr: 9.377e-06, eta: 0:28:23, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0497, decode.acc_seg: 98.2168, loss: 0.0497
2022-11-29 20:39:16,813 - mmseg - INFO - Iter [33800/40000]	lr: 9.301e-06, eta: 0:28:09, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0790, decode.acc_seg: 96.5933, loss: 0.0790
2022-11-29 20:39:29,688 - mmseg - INFO - Iter [33850/40000]	lr: 9.227e-06, eta: 0:27:55, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0765, decode.acc_seg: 96.7072, loss: 0.0765
2022-11-29 20:39:42,646 - mmseg - INFO - Iter [33900/40000]	lr: 9.152e-06, eta: 0:27:42, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0684, decode.acc_seg: 96.7771, loss: 0.0684
2022-11-29 20:39:55,494 - mmseg - INFO - Iter [33950/40000]	lr: 9.077e-06, eta: 0:27:28, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0997, decode.acc_seg: 95.7991, loss: 0.0997
2022-11-29 20:40:08,397 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:40:08,397 - mmseg - INFO - Iter [34000/40000]	lr: 9.001e-06, eta: 0:27:14, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0504, decode.acc_seg: 97.9128, loss: 0.0504
2022-11-29 20:40:21,318 - mmseg - INFO - Iter [34050/40000]	lr: 8.926e-06, eta: 0:27:00, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0717, decode.acc_seg: 97.2659, loss: 0.0717
2022-11-29 20:40:34,219 - mmseg - INFO - Iter [34100/40000]	lr: 8.852e-06, eta: 0:26:47, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1068, decode.acc_seg: 96.0925, loss: 0.1068
2022-11-29 20:40:47,150 - mmseg - INFO - Iter [34150/40000]	lr: 8.777e-06, eta: 0:26:33, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0682, decode.acc_seg: 97.2403, loss: 0.0682
2022-11-29 20:41:00,093 - mmseg - INFO - Iter [34200/40000]	lr: 8.701e-06, eta: 0:26:19, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1002, decode.acc_seg: 96.3404, loss: 0.1002
2022-11-29 20:41:13,080 - mmseg - INFO - Iter [34250/40000]	lr: 8.626e-06, eta: 0:26:06, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0789, decode.acc_seg: 96.7190, loss: 0.0789
2022-11-29 20:41:26,011 - mmseg - INFO - Iter [34300/40000]	lr: 8.552e-06, eta: 0:25:52, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0841, decode.acc_seg: 96.8535, loss: 0.0841
2022-11-29 20:41:38,925 - mmseg - INFO - Iter [34350/40000]	lr: 8.477e-06, eta: 0:25:38, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0816, decode.acc_seg: 96.4910, loss: 0.0816
2022-11-29 20:41:51,850 - mmseg - INFO - Iter [34400/40000]	lr: 8.401e-06, eta: 0:25:24, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0587, decode.acc_seg: 97.6537, loss: 0.0587
2022-11-29 20:42:04,770 - mmseg - INFO - Iter [34450/40000]	lr: 8.326e-06, eta: 0:25:11, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0715, decode.acc_seg: 97.1045, loss: 0.0715
2022-11-29 20:42:17,671 - mmseg - INFO - Iter [34500/40000]	lr: 8.252e-06, eta: 0:24:57, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0826, decode.acc_seg: 95.6499, loss: 0.0826
2022-11-29 20:42:30,620 - mmseg - INFO - Iter [34550/40000]	lr: 8.177e-06, eta: 0:24:43, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0785, decode.acc_seg: 96.8752, loss: 0.0785
2022-11-29 20:42:43,529 - mmseg - INFO - Iter [34600/40000]	lr: 8.101e-06, eta: 0:24:29, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0609, decode.acc_seg: 97.4565, loss: 0.0609
2022-11-29 20:42:56,466 - mmseg - INFO - Iter [34650/40000]	lr: 8.026e-06, eta: 0:24:16, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1533, decode.acc_seg: 95.1140, loss: 0.1533
2022-11-29 20:43:09,418 - mmseg - INFO - Iter [34700/40000]	lr: 7.952e-06, eta: 0:24:02, time: 0.259, data_time: 0.007, memory: 5537, decode.loss_ce: 0.0854, decode.acc_seg: 96.4366, loss: 0.0854
2022-11-29 20:43:22,342 - mmseg - INFO - Iter [34750/40000]	lr: 7.877e-06, eta: 0:23:48, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0927, decode.acc_seg: 96.6281, loss: 0.0927
2022-11-29 20:43:35,272 - mmseg - INFO - Iter [34800/40000]	lr: 7.801e-06, eta: 0:23:35, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0665, decode.acc_seg: 97.2231, loss: 0.0665
2022-11-29 20:43:48,324 - mmseg - INFO - Iter [34850/40000]	lr: 7.726e-06, eta: 0:23:21, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0630, decode.acc_seg: 97.2698, loss: 0.0630
2022-11-29 20:44:01,249 - mmseg - INFO - Iter [34900/40000]	lr: 7.651e-06, eta: 0:23:07, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0773, decode.acc_seg: 96.6942, loss: 0.0773
2022-11-29 20:44:14,138 - mmseg - INFO - Iter [34950/40000]	lr: 7.577e-06, eta: 0:22:53, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1195, decode.acc_seg: 96.0287, loss: 0.1195
2022-11-29 20:44:27,050 - mmseg - INFO - Saving checkpoint at 35000 iterations
2022-11-29 20:44:29,761 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:44:29,761 - mmseg - INFO - Iter [35000/40000]	lr: 7.502e-06, eta: 0:22:40, time: 0.312, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0477, decode.acc_seg: 98.0715, loss: 0.0477
2022-11-29 20:45:11,401 - mmseg - INFO - per class results:
2022-11-29 20:45:11,402 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 93.86 | 97.22 |
|  aeroplane  | 88.72 | 93.22 |
|   bicycle   | 68.03 | 85.32 |
|     bird    | 88.96 | 91.32 |
|     boat    | 76.36 | 82.97 |
|    bottle   | 76.27 | 85.26 |
|     bus     | 90.25 | 94.09 |
|     car     | 83.37 | 90.35 |
|     cat     | 88.12 | 92.72 |
|    chair    | 35.18 |  50.7 |
|     cow     | 81.32 | 85.85 |
| diningtable | 61.29 | 66.28 |
|     dog     | 86.86 | 91.87 |
|    horse    | 80.69 | 89.39 |
|  motorbike  | 83.43 | 91.06 |
|    person   | 85.22 | 93.36 |
| pottedplant | 53.29 | 79.33 |
|    sheep    | 79.03 | 80.12 |
|     sofa    | 52.08 | 69.03 |
|    train    | 82.29 | 92.33 |
|  tvmonitor  | 56.33 | 65.88 |
+-------------+-------+-------+
2022-11-29 20:45:11,402 - mmseg - INFO - Summary:
2022-11-29 20:45:11,403 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.29 | 75.76 | 84.17 |
+-------+-------+-------+
2022-11-29 20:45:11,404 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:45:11,405 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9429, mIoU: 0.7576, mAcc: 0.8417, IoU.background: 0.9386, IoU.aeroplane: 0.8872, IoU.bicycle: 0.6803, IoU.bird: 0.8896, IoU.boat: 0.7636, IoU.bottle: 0.7627, IoU.bus: 0.9025, IoU.car: 0.8337, IoU.cat: 0.8812, IoU.chair: 0.3518, IoU.cow: 0.8132, IoU.diningtable: 0.6129, IoU.dog: 0.8686, IoU.horse: 0.8069, IoU.motorbike: 0.8343, IoU.person: 0.8522, IoU.pottedplant: 0.5329, IoU.sheep: 0.7903, IoU.sofa: 0.5208, IoU.train: 0.8229, IoU.tvmonitor: 0.5633, Acc.background: 0.9722, Acc.aeroplane: 0.9322, Acc.bicycle: 0.8532, Acc.bird: 0.9132, Acc.boat: 0.8297, Acc.bottle: 0.8526, Acc.bus: 0.9409, Acc.car: 0.9035, Acc.cat: 0.9272, Acc.chair: 0.5070, Acc.cow: 0.8585, Acc.diningtable: 0.6628, Acc.dog: 0.9187, Acc.horse: 0.8939, Acc.motorbike: 0.9106, Acc.person: 0.9336, Acc.pottedplant: 0.7933, Acc.sheep: 0.8012, Acc.sofa: 0.6903, Acc.train: 0.9233, Acc.tvmonitor: 0.6588
2022-11-29 20:45:24,369 - mmseg - INFO - Iter [35050/40000]	lr: 7.426e-06, eta: 0:22:32, time: 1.092, data_time: 0.839, memory: 5537, decode.loss_ce: 0.0983, decode.acc_seg: 95.9780, loss: 0.0983
2022-11-29 20:45:37,251 - mmseg - INFO - Iter [35100/40000]	lr: 7.351e-06, eta: 0:22:19, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0750, decode.acc_seg: 97.1158, loss: 0.0750
2022-11-29 20:45:52,326 - mmseg - INFO - Iter [35150/40000]	lr: 7.277e-06, eta: 0:22:05, time: 0.301, data_time: 0.048, memory: 5537, decode.loss_ce: 0.0773, decode.acc_seg: 97.0277, loss: 0.0773
2022-11-29 20:46:05,242 - mmseg - INFO - Iter [35200/40000]	lr: 7.202e-06, eta: 0:21:51, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0777, decode.acc_seg: 97.0713, loss: 0.0777
2022-11-29 20:46:18,168 - mmseg - INFO - Iter [35250/40000]	lr: 7.126e-06, eta: 0:21:38, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0648, decode.acc_seg: 97.6697, loss: 0.0648
2022-11-29 20:46:31,051 - mmseg - INFO - Iter [35300/40000]	lr: 7.051e-06, eta: 0:21:24, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0971, decode.acc_seg: 96.1678, loss: 0.0971
2022-11-29 20:46:43,961 - mmseg - INFO - Iter [35350/40000]	lr: 6.977e-06, eta: 0:21:10, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0759, decode.acc_seg: 97.4213, loss: 0.0759
2022-11-29 20:46:56,936 - mmseg - INFO - Iter [35400/40000]	lr: 6.902e-06, eta: 0:20:56, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0632, decode.acc_seg: 97.4420, loss: 0.0632
2022-11-29 20:47:09,835 - mmseg - INFO - Iter [35450/40000]	lr: 6.826e-06, eta: 0:20:43, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0905, decode.acc_seg: 96.7175, loss: 0.0905
2022-11-29 20:47:22,757 - mmseg - INFO - Iter [35500/40000]	lr: 6.751e-06, eta: 0:20:29, time: 0.258, data_time: 0.007, memory: 5537, decode.loss_ce: 0.0701, decode.acc_seg: 97.0561, loss: 0.0701
2022-11-29 20:47:35,642 - mmseg - INFO - Iter [35550/40000]	lr: 6.677e-06, eta: 0:20:15, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0994, decode.acc_seg: 95.9873, loss: 0.0994
2022-11-29 20:47:48,566 - mmseg - INFO - Iter [35600/40000]	lr: 6.602e-06, eta: 0:20:01, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0863, decode.acc_seg: 96.3150, loss: 0.0863
2022-11-29 20:48:01,494 - mmseg - INFO - Iter [35650/40000]	lr: 6.526e-06, eta: 0:19:48, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0729, decode.acc_seg: 97.3813, loss: 0.0729
2022-11-29 20:48:14,408 - mmseg - INFO - Iter [35700/40000]	lr: 6.451e-06, eta: 0:19:34, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0636, decode.acc_seg: 97.4492, loss: 0.0636
2022-11-29 20:48:27,323 - mmseg - INFO - Iter [35750/40000]	lr: 6.377e-06, eta: 0:19:20, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0499, decode.acc_seg: 98.1544, loss: 0.0499
2022-11-29 20:48:40,234 - mmseg - INFO - Iter [35800/40000]	lr: 6.302e-06, eta: 0:19:06, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0795, decode.acc_seg: 96.9329, loss: 0.0795
2022-11-29 20:48:53,135 - mmseg - INFO - Iter [35850/40000]	lr: 6.226e-06, eta: 0:18:53, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0488, decode.acc_seg: 97.8910, loss: 0.0488
2022-11-29 20:49:06,069 - mmseg - INFO - Iter [35900/40000]	lr: 6.151e-06, eta: 0:18:39, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0577, decode.acc_seg: 97.4361, loss: 0.0577
2022-11-29 20:49:18,981 - mmseg - INFO - Iter [35950/40000]	lr: 6.077e-06, eta: 0:18:25, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1546, decode.acc_seg: 94.7786, loss: 0.1546
2022-11-29 20:49:31,879 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:49:31,880 - mmseg - INFO - Iter [36000/40000]	lr: 6.002e-06, eta: 0:18:11, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0807, decode.acc_seg: 97.2021, loss: 0.0807
2022-11-29 20:49:44,811 - mmseg - INFO - Iter [36050/40000]	lr: 5.926e-06, eta: 0:17:58, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0774, decode.acc_seg: 96.9788, loss: 0.0774
2022-11-29 20:49:57,720 - mmseg - INFO - Iter [36100/40000]	lr: 5.851e-06, eta: 0:17:44, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1233, decode.acc_seg: 95.1521, loss: 0.1233
2022-11-29 20:50:10,634 - mmseg - INFO - Iter [36150/40000]	lr: 5.777e-06, eta: 0:17:30, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0890, decode.acc_seg: 96.6892, loss: 0.0890
2022-11-29 20:50:23,491 - mmseg - INFO - Iter [36200/40000]	lr: 5.702e-06, eta: 0:17:16, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0630, decode.acc_seg: 97.3366, loss: 0.0630
2022-11-29 20:50:36,429 - mmseg - INFO - Iter [36250/40000]	lr: 5.627e-06, eta: 0:17:03, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0863, decode.acc_seg: 96.6041, loss: 0.0863
2022-11-29 20:50:49,430 - mmseg - INFO - Iter [36300/40000]	lr: 5.551e-06, eta: 0:16:49, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0724, decode.acc_seg: 97.5722, loss: 0.0724
2022-11-29 20:51:02,313 - mmseg - INFO - Iter [36350/40000]	lr: 5.476e-06, eta: 0:16:35, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0802, decode.acc_seg: 97.0305, loss: 0.0802
2022-11-29 20:51:15,214 - mmseg - INFO - Iter [36400/40000]	lr: 5.402e-06, eta: 0:16:22, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0629, decode.acc_seg: 97.5891, loss: 0.0629
2022-11-29 20:51:28,062 - mmseg - INFO - Iter [36450/40000]	lr: 5.327e-06, eta: 0:16:08, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0635, decode.acc_seg: 97.7156, loss: 0.0635
2022-11-29 20:51:40,908 - mmseg - INFO - Iter [36500/40000]	lr: 5.251e-06, eta: 0:15:54, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0968, decode.acc_seg: 96.6108, loss: 0.0968
2022-11-29 20:51:53,731 - mmseg - INFO - Iter [36550/40000]	lr: 5.176e-06, eta: 0:15:40, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0615, decode.acc_seg: 97.5122, loss: 0.0615
2022-11-29 20:52:06,546 - mmseg - INFO - Iter [36600/40000]	lr: 5.102e-06, eta: 0:15:27, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0627, decode.acc_seg: 97.6229, loss: 0.0627
2022-11-29 20:52:21,625 - mmseg - INFO - Iter [36650/40000]	lr: 5.027e-06, eta: 0:15:13, time: 0.302, data_time: 0.047, memory: 5537, decode.loss_ce: 0.0667, decode.acc_seg: 97.3853, loss: 0.0667
2022-11-29 20:52:34,549 - mmseg - INFO - Iter [36700/40000]	lr: 4.951e-06, eta: 0:15:00, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0596, decode.acc_seg: 97.4761, loss: 0.0596
2022-11-29 20:52:47,356 - mmseg - INFO - Iter [36750/40000]	lr: 4.876e-06, eta: 0:14:46, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0511, decode.acc_seg: 97.9175, loss: 0.0511
2022-11-29 20:53:00,160 - mmseg - INFO - Iter [36800/40000]	lr: 4.802e-06, eta: 0:14:32, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0509, decode.acc_seg: 97.7957, loss: 0.0509
2022-11-29 20:53:12,970 - mmseg - INFO - Iter [36850/40000]	lr: 4.727e-06, eta: 0:14:18, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0691, decode.acc_seg: 97.4216, loss: 0.0691
2022-11-29 20:53:25,867 - mmseg - INFO - Iter [36900/40000]	lr: 4.651e-06, eta: 0:14:05, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0704, decode.acc_seg: 96.7213, loss: 0.0704
2022-11-29 20:53:38,707 - mmseg - INFO - Iter [36950/40000]	lr: 4.576e-06, eta: 0:13:51, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0713, decode.acc_seg: 96.3364, loss: 0.0713
2022-11-29 20:53:51,533 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:53:51,534 - mmseg - INFO - Iter [37000/40000]	lr: 4.502e-06, eta: 0:13:37, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0940, decode.acc_seg: 96.5313, loss: 0.0940
2022-11-29 20:54:04,345 - mmseg - INFO - Iter [37050/40000]	lr: 4.427e-06, eta: 0:13:24, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0950, decode.acc_seg: 96.3464, loss: 0.0950
2022-11-29 20:54:17,155 - mmseg - INFO - Iter [37100/40000]	lr: 4.351e-06, eta: 0:13:10, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0753, decode.acc_seg: 96.5079, loss: 0.0753
2022-11-29 20:54:29,980 - mmseg - INFO - Iter [37150/40000]	lr: 4.276e-06, eta: 0:12:56, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0584, decode.acc_seg: 97.7734, loss: 0.0584
2022-11-29 20:54:42,803 - mmseg - INFO - Iter [37200/40000]	lr: 4.202e-06, eta: 0:12:43, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0822, decode.acc_seg: 97.6475, loss: 0.0822
2022-11-29 20:54:55,726 - mmseg - INFO - Iter [37250/40000]	lr: 4.127e-06, eta: 0:12:29, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0574, decode.acc_seg: 97.4280, loss: 0.0574
2022-11-29 20:55:08,593 - mmseg - INFO - Iter [37300/40000]	lr: 4.051e-06, eta: 0:12:15, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0884, decode.acc_seg: 96.8187, loss: 0.0884
2022-11-29 20:55:21,423 - mmseg - INFO - Iter [37350/40000]	lr: 3.976e-06, eta: 0:12:02, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0516, decode.acc_seg: 98.1513, loss: 0.0516
2022-11-29 20:55:34,259 - mmseg - INFO - Iter [37400/40000]	lr: 3.901e-06, eta: 0:11:48, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0877, decode.acc_seg: 96.6476, loss: 0.0877
2022-11-29 20:55:47,133 - mmseg - INFO - Iter [37450/40000]	lr: 3.827e-06, eta: 0:11:34, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0679, decode.acc_seg: 97.3877, loss: 0.0679
2022-11-29 20:55:59,984 - mmseg - INFO - Iter [37500/40000]	lr: 3.752e-06, eta: 0:11:20, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0676, decode.acc_seg: 97.6919, loss: 0.0676
2022-11-29 20:56:12,895 - mmseg - INFO - Iter [37550/40000]	lr: 3.676e-06, eta: 0:11:07, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0634, decode.acc_seg: 97.4873, loss: 0.0634
2022-11-29 20:56:25,729 - mmseg - INFO - Iter [37600/40000]	lr: 3.601e-06, eta: 0:10:53, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1062, decode.acc_seg: 96.7089, loss: 0.1062
2022-11-29 20:56:38,561 - mmseg - INFO - Iter [37650/40000]	lr: 3.527e-06, eta: 0:10:39, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0608, decode.acc_seg: 97.2606, loss: 0.0608
2022-11-29 20:56:51,470 - mmseg - INFO - Iter [37700/40000]	lr: 3.452e-06, eta: 0:10:26, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0946, decode.acc_seg: 96.0469, loss: 0.0946
2022-11-29 20:57:04,331 - mmseg - INFO - Iter [37750/40000]	lr: 3.376e-06, eta: 0:10:12, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0728, decode.acc_seg: 97.1828, loss: 0.0728
2022-11-29 20:57:17,220 - mmseg - INFO - Iter [37800/40000]	lr: 3.301e-06, eta: 0:09:59, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0578, decode.acc_seg: 98.0009, loss: 0.0578
2022-11-29 20:57:30,150 - mmseg - INFO - Iter [37850/40000]	lr: 3.227e-06, eta: 0:09:45, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0691, decode.acc_seg: 97.3710, loss: 0.0691
2022-11-29 20:57:43,057 - mmseg - INFO - Iter [37900/40000]	lr: 3.152e-06, eta: 0:09:31, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0998, decode.acc_seg: 96.5936, loss: 0.0998
2022-11-29 20:57:55,891 - mmseg - INFO - Iter [37950/40000]	lr: 3.076e-06, eta: 0:09:18, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0595, decode.acc_seg: 97.3597, loss: 0.0595
2022-11-29 20:58:08,768 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 20:58:08,768 - mmseg - INFO - Iter [38000/40000]	lr: 3.001e-06, eta: 0:09:04, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0692, decode.acc_seg: 97.5431, loss: 0.0692
2022-11-29 20:58:21,615 - mmseg - INFO - Iter [38050/40000]	lr: 2.927e-06, eta: 0:08:50, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0543, decode.acc_seg: 97.9990, loss: 0.0543
2022-11-29 20:58:36,699 - mmseg - INFO - Iter [38100/40000]	lr: 2.852e-06, eta: 0:08:37, time: 0.302, data_time: 0.048, memory: 5537, decode.loss_ce: 0.0677, decode.acc_seg: 96.8273, loss: 0.0677
2022-11-29 20:58:49,703 - mmseg - INFO - Iter [38150/40000]	lr: 2.776e-06, eta: 0:08:23, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0574, decode.acc_seg: 97.5694, loss: 0.0574
2022-11-29 20:59:02,583 - mmseg - INFO - Iter [38200/40000]	lr: 2.701e-06, eta: 0:08:09, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0603, decode.acc_seg: 97.8813, loss: 0.0603
2022-11-29 20:59:15,477 - mmseg - INFO - Iter [38250/40000]	lr: 2.627e-06, eta: 0:07:56, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0688, decode.acc_seg: 97.2090, loss: 0.0688
2022-11-29 20:59:28,363 - mmseg - INFO - Iter [38300/40000]	lr: 2.552e-06, eta: 0:07:42, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0812, decode.acc_seg: 96.6808, loss: 0.0812
2022-11-29 20:59:41,454 - mmseg - INFO - Iter [38350/40000]	lr: 2.476e-06, eta: 0:07:29, time: 0.262, data_time: 0.007, memory: 5537, decode.loss_ce: 0.1226, decode.acc_seg: 96.0048, loss: 0.1226
2022-11-29 20:59:54,578 - mmseg - INFO - Iter [38400/40000]	lr: 2.401e-06, eta: 0:07:15, time: 0.263, data_time: 0.007, memory: 5537, decode.loss_ce: 0.1023, decode.acc_seg: 96.4527, loss: 0.1023
2022-11-29 21:00:07,883 - mmseg - INFO - Iter [38450/40000]	lr: 2.327e-06, eta: 0:07:01, time: 0.266, data_time: 0.007, memory: 5537, decode.loss_ce: 0.0633, decode.acc_seg: 97.5490, loss: 0.0633
2022-11-29 21:00:20,938 - mmseg - INFO - Iter [38500/40000]	lr: 2.252e-06, eta: 0:06:48, time: 0.261, data_time: 0.007, memory: 5537, decode.loss_ce: 0.0520, decode.acc_seg: 97.8938, loss: 0.0520
2022-11-29 21:00:33,860 - mmseg - INFO - Iter [38550/40000]	lr: 2.176e-06, eta: 0:06:34, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0684, decode.acc_seg: 97.5625, loss: 0.0684
2022-11-29 21:00:46,768 - mmseg - INFO - Iter [38600/40000]	lr: 2.101e-06, eta: 0:06:20, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0698, decode.acc_seg: 97.7294, loss: 0.0698
2022-11-29 21:00:59,837 - mmseg - INFO - Iter [38650/40000]	lr: 2.026e-06, eta: 0:06:07, time: 0.261, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1212, decode.acc_seg: 96.1998, loss: 0.1212
2022-11-29 21:01:12,844 - mmseg - INFO - Iter [38700/40000]	lr: 1.952e-06, eta: 0:05:53, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0880, decode.acc_seg: 96.5870, loss: 0.0880
2022-11-29 21:01:25,711 - mmseg - INFO - Iter [38750/40000]	lr: 1.877e-06, eta: 0:05:40, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0802, decode.acc_seg: 97.1947, loss: 0.0802
2022-11-29 21:01:38,583 - mmseg - INFO - Iter [38800/40000]	lr: 1.801e-06, eta: 0:05:26, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0628, decode.acc_seg: 97.6336, loss: 0.0628
2022-11-29 21:01:51,462 - mmseg - INFO - Iter [38850/40000]	lr: 1.726e-06, eta: 0:05:12, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0680, decode.acc_seg: 97.2326, loss: 0.0680
2022-11-29 21:02:04,405 - mmseg - INFO - Iter [38900/40000]	lr: 1.652e-06, eta: 0:04:59, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0710, decode.acc_seg: 97.3208, loss: 0.0710
2022-11-29 21:02:17,280 - mmseg - INFO - Iter [38950/40000]	lr: 1.577e-06, eta: 0:04:45, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0634, decode.acc_seg: 97.3885, loss: 0.0634
2022-11-29 21:02:30,163 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 21:02:30,164 - mmseg - INFO - Iter [39000/40000]	lr: 1.501e-06, eta: 0:04:31, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0637, decode.acc_seg: 97.4625, loss: 0.0637
2022-11-29 21:02:43,054 - mmseg - INFO - Iter [39050/40000]	lr: 1.426e-06, eta: 0:04:18, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0727, decode.acc_seg: 97.3810, loss: 0.0727
2022-11-29 21:02:56,028 - mmseg - INFO - Iter [39100/40000]	lr: 1.352e-06, eta: 0:04:04, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0582, decode.acc_seg: 97.9133, loss: 0.0582
2022-11-29 21:03:08,931 - mmseg - INFO - Iter [39150/40000]	lr: 1.277e-06, eta: 0:03:51, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0874, decode.acc_seg: 96.6756, loss: 0.0874
2022-11-29 21:03:21,806 - mmseg - INFO - Iter [39200/40000]	lr: 1.201e-06, eta: 0:03:37, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0597, decode.acc_seg: 97.4634, loss: 0.0597
2022-11-29 21:03:34,656 - mmseg - INFO - Iter [39250/40000]	lr: 1.126e-06, eta: 0:03:23, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0607, decode.acc_seg: 97.3416, loss: 0.0607
2022-11-29 21:03:47,540 - mmseg - INFO - Iter [39300/40000]	lr: 1.052e-06, eta: 0:03:10, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.1336, decode.acc_seg: 95.2587, loss: 0.1336
2022-11-29 21:04:00,408 - mmseg - INFO - Iter [39350/40000]	lr: 9.765e-07, eta: 0:02:56, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0574, decode.acc_seg: 97.7190, loss: 0.0574
2022-11-29 21:04:13,235 - mmseg - INFO - Iter [39400/40000]	lr: 9.015e-07, eta: 0:02:43, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0796, decode.acc_seg: 96.4563, loss: 0.0796
2022-11-29 21:04:26,051 - mmseg - INFO - Iter [39450/40000]	lr: 8.265e-07, eta: 0:02:29, time: 0.256, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0590, decode.acc_seg: 97.5949, loss: 0.0590
2022-11-29 21:04:38,881 - mmseg - INFO - Iter [39500/40000]	lr: 7.515e-07, eta: 0:02:15, time: 0.257, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0568, decode.acc_seg: 97.9105, loss: 0.0568
2022-11-29 21:04:53,889 - mmseg - INFO - Iter [39550/40000]	lr: 6.765e-07, eta: 0:02:02, time: 0.300, data_time: 0.047, memory: 5537, decode.loss_ce: 0.0636, decode.acc_seg: 97.1587, loss: 0.0636
2022-11-29 21:05:06,854 - mmseg - INFO - Iter [39600/40000]	lr: 6.015e-07, eta: 0:01:48, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0627, decode.acc_seg: 97.4921, loss: 0.0627
2022-11-29 21:05:19,788 - mmseg - INFO - Iter [39650/40000]	lr: 5.265e-07, eta: 0:01:35, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0715, decode.acc_seg: 97.3611, loss: 0.0715
2022-11-29 21:05:32,704 - mmseg - INFO - Iter [39700/40000]	lr: 4.515e-07, eta: 0:01:21, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0605, decode.acc_seg: 97.4852, loss: 0.0605
2022-11-29 21:05:45,641 - mmseg - INFO - Iter [39750/40000]	lr: 3.765e-07, eta: 0:01:07, time: 0.259, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0843, decode.acc_seg: 95.9937, loss: 0.0843
2022-11-29 21:05:58,628 - mmseg - INFO - Iter [39800/40000]	lr: 3.015e-07, eta: 0:00:54, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0548, decode.acc_seg: 97.3798, loss: 0.0548
2022-11-29 21:06:11,628 - mmseg - INFO - Iter [39850/40000]	lr: 2.265e-07, eta: 0:00:40, time: 0.260, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0794, decode.acc_seg: 96.8066, loss: 0.0794
2022-11-29 21:06:24,538 - mmseg - INFO - Iter [39900/40000]	lr: 1.515e-07, eta: 0:00:27, time: 0.258, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0697, decode.acc_seg: 97.0621, loss: 0.0697
2022-11-29 21:06:37,476 - mmseg - INFO - Iter [39950/40000]	lr: 7.650e-08, eta: 0:00:13, time: 0.259, data_time: 0.007, memory: 5537, decode.loss_ce: 0.0751, decode.acc_seg: 97.2470, loss: 0.0751
2022-11-29 21:06:50,519 - mmseg - INFO - Saving checkpoint at 40000 iterations
2022-11-29 21:06:52,981 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 21:06:52,981 - mmseg - INFO - Iter [40000/40000]	lr: 1.500e-09, eta: 0:00:00, time: 0.310, data_time: 0.006, memory: 5537, decode.loss_ce: 0.0650, decode.acc_seg: 97.8835, loss: 0.0650
2022-11-29 21:07:34,685 - mmseg - INFO - per class results:
2022-11-29 21:07:34,687 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 93.91 | 97.08 |
|  aeroplane  | 88.05 | 91.71 |
|   bicycle   | 68.39 | 83.02 |
|     bird    | 83.21 | 92.31 |
|     boat    | 75.15 | 79.08 |
|    bottle   | 74.53 | 87.82 |
|     bus     | 90.31 | 94.96 |
|     car     | 85.33 | 89.94 |
|     cat     | 88.59 | 93.56 |
|    chair    | 32.71 | 50.23 |
|     cow     | 81.37 | 91.23 |
| diningtable |  60.9 | 66.79 |
|     dog     | 85.39 | 93.93 |
|    horse    | 83.47 | 90.31 |
|  motorbike  | 81.63 | 90.47 |
|    person   | 84.48 | 94.94 |
| pottedplant | 59.39 | 74.31 |
|    sheep    | 72.28 | 74.69 |
|     sofa    | 52.33 |  62.7 |
|    train    |  70.5 | 87.82 |
|  tvmonitor  | 57.53 | 67.48 |
+-------------+-------+-------+
2022-11-29 21:07:34,687 - mmseg - INFO - Summary:
2022-11-29 21:07:34,687 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.15 | 74.74 | 83.54 |
+-------+-------+-------+
2022-11-29 21:07:34,689 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k.py
2022-11-29 21:07:34,689 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9415, mIoU: 0.7474, mAcc: 0.8354, IoU.background: 0.9391, IoU.aeroplane: 0.8805, IoU.bicycle: 0.6839, IoU.bird: 0.8321, IoU.boat: 0.7515, IoU.bottle: 0.7453, IoU.bus: 0.9031, IoU.car: 0.8533, IoU.cat: 0.8859, IoU.chair: 0.3271, IoU.cow: 0.8137, IoU.diningtable: 0.6090, IoU.dog: 0.8539, IoU.horse: 0.8347, IoU.motorbike: 0.8163, IoU.person: 0.8448, IoU.pottedplant: 0.5939, IoU.sheep: 0.7228, IoU.sofa: 0.5233, IoU.train: 0.7050, IoU.tvmonitor: 0.5753, Acc.background: 0.9708, Acc.aeroplane: 0.9171, Acc.bicycle: 0.8302, Acc.bird: 0.9231, Acc.boat: 0.7908, Acc.bottle: 0.8782, Acc.bus: 0.9496, Acc.car: 0.8994, Acc.cat: 0.9356, Acc.chair: 0.5023, Acc.cow: 0.9123, Acc.diningtable: 0.6679, Acc.dog: 0.9393, Acc.horse: 0.9031, Acc.motorbike: 0.9047, Acc.person: 0.9494, Acc.pottedplant: 0.7431, Acc.sheep: 0.7469, Acc.sofa: 0.6270, Acc.train: 0.8782, Acc.tvmonitor: 0.6748
