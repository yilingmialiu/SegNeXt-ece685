2022-11-29 18:22:17,511 - mmseg - INFO - Multi-processing start method is `None`
2022-11-29 18:22:17,511 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>
2022-11-29 18:22:17,588 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.8 (default, Apr 13 2021, 19:58:26) [GCC 7.3.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.5, V11.5.119
GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-3)
PyTorch: 1.11.0+cu102
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.2-Product Build 20210312 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu102
OpenCV: 4.6.0
MMCV: 1.6.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 10.2
MMSegmentation: 0.24.1+
------------------------------------------------------------

2022-11-29 18:22:17,588 - mmseg - INFO - Distributed training: False
2022-11-29 18:22:17,881 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
ham_norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='MSCAN',
        embed_dims=[64, 128, 320, 512],
        mlp_ratios=[8, 8, 4, 4],
        drop_rate=0.0,
        drop_path_rate=0.3,
        depths=[3, 5, 27, 3],
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        init_cfg=dict(type='Pretrained', checkpoint='pretrained/mscan_l.pth')),
    decode_head=dict(
        type='LightHamHead',
        in_channels=[128, 320, 512],
        in_index=[1, 2, 3],
        channels=1024,
        ham_channels=1024,
        dropout_ratio=0.1,
        num_classes=21,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'PascalVOCDataset'
data_root = '/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=1,
    train=dict(
        type='PascalVOCDataset',
        data_root='/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/train_sub.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='PascalVOCDataset',
        data_root='/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='PascalVOCDataset',
        data_root='/datacommons/carlsonlab/yl407/VOCdevkit/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/test.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=40000)
checkpoint_config = dict(by_epoch=False, interval=5000)
evaluation = dict(interval=5000, metric='mIoU')
find_unused_parameters = True
work_dir = './work_dirs/segnext.large.512x512.voc.40k_sub'
gpu_ids = [0]
auto_resume = False

2022-11-29 18:22:17,882 - mmseg - INFO - Set random seed to 1169021884, deterministic: False
2022-11-29 18:22:18,368 - mmseg - INFO - initialize MSCAN with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/mscan_l.pth'}
2022-11-29 18:22:23,789 - mmseg - INFO - initialize LightHamHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.patch_embed1.proj.0.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.0.bias - torch.Size([32]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.1.weight - torch.Size([32]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.1.bias - torch.Size([32]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.3.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.3.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.4.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed1.proj.4.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.layer_scale_1 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.layer_scale_2 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.proj_1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.proj_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0.weight - torch.Size([64, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([64, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([64, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([64, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([64, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([64, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([64, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv3.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.spatial_gating_unit.conv3.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.proj_2.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.attn.proj_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.norm2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.norm2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.fc1.weight - torch.Size([512, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.fc1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.dwconv.dwconv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.dwconv.dwconv.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.fc2.weight - torch.Size([64, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.0.mlp.fc2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.layer_scale_1 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.layer_scale_2 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.proj_1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.proj_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0.weight - torch.Size([64, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([64, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([64, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([64, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([64, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([64, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([64, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv3.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.spatial_gating_unit.conv3.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.proj_2.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.attn.proj_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.norm2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.norm2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.fc1.weight - torch.Size([512, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.fc1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.dwconv.dwconv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.dwconv.dwconv.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.fc2.weight - torch.Size([64, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.1.mlp.fc2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.layer_scale_1 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.layer_scale_2 - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.proj_1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.proj_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0.weight - torch.Size([64, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([64, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([64, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([64, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([64, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([64, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([64, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv3.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.spatial_gating_unit.conv3.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.proj_2.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.attn.proj_2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.norm2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.norm2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.fc1.weight - torch.Size([512, 64, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.fc1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.dwconv.dwconv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.dwconv.dwconv.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.fc2.weight - torch.Size([64, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block1.2.mlp.fc2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed2.proj.weight - torch.Size([128, 64, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed2.proj.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed2.norm.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed2.norm.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.0.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.1.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.2.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.3.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.layer_scale_1 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.layer_scale_2 - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.proj_1.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.proj_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0.weight - torch.Size([128, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0_1.weight - torch.Size([128, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0_2.weight - torch.Size([128, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv0_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv1_1.weight - torch.Size([128, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv1_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv1_2.weight - torch.Size([128, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv1_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv2_1.weight - torch.Size([128, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv2_1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv2_2.weight - torch.Size([128, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv2_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv3.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.spatial_gating_unit.conv3.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.proj_2.weight - torch.Size([128, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.attn.proj_2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.fc1.weight - torch.Size([1024, 128, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.fc1.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.dwconv.dwconv.weight - torch.Size([1024, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.dwconv.dwconv.bias - torch.Size([1024]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.fc2.weight - torch.Size([128, 1024, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block2.4.mlp.fc2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed3.proj.weight - torch.Size([320, 128, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed3.proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed3.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed3.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.0.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.1.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.2.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.3.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.4.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.5.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.6.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.7.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.8.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.9.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.10.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.11.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.12.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.13.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.14.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.15.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.16.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.17.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.18.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.19.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.20.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.21.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.22.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.23.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.24.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.25.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.layer_scale_1 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.layer_scale_2 - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.proj_1.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.proj_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0.weight - torch.Size([320, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0_1.weight - torch.Size([320, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0_2.weight - torch.Size([320, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv0_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv1_1.weight - torch.Size([320, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv1_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv1_2.weight - torch.Size([320, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv1_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv2_1.weight - torch.Size([320, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv2_1.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv2_2.weight - torch.Size([320, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv2_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv3.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.spatial_gating_unit.conv3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.proj_2.weight - torch.Size([320, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.attn.proj_2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.fc1.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.fc1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.dwconv.dwconv.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.dwconv.dwconv.bias - torch.Size([1280]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.fc2.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block3.26.mlp.fc2.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm3.weight - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm3.bias - torch.Size([320]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed4.proj.weight - torch.Size([512, 320, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed4.proj.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed4.norm.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.patch_embed4.norm.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.layer_scale_1 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.layer_scale_2 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.norm1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.norm1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.proj_1.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.proj_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0.weight - torch.Size([512, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0_1.weight - torch.Size([512, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0_2.weight - torch.Size([512, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv0_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv1_1.weight - torch.Size([512, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv1_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv1_2.weight - torch.Size([512, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv1_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv2_1.weight - torch.Size([512, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv2_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv2_2.weight - torch.Size([512, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv2_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv3.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.spatial_gating_unit.conv3.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.proj_2.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.attn.proj_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.norm2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.norm2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.fc1.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.fc1.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.dwconv.dwconv.weight - torch.Size([2048, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.dwconv.dwconv.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.fc2.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.0.mlp.fc2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.layer_scale_1 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.layer_scale_2 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.norm1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.norm1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.proj_1.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.proj_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0.weight - torch.Size([512, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0_1.weight - torch.Size([512, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0_2.weight - torch.Size([512, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv0_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv1_1.weight - torch.Size([512, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv1_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv1_2.weight - torch.Size([512, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv1_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv2_1.weight - torch.Size([512, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv2_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv2_2.weight - torch.Size([512, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv2_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv3.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.spatial_gating_unit.conv3.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.proj_2.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.attn.proj_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.norm2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.norm2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.fc1.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.fc1.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.dwconv.dwconv.weight - torch.Size([2048, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.dwconv.dwconv.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.fc2.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.1.mlp.fc2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.layer_scale_1 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.layer_scale_2 - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.norm1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.norm1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.proj_1.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.proj_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0.weight - torch.Size([512, 1, 5, 5]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0_1.weight - torch.Size([512, 1, 1, 7]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0_2.weight - torch.Size([512, 1, 7, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv0_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv1_1.weight - torch.Size([512, 1, 1, 11]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv1_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv1_2.weight - torch.Size([512, 1, 11, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv1_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv2_1.weight - torch.Size([512, 1, 1, 21]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv2_1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv2_2.weight - torch.Size([512, 1, 21, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv2_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv3.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.spatial_gating_unit.conv3.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.proj_2.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.attn.proj_2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.norm2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.norm2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.fc1.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.fc1.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.dwconv.dwconv.weight - torch.Size([2048, 1, 3, 3]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.dwconv.dwconv.bias - torch.Size([2048]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.fc2.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.block4.2.mlp.fc2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm4.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

backbone.norm4.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/mscan_l.pth 

decode_head.conv_seg.weight - torch.Size([21, 1024, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([21]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.squeeze.conv.weight - torch.Size([1024, 960, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.squeeze.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.squeeze.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_in.conv.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_in.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_out.conv.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_out.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.hamburger.ham_out.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.conv.weight - torch.Size([1024, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.align.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2022-11-29 18:22:23,823 - mmseg - INFO - EncoderDecoder(
  (backbone): MSCAN(
    (patch_embed1): StemConv(
      (proj): Sequential(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU()
        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)
            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)
            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)
            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)
            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)
            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)
            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)
            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)
            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)
            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)
            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)
            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)
            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (conv0_1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=64)
            (conv0_2): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=64)
            (conv1_1): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)
            (conv1_2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)
            (conv2_1): Conv2d(64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)
            (conv2_2): Conv2d(64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)
            (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (conv0_1): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=128)
            (conv0_2): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=128)
            (conv1_1): Conv2d(128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)
            (conv1_2): Conv2d(128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)
            (conv2_1): Conv2d(128, 128, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=128)
            (conv2_2): Conv2d(128, 128, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=128)
            (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (norm1): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320)
            (conv0_1): Conv2d(320, 320, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=320)
            (conv0_2): Conv2d(320, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=320)
            (conv1_1): Conv2d(320, 320, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=320)
            (conv1_2): Conv2d(320, 320, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=320)
            (conv2_1): Conv2d(320, 320, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=320)
            (conv2_2): Conv2d(320, 320, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=320)
            (conv3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (conv0_1): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=512)
            (conv0_2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=512)
            (conv1_1): Conv2d(512, 512, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=512)
            (conv1_2): Conv2d(512, 512, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=512)
            (conv2_1): Conv2d(512, 512, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=512)
            (conv2_2): Conv2d(512, 512, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=512)
            (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (conv0_1): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=512)
            (conv0_2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=512)
            (conv1_1): Conv2d(512, 512, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=512)
            (conv1_2): Conv2d(512, 512, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=512)
            (conv2_1): Conv2d(512, 512, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=512)
            (conv2_2): Conv2d(512, 512, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=512)
            (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (attn): SpatialAttention(
          (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (activation): GELU()
          (spatial_gating_unit): AttentionModule(
            (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (conv0_1): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), groups=512)
            (conv0_2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=512)
            (conv1_1): Conv2d(512, 512, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=512)
            (conv1_2): Conv2d(512, 512, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=512)
            (conv2_1): Conv2d(512, 512, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=512)
            (conv2_2): Conv2d(512, 512, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=512)
            (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): DropPath()
        (norm2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlp): Mlp(
          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'pretrained/mscan_l.pth'}
  (decode_head): LightHamHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(1024, 21, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (squeeze): ConvModule(
      (conv): Conv2d(960, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
    (hamburger): Hamburger(
      (ham_in): ConvModule(
        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (ham): NMF2D()
      (ham_out): ConvModule(
        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
      )
    )
    (align): ConvModule(
      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2022-11-29 18:22:23,849 - mmseg - INFO - Loaded 183 images
2022-11-29 18:22:24,668 - mmseg - INFO - Loaded 724 images
2022-11-29 18:22:24,668 - mmseg - INFO - Start running, host: yl407@dcc-carlsonlab-gpu-11, work_dir: /work/yl407/SegNeXt/work_dirs/segnext.large.512x512.voc.40k_sub
2022-11-29 18:22:24,668 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-11-29 18:22:24,669 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters
2022-11-29 18:22:24,669 - mmseg - INFO - Checkpoints will be saved to /work/yl407/SegNeXt/work_dirs/segnext.large.512x512.voc.40k_sub by HardDiskBackend.
2022-11-29 18:22:38,958 - mmseg - INFO - Iter [50/40000]	lr: 1.958e-06, eta: 3:08:37, time: 0.283, data_time: 0.009, memory: 5529, decode.loss_ce: 2.3554, decode.acc_seg: 27.5872, loss: 2.3554
2022-11-29 18:22:51,922 - mmseg - INFO - Iter [100/40000]	lr: 3.950e-06, eta: 3:00:23, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 1.7149, decode.acc_seg: 66.0633, loss: 1.7149
2022-11-29 18:23:04,852 - mmseg - INFO - Iter [150/40000]	lr: 5.938e-06, eta: 2:57:21, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 1.7025, decode.acc_seg: 60.1815, loss: 1.7025
2022-11-29 18:23:19,792 - mmseg - INFO - Iter [200/40000]	lr: 7.920e-06, eta: 3:02:23, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 1.4386, decode.acc_seg: 65.5370, loss: 1.4386
2022-11-29 18:23:32,624 - mmseg - INFO - Iter [250/40000]	lr: 9.898e-06, eta: 2:59:43, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 1.4884, decode.acc_seg: 60.4812, loss: 1.4884
2022-11-29 18:23:45,535 - mmseg - INFO - Iter [300/40000]	lr: 1.187e-05, eta: 2:58:03, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 1.4275, decode.acc_seg: 65.5957, loss: 1.4275
2022-11-29 18:23:58,558 - mmseg - INFO - Iter [350/40000]	lr: 1.384e-05, eta: 2:57:01, time: 0.260, data_time: 0.006, memory: 5529, decode.loss_ce: 1.3189, decode.acc_seg: 62.9403, loss: 1.3189
2022-11-29 18:24:13,616 - mmseg - INFO - Iter [400/40000]	lr: 1.580e-05, eta: 2:59:32, time: 0.301, data_time: 0.047, memory: 5529, decode.loss_ce: 1.2823, decode.acc_seg: 63.7922, loss: 1.2823
2022-11-29 18:24:26,496 - mmseg - INFO - Iter [450/40000]	lr: 1.776e-05, eta: 2:58:15, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 1.3506, decode.acc_seg: 61.5062, loss: 1.3506
2022-11-29 18:24:39,377 - mmseg - INFO - Iter [500/40000]	lr: 1.971e-05, eta: 2:57:10, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 1.0627, decode.acc_seg: 71.0456, loss: 1.0627
2022-11-29 18:24:54,291 - mmseg - INFO - Iter [550/40000]	lr: 2.166e-05, eta: 2:58:41, time: 0.298, data_time: 0.047, memory: 5529, decode.loss_ce: 1.0020, decode.acc_seg: 71.9780, loss: 1.0020
2022-11-29 18:25:07,197 - mmseg - INFO - Iter [600/40000]	lr: 2.360e-05, eta: 2:57:43, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 0.8585, decode.acc_seg: 73.6110, loss: 0.8585
2022-11-29 18:25:20,129 - mmseg - INFO - Iter [650/40000]	lr: 2.554e-05, eta: 2:56:53, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 0.9664, decode.acc_seg: 69.5154, loss: 0.9664
2022-11-29 18:25:34,741 - mmseg - INFO - Iter [700/40000]	lr: 2.747e-05, eta: 2:57:43, time: 0.292, data_time: 0.006, memory: 5529, decode.loss_ce: 0.9977, decode.acc_seg: 70.1820, loss: 0.9977
2022-11-29 18:25:50,323 - mmseg - INFO - Iter [750/40000]	lr: 2.940e-05, eta: 2:59:15, time: 0.312, data_time: 0.047, memory: 5529, decode.loss_ce: 0.9294, decode.acc_seg: 71.6393, loss: 0.9294
2022-11-29 18:26:03,205 - mmseg - INFO - Iter [800/40000]	lr: 3.132e-05, eta: 2:58:21, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 0.8624, decode.acc_seg: 73.8429, loss: 0.8624
2022-11-29 18:26:16,131 - mmseg - INFO - Iter [850/40000]	lr: 3.324e-05, eta: 2:57:34, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 0.8489, decode.acc_seg: 75.7824, loss: 0.8489
2022-11-29 18:26:29,136 - mmseg - INFO - Iter [900/40000]	lr: 3.515e-05, eta: 2:56:54, time: 0.260, data_time: 0.006, memory: 5529, decode.loss_ce: 0.8711, decode.acc_seg: 75.2809, loss: 0.8711
2022-11-29 18:26:46,255 - mmseg - INFO - Iter [950/40000]	lr: 3.706e-05, eta: 2:59:06, time: 0.342, data_time: 0.048, memory: 5529, decode.loss_ce: 0.8312, decode.acc_seg: 72.1797, loss: 0.8312
2022-11-29 18:27:00,966 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 18:27:00,966 - mmseg - INFO - Iter [1000/40000]	lr: 3.896e-05, eta: 2:59:29, time: 0.294, data_time: 0.006, memory: 5529, decode.loss_ce: 0.7839, decode.acc_seg: 73.3741, loss: 0.7839
2022-11-29 18:27:13,885 - mmseg - INFO - Iter [1050/40000]	lr: 4.086e-05, eta: 2:58:43, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 0.7711, decode.acc_seg: 72.5346, loss: 0.7711
2022-11-29 18:27:29,161 - mmseg - INFO - Iter [1100/40000]	lr: 4.275e-05, eta: 2:59:22, time: 0.306, data_time: 0.048, memory: 5529, decode.loss_ce: 0.6658, decode.acc_seg: 78.6489, loss: 0.6658
2022-11-29 18:27:42,582 - mmseg - INFO - Iter [1150/40000]	lr: 4.464e-05, eta: 2:58:54, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.5038, decode.acc_seg: 83.4065, loss: 0.5038
2022-11-29 18:27:55,987 - mmseg - INFO - Iter [1200/40000]	lr: 4.652e-05, eta: 2:58:27, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.8313, decode.acc_seg: 70.7919, loss: 0.8313
2022-11-29 18:28:09,322 - mmseg - INFO - Iter [1250/40000]	lr: 4.840e-05, eta: 2:57:59, time: 0.267, data_time: 0.007, memory: 5529, decode.loss_ce: 0.8984, decode.acc_seg: 71.3810, loss: 0.8984
2022-11-29 18:28:24,595 - mmseg - INFO - Iter [1300/40000]	lr: 5.027e-05, eta: 2:58:30, time: 0.305, data_time: 0.048, memory: 5529, decode.loss_ce: 0.9709, decode.acc_seg: 70.4990, loss: 0.9709
2022-11-29 18:28:37,752 - mmseg - INFO - Iter [1350/40000]	lr: 5.214e-05, eta: 2:57:56, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.7680, decode.acc_seg: 76.7245, loss: 0.7680
2022-11-29 18:28:52,039 - mmseg - INFO - Iter [1400/40000]	lr: 5.400e-05, eta: 2:57:56, time: 0.286, data_time: 0.007, memory: 5529, decode.loss_ce: 0.6107, decode.acc_seg: 79.8252, loss: 0.6107
2022-11-29 18:29:06,754 - mmseg - INFO - Iter [1450/40000]	lr: 5.586e-05, eta: 2:58:05, time: 0.294, data_time: 0.007, memory: 5529, decode.loss_ce: 0.5907, decode.acc_seg: 79.6263, loss: 0.5907
2022-11-29 18:29:22,108 - mmseg - INFO - Iter [1500/40000]	lr: 5.771e-05, eta: 2:58:30, time: 0.307, data_time: 0.048, memory: 5529, decode.loss_ce: 0.6789, decode.acc_seg: 78.5506, loss: 0.6789
2022-11-29 18:29:35,892 - mmseg - INFO - Iter [1550/40000]	lr: 5.768e-05, eta: 2:58:13, time: 0.276, data_time: 0.007, memory: 5529, decode.loss_ce: 0.5251, decode.acc_seg: 82.0148, loss: 0.5251
2022-11-29 18:29:49,795 - mmseg - INFO - Iter [1600/40000]	lr: 5.760e-05, eta: 2:57:59, time: 0.278, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3581, decode.acc_seg: 88.7607, loss: 0.3581
2022-11-29 18:30:05,216 - mmseg - INFO - Iter [1650/40000]	lr: 5.753e-05, eta: 2:58:20, time: 0.308, data_time: 0.048, memory: 5529, decode.loss_ce: 0.7335, decode.acc_seg: 75.5718, loss: 0.7335
2022-11-29 18:30:19,650 - mmseg - INFO - Iter [1700/40000]	lr: 5.745e-05, eta: 2:58:17, time: 0.289, data_time: 0.009, memory: 5529, decode.loss_ce: 0.7208, decode.acc_seg: 74.2192, loss: 0.7208
2022-11-29 18:30:33,910 - mmseg - INFO - Iter [1750/40000]	lr: 5.738e-05, eta: 2:58:09, time: 0.285, data_time: 0.009, memory: 5529, decode.loss_ce: 0.6682, decode.acc_seg: 79.8695, loss: 0.6682
2022-11-29 18:30:47,102 - mmseg - INFO - Iter [1800/40000]	lr: 5.730e-05, eta: 2:57:39, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.5167, decode.acc_seg: 82.5672, loss: 0.5167
2022-11-29 18:31:02,363 - mmseg - INFO - Iter [1850/40000]	lr: 5.723e-05, eta: 2:57:52, time: 0.305, data_time: 0.048, memory: 5529, decode.loss_ce: 0.5798, decode.acc_seg: 81.3391, loss: 0.5798
2022-11-29 18:31:15,323 - mmseg - INFO - Iter [1900/40000]	lr: 5.715e-05, eta: 2:57:17, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.5129, decode.acc_seg: 83.5594, loss: 0.5129
2022-11-29 18:31:28,502 - mmseg - INFO - Iter [1950/40000]	lr: 5.708e-05, eta: 2:56:48, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.7343, decode.acc_seg: 78.4793, loss: 0.7343
2022-11-29 18:31:41,535 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 18:31:41,536 - mmseg - INFO - Iter [2000/40000]	lr: 5.700e-05, eta: 2:56:17, time: 0.261, data_time: 0.006, memory: 5529, decode.loss_ce: 0.6154, decode.acc_seg: 80.3071, loss: 0.6154
2022-11-29 18:31:56,816 - mmseg - INFO - Iter [2050/40000]	lr: 5.693e-05, eta: 2:56:28, time: 0.306, data_time: 0.047, memory: 5529, decode.loss_ce: 0.5181, decode.acc_seg: 82.4350, loss: 0.5181
2022-11-29 18:32:09,747 - mmseg - INFO - Iter [2100/40000]	lr: 5.685e-05, eta: 2:55:56, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 0.5403, decode.acc_seg: 83.0230, loss: 0.5403
2022-11-29 18:32:22,708 - mmseg - INFO - Iter [2150/40000]	lr: 5.678e-05, eta: 2:55:25, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 0.4930, decode.acc_seg: 82.4840, loss: 0.4930
2022-11-29 18:32:38,002 - mmseg - INFO - Iter [2200/40000]	lr: 5.670e-05, eta: 2:55:35, time: 0.306, data_time: 0.048, memory: 5529, decode.loss_ce: 0.5159, decode.acc_seg: 83.6186, loss: 0.5159
2022-11-29 18:32:51,397 - mmseg - INFO - Iter [2250/40000]	lr: 5.663e-05, eta: 2:55:12, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.4137, decode.acc_seg: 86.0231, loss: 0.4137
2022-11-29 18:33:04,498 - mmseg - INFO - Iter [2300/40000]	lr: 5.655e-05, eta: 2:54:44, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3655, decode.acc_seg: 86.1744, loss: 0.3655
2022-11-29 18:33:17,594 - mmseg - INFO - Iter [2350/40000]	lr: 5.648e-05, eta: 2:54:17, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.5358, decode.acc_seg: 83.5117, loss: 0.5358
2022-11-29 18:33:33,152 - mmseg - INFO - Iter [2400/40000]	lr: 5.640e-05, eta: 2:54:30, time: 0.311, data_time: 0.048, memory: 5529, decode.loss_ce: 0.3614, decode.acc_seg: 87.6363, loss: 0.3614
2022-11-29 18:33:47,925 - mmseg - INFO - Iter [2450/40000]	lr: 5.633e-05, eta: 2:54:29, time: 0.295, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3620, decode.acc_seg: 86.3504, loss: 0.3620
2022-11-29 18:34:01,212 - mmseg - INFO - Iter [2500/40000]	lr: 5.625e-05, eta: 2:54:05, time: 0.266, data_time: 0.007, memory: 5529, decode.loss_ce: 0.4281, decode.acc_seg: 86.0634, loss: 0.4281
2022-11-29 18:34:14,335 - mmseg - INFO - Iter [2550/40000]	lr: 5.618e-05, eta: 2:53:39, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3505, decode.acc_seg: 87.1473, loss: 0.3505
2022-11-29 18:34:30,285 - mmseg - INFO - Iter [2600/40000]	lr: 5.610e-05, eta: 2:53:55, time: 0.319, data_time: 0.048, memory: 5529, decode.loss_ce: 0.2923, decode.acc_seg: 91.3545, loss: 0.2923
2022-11-29 18:34:43,416 - mmseg - INFO - Iter [2650/40000]	lr: 5.603e-05, eta: 2:53:29, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.4720, decode.acc_seg: 82.7864, loss: 0.4720
2022-11-29 18:34:57,676 - mmseg - INFO - Iter [2700/40000]	lr: 5.595e-05, eta: 2:53:20, time: 0.285, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3985, decode.acc_seg: 87.1973, loss: 0.3985
2022-11-29 18:35:15,180 - mmseg - INFO - Iter [2750/40000]	lr: 5.588e-05, eta: 2:53:54, time: 0.350, data_time: 0.048, memory: 5529, decode.loss_ce: 0.3408, decode.acc_seg: 87.0615, loss: 0.3408
2022-11-29 18:35:28,649 - mmseg - INFO - Iter [2800/40000]	lr: 5.580e-05, eta: 2:53:33, time: 0.269, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3748, decode.acc_seg: 88.2196, loss: 0.3748
2022-11-29 18:35:41,909 - mmseg - INFO - Iter [2850/40000]	lr: 5.573e-05, eta: 2:53:09, time: 0.265, data_time: 0.007, memory: 5529, decode.loss_ce: 0.4549, decode.acc_seg: 87.0435, loss: 0.4549
2022-11-29 18:35:55,118 - mmseg - INFO - Iter [2900/40000]	lr: 5.565e-05, eta: 2:52:45, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2187, decode.acc_seg: 92.6304, loss: 0.2187
2022-11-29 18:36:10,449 - mmseg - INFO - Iter [2950/40000]	lr: 5.558e-05, eta: 2:52:49, time: 0.307, data_time: 0.048, memory: 5529, decode.loss_ce: 0.4480, decode.acc_seg: 86.1401, loss: 0.4480
2022-11-29 18:36:23,888 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 18:36:23,888 - mmseg - INFO - Iter [3000/40000]	lr: 5.550e-05, eta: 2:52:28, time: 0.269, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2716, decode.acc_seg: 89.3469, loss: 0.2716
2022-11-29 18:36:37,081 - mmseg - INFO - Iter [3050/40000]	lr: 5.543e-05, eta: 2:52:04, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3472, decode.acc_seg: 87.7440, loss: 0.3472
2022-11-29 18:36:50,209 - mmseg - INFO - Iter [3100/40000]	lr: 5.535e-05, eta: 2:51:40, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.4035, decode.acc_seg: 86.9089, loss: 0.4035
2022-11-29 18:37:05,408 - mmseg - INFO - Iter [3150/40000]	lr: 5.528e-05, eta: 2:51:41, time: 0.304, data_time: 0.048, memory: 5529, decode.loss_ce: 0.3950, decode.acc_seg: 89.3411, loss: 0.3950
2022-11-29 18:37:18,418 - mmseg - INFO - Iter [3200/40000]	lr: 5.520e-05, eta: 2:51:16, time: 0.260, data_time: 0.006, memory: 5529, decode.loss_ce: 0.2501, decode.acc_seg: 90.9069, loss: 0.2501
2022-11-29 18:37:31,601 - mmseg - INFO - Iter [3250/40000]	lr: 5.513e-05, eta: 2:50:53, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3480, decode.acc_seg: 89.9303, loss: 0.3480
2022-11-29 18:37:46,871 - mmseg - INFO - Iter [3300/40000]	lr: 5.505e-05, eta: 2:50:53, time: 0.305, data_time: 0.048, memory: 5529, decode.loss_ce: 0.3202, decode.acc_seg: 89.3554, loss: 0.3202
2022-11-29 18:38:00,268 - mmseg - INFO - Iter [3350/40000]	lr: 5.498e-05, eta: 2:50:33, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3374, decode.acc_seg: 88.7420, loss: 0.3374
2022-11-29 18:38:13,614 - mmseg - INFO - Iter [3400/40000]	lr: 5.490e-05, eta: 2:50:13, time: 0.267, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3463, decode.acc_seg: 88.3882, loss: 0.3463
2022-11-29 18:38:27,756 - mmseg - INFO - Iter [3450/40000]	lr: 5.483e-05, eta: 2:50:01, time: 0.283, data_time: 0.007, memory: 5529, decode.loss_ce: 0.4084, decode.acc_seg: 87.8569, loss: 0.4084
2022-11-29 18:38:45,808 - mmseg - INFO - Iter [3500/40000]	lr: 5.475e-05, eta: 2:50:29, time: 0.361, data_time: 0.048, memory: 5529, decode.loss_ce: 0.1935, decode.acc_seg: 93.5773, loss: 0.1935
2022-11-29 18:39:01,700 - mmseg - INFO - Iter [3550/40000]	lr: 5.468e-05, eta: 2:50:35, time: 0.318, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2620, decode.acc_seg: 90.2423, loss: 0.2620
2022-11-29 18:39:14,931 - mmseg - INFO - Iter [3600/40000]	lr: 5.460e-05, eta: 2:50:12, time: 0.265, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2935, decode.acc_seg: 90.4897, loss: 0.2935
2022-11-29 18:39:28,098 - mmseg - INFO - Iter [3650/40000]	lr: 5.453e-05, eta: 2:49:50, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3170, decode.acc_seg: 89.3724, loss: 0.3170
2022-11-29 18:39:43,442 - mmseg - INFO - Iter [3700/40000]	lr: 5.445e-05, eta: 2:49:49, time: 0.307, data_time: 0.048, memory: 5529, decode.loss_ce: 0.2897, decode.acc_seg: 90.9689, loss: 0.2897
2022-11-29 18:39:56,559 - mmseg - INFO - Iter [3750/40000]	lr: 5.438e-05, eta: 2:49:26, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1993, decode.acc_seg: 92.1710, loss: 0.1993
2022-11-29 18:40:09,695 - mmseg - INFO - Iter [3800/40000]	lr: 5.430e-05, eta: 2:49:03, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3331, decode.acc_seg: 88.3289, loss: 0.3331
2022-11-29 18:40:25,061 - mmseg - INFO - Iter [3850/40000]	lr: 5.423e-05, eta: 2:49:02, time: 0.307, data_time: 0.049, memory: 5529, decode.loss_ce: 0.2149, decode.acc_seg: 92.8985, loss: 0.2149
2022-11-29 18:40:38,229 - mmseg - INFO - Iter [3900/40000]	lr: 5.415e-05, eta: 2:48:40, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3063, decode.acc_seg: 90.6676, loss: 0.3063
2022-11-29 18:40:51,483 - mmseg - INFO - Iter [3950/40000]	lr: 5.408e-05, eta: 2:48:19, time: 0.265, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2732, decode.acc_seg: 90.6153, loss: 0.2732
2022-11-29 18:41:06,819 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 18:41:06,819 - mmseg - INFO - Iter [4000/40000]	lr: 5.400e-05, eta: 2:48:17, time: 0.307, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2146, decode.acc_seg: 93.4258, loss: 0.2146
2022-11-29 18:41:21,921 - mmseg - INFO - Iter [4050/40000]	lr: 5.393e-05, eta: 2:48:13, time: 0.302, data_time: 0.047, memory: 5529, decode.loss_ce: 0.2899, decode.acc_seg: 90.4366, loss: 0.2899
2022-11-29 18:41:34,543 - mmseg - INFO - Iter [4100/40000]	lr: 5.385e-05, eta: 2:47:46, time: 0.252, data_time: 0.006, memory: 5529, decode.loss_ce: 0.2199, decode.acc_seg: 92.0771, loss: 0.2199
2022-11-29 18:41:47,227 - mmseg - INFO - Iter [4150/40000]	lr: 5.378e-05, eta: 2:47:21, time: 0.254, data_time: 0.006, memory: 5529, decode.loss_ce: 0.2284, decode.acc_seg: 91.9007, loss: 0.2284
2022-11-29 18:42:00,096 - mmseg - INFO - Iter [4200/40000]	lr: 5.370e-05, eta: 2:46:57, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.2311, decode.acc_seg: 91.9203, loss: 0.2311
2022-11-29 18:42:14,771 - mmseg - INFO - Iter [4250/40000]	lr: 5.363e-05, eta: 2:46:49, time: 0.293, data_time: 0.047, memory: 5529, decode.loss_ce: 0.1721, decode.acc_seg: 94.0233, loss: 0.1721
2022-11-29 18:42:27,338 - mmseg - INFO - Iter [4300/40000]	lr: 5.355e-05, eta: 2:46:23, time: 0.251, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1833, decode.acc_seg: 93.2071, loss: 0.1833
2022-11-29 18:42:40,039 - mmseg - INFO - Iter [4350/40000]	lr: 5.348e-05, eta: 2:45:58, time: 0.254, data_time: 0.006, memory: 5529, decode.loss_ce: 0.2592, decode.acc_seg: 92.7545, loss: 0.2592
2022-11-29 18:42:55,338 - mmseg - INFO - Iter [4400/40000]	lr: 5.340e-05, eta: 2:45:55, time: 0.306, data_time: 0.048, memory: 5529, decode.loss_ce: 0.1483, decode.acc_seg: 94.0710, loss: 0.1483
2022-11-29 18:43:08,473 - mmseg - INFO - Iter [4450/40000]	lr: 5.333e-05, eta: 2:45:34, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2155, decode.acc_seg: 93.6351, loss: 0.2155
2022-11-29 18:43:21,668 - mmseg - INFO - Iter [4500/40000]	lr: 5.325e-05, eta: 2:45:14, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.4406, decode.acc_seg: 88.5481, loss: 0.4406
2022-11-29 18:43:34,912 - mmseg - INFO - Iter [4550/40000]	lr: 5.318e-05, eta: 2:44:55, time: 0.265, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3172, decode.acc_seg: 91.5292, loss: 0.3172
2022-11-29 18:43:50,115 - mmseg - INFO - Iter [4600/40000]	lr: 5.310e-05, eta: 2:44:50, time: 0.304, data_time: 0.048, memory: 5529, decode.loss_ce: 0.1310, decode.acc_seg: 95.6058, loss: 0.1310
2022-11-29 18:44:03,226 - mmseg - INFO - Iter [4650/40000]	lr: 5.303e-05, eta: 2:44:30, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3400, decode.acc_seg: 89.4460, loss: 0.3400
2022-11-29 18:44:16,371 - mmseg - INFO - Iter [4700/40000]	lr: 5.295e-05, eta: 2:44:10, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1518, decode.acc_seg: 94.7200, loss: 0.1518
2022-11-29 18:44:29,509 - mmseg - INFO - Iter [4750/40000]	lr: 5.288e-05, eta: 2:43:50, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1457, decode.acc_seg: 94.3931, loss: 0.1457
2022-11-29 18:44:44,917 - mmseg - INFO - Iter [4800/40000]	lr: 5.280e-05, eta: 2:43:47, time: 0.308, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0952, decode.acc_seg: 96.6378, loss: 0.0952
2022-11-29 18:44:58,043 - mmseg - INFO - Iter [4850/40000]	lr: 5.273e-05, eta: 2:43:27, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2168, decode.acc_seg: 93.1717, loss: 0.2168
2022-11-29 18:45:11,224 - mmseg - INFO - Iter [4900/40000]	lr: 5.265e-05, eta: 2:43:07, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.4457, decode.acc_seg: 88.6155, loss: 0.4457
2022-11-29 18:45:26,427 - mmseg - INFO - Iter [4950/40000]	lr: 5.258e-05, eta: 2:43:02, time: 0.304, data_time: 0.049, memory: 5529, decode.loss_ce: 0.2900, decode.acc_seg: 91.6822, loss: 0.2900
2022-11-29 18:45:39,558 - mmseg - INFO - Saving checkpoint at 5000 iterations
2022-11-29 18:45:42,140 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 18:45:42,140 - mmseg - INFO - Iter [5000/40000]	lr: 5.250e-05, eta: 2:43:00, time: 0.314, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1837, decode.acc_seg: 93.5034, loss: 0.1837
2022-11-29 18:46:37,982 - mmseg - INFO - per class results:
2022-11-29 18:46:37,984 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  90.0 | 95.63 |
|  aeroplane  | 68.52 |  90.0 |
|   bicycle   | 22.13 | 24.04 |
|     bird    | 69.56 | 85.33 |
|     boat    | 37.61 | 71.37 |
|    bottle   | 58.96 | 66.02 |
|     bus     | 73.24 | 88.01 |
|     car     | 72.29 | 83.86 |
|     cat     | 78.93 | 91.65 |
|    chair    | 11.21 |  13.9 |
|     cow     | 47.37 | 74.49 |
| diningtable | 27.51 | 29.28 |
|     dog     | 73.89 | 88.67 |
|    horse    | 44.31 | 46.87 |
|  motorbike  | 61.53 | 78.16 |
|    person   | 74.98 | 90.45 |
| pottedplant | 29.01 | 32.87 |
|    sheep    | 65.43 | 76.89 |
|     sofa    | 36.06 | 42.73 |
|    train    | 66.69 | 74.04 |
|  tvmonitor  | 35.19 | 67.17 |
+-------------+-------+-------+
2022-11-29 18:46:37,984 - mmseg - INFO - Summary:
2022-11-29 18:46:37,984 - mmseg - INFO - 
+------+------+-------+
| aAcc | mIoU |  mAcc |
+------+------+-------+
| 89.6 | 54.5 | 67.21 |
+------+------+-------+
2022-11-29 18:46:37,987 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 18:46:37,987 - mmseg - INFO - Iter(val) [724]	aAcc: 0.8960, mIoU: 0.5450, mAcc: 0.6721, IoU.background: 0.9000, IoU.aeroplane: 0.6852, IoU.bicycle: 0.2213, IoU.bird: 0.6956, IoU.boat: 0.3761, IoU.bottle: 0.5896, IoU.bus: 0.7324, IoU.car: 0.7229, IoU.cat: 0.7893, IoU.chair: 0.1121, IoU.cow: 0.4737, IoU.diningtable: 0.2751, IoU.dog: 0.7389, IoU.horse: 0.4431, IoU.motorbike: 0.6153, IoU.person: 0.7498, IoU.pottedplant: 0.2901, IoU.sheep: 0.6543, IoU.sofa: 0.3606, IoU.train: 0.6669, IoU.tvmonitor: 0.3519, Acc.background: 0.9563, Acc.aeroplane: 0.9000, Acc.bicycle: 0.2404, Acc.bird: 0.8533, Acc.boat: 0.7137, Acc.bottle: 0.6602, Acc.bus: 0.8801, Acc.car: 0.8386, Acc.cat: 0.9165, Acc.chair: 0.1390, Acc.cow: 0.7449, Acc.diningtable: 0.2928, Acc.dog: 0.8867, Acc.horse: 0.4687, Acc.motorbike: 0.7816, Acc.person: 0.9045, Acc.pottedplant: 0.3287, Acc.sheep: 0.7689, Acc.sofa: 0.4273, Acc.train: 0.7404, Acc.tvmonitor: 0.6717
2022-11-29 18:46:51,254 - mmseg - INFO - Iter [5050/40000]	lr: 5.243e-05, eta: 2:49:08, time: 1.382, data_time: 1.124, memory: 5529, decode.loss_ce: 0.2382, decode.acc_seg: 91.7371, loss: 0.2382
2022-11-29 18:47:04,340 - mmseg - INFO - Iter [5100/40000]	lr: 5.235e-05, eta: 2:48:44, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1825, decode.acc_seg: 93.8715, loss: 0.1825
2022-11-29 18:47:19,757 - mmseg - INFO - Iter [5150/40000]	lr: 5.228e-05, eta: 2:48:35, time: 0.308, data_time: 0.048, memory: 5529, decode.loss_ce: 0.2080, decode.acc_seg: 92.9971, loss: 0.2080
2022-11-29 18:47:32,863 - mmseg - INFO - Iter [5200/40000]	lr: 5.220e-05, eta: 2:48:11, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1115, decode.acc_seg: 95.9305, loss: 0.1115
2022-11-29 18:47:45,602 - mmseg - INFO - Iter [5250/40000]	lr: 5.213e-05, eta: 2:47:45, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1191, decode.acc_seg: 95.4356, loss: 0.1191
2022-11-29 18:47:58,581 - mmseg - INFO - Iter [5300/40000]	lr: 5.205e-05, eta: 2:47:21, time: 0.260, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1545, decode.acc_seg: 94.9155, loss: 0.1545
2022-11-29 18:48:13,618 - mmseg - INFO - Iter [5350/40000]	lr: 5.198e-05, eta: 2:47:10, time: 0.301, data_time: 0.047, memory: 5529, decode.loss_ce: 0.1660, decode.acc_seg: 95.0169, loss: 0.1660
2022-11-29 18:48:26,558 - mmseg - INFO - Iter [5400/40000]	lr: 5.190e-05, eta: 2:46:46, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1317, decode.acc_seg: 95.0128, loss: 0.1317
2022-11-29 18:48:39,593 - mmseg - INFO - Iter [5450/40000]	lr: 5.183e-05, eta: 2:46:22, time: 0.261, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1571, decode.acc_seg: 94.2930, loss: 0.1571
2022-11-29 18:48:56,985 - mmseg - INFO - Iter [5500/40000]	lr: 5.175e-05, eta: 2:46:26, time: 0.348, data_time: 0.048, memory: 5529, decode.loss_ce: 0.1080, decode.acc_seg: 96.1838, loss: 0.1080
2022-11-29 18:49:10,409 - mmseg - INFO - Iter [5550/40000]	lr: 5.168e-05, eta: 2:46:05, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1574, decode.acc_seg: 94.4841, loss: 0.1574
2022-11-29 18:49:23,578 - mmseg - INFO - Iter [5600/40000]	lr: 5.160e-05, eta: 2:45:43, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1130, decode.acc_seg: 95.9771, loss: 0.1130
2022-11-29 18:49:37,752 - mmseg - INFO - Iter [5650/40000]	lr: 5.153e-05, eta: 2:45:27, time: 0.283, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1202, decode.acc_seg: 95.5457, loss: 0.1202
2022-11-29 18:49:54,251 - mmseg - INFO - Iter [5700/40000]	lr: 5.145e-05, eta: 2:45:25, time: 0.330, data_time: 0.048, memory: 5529, decode.loss_ce: 0.1142, decode.acc_seg: 95.6146, loss: 0.1142
2022-11-29 18:50:07,403 - mmseg - INFO - Iter [5750/40000]	lr: 5.138e-05, eta: 2:45:02, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1880, decode.acc_seg: 93.0041, loss: 0.1880
2022-11-29 18:50:20,560 - mmseg - INFO - Iter [5800/40000]	lr: 5.130e-05, eta: 2:44:40, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1233, decode.acc_seg: 96.0319, loss: 0.1233
2022-11-29 18:50:33,935 - mmseg - INFO - Iter [5850/40000]	lr: 5.123e-05, eta: 2:44:19, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2813, decode.acc_seg: 90.8033, loss: 0.2813
2022-11-29 18:50:50,090 - mmseg - INFO - Iter [5900/40000]	lr: 5.115e-05, eta: 2:44:15, time: 0.323, data_time: 0.048, memory: 5529, decode.loss_ce: 0.1863, decode.acc_seg: 92.4912, loss: 0.1863
2022-11-29 18:51:04,159 - mmseg - INFO - Iter [5950/40000]	lr: 5.108e-05, eta: 2:43:58, time: 0.281, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3006, decode.acc_seg: 90.0765, loss: 0.3006
2022-11-29 18:51:17,552 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 18:51:17,552 - mmseg - INFO - Iter [6000/40000]	lr: 5.100e-05, eta: 2:43:38, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2133, decode.acc_seg: 93.3816, loss: 0.2133
2022-11-29 18:51:32,913 - mmseg - INFO - Iter [6050/40000]	lr: 5.093e-05, eta: 2:43:29, time: 0.307, data_time: 0.048, memory: 5529, decode.loss_ce: 0.2462, decode.acc_seg: 90.9847, loss: 0.2462
2022-11-29 18:51:46,827 - mmseg - INFO - Iter [6100/40000]	lr: 5.085e-05, eta: 2:43:11, time: 0.278, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1486, decode.acc_seg: 94.9840, loss: 0.1486
2022-11-29 18:52:01,513 - mmseg - INFO - Iter [6150/40000]	lr: 5.078e-05, eta: 2:42:58, time: 0.294, data_time: 0.007, memory: 5529, decode.loss_ce: 0.4283, decode.acc_seg: 90.7246, loss: 0.4283
2022-11-29 18:52:14,877 - mmseg - INFO - Iter [6200/40000]	lr: 5.070e-05, eta: 2:42:38, time: 0.267, data_time: 0.007, memory: 5529, decode.loss_ce: 0.3619, decode.acc_seg: 89.2241, loss: 0.3619
2022-11-29 18:52:30,704 - mmseg - INFO - Iter [6250/40000]	lr: 5.063e-05, eta: 2:42:31, time: 0.317, data_time: 0.049, memory: 5529, decode.loss_ce: 0.1280, decode.acc_seg: 95.2053, loss: 0.1280
2022-11-29 18:52:44,831 - mmseg - INFO - Iter [6300/40000]	lr: 5.055e-05, eta: 2:42:15, time: 0.282, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1279, decode.acc_seg: 95.7302, loss: 0.1279
2022-11-29 18:53:00,794 - mmseg - INFO - Iter [6350/40000]	lr: 5.048e-05, eta: 2:42:08, time: 0.319, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1965, decode.acc_seg: 93.9562, loss: 0.1965
2022-11-29 18:53:14,823 - mmseg - INFO - Iter [6400/40000]	lr: 5.040e-05, eta: 2:41:52, time: 0.281, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0980, decode.acc_seg: 96.4375, loss: 0.0980
2022-11-29 18:53:30,258 - mmseg - INFO - Iter [6450/40000]	lr: 5.033e-05, eta: 2:41:42, time: 0.309, data_time: 0.049, memory: 5529, decode.loss_ce: 0.1732, decode.acc_seg: 93.6289, loss: 0.1732
2022-11-29 18:53:42,897 - mmseg - INFO - Iter [6500/40000]	lr: 5.025e-05, eta: 2:41:18, time: 0.253, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1772, decode.acc_seg: 94.8237, loss: 0.1772
2022-11-29 18:53:55,449 - mmseg - INFO - Iter [6550/40000]	lr: 5.018e-05, eta: 2:40:54, time: 0.251, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1247, decode.acc_seg: 95.9373, loss: 0.1247
2022-11-29 18:54:10,210 - mmseg - INFO - Iter [6600/40000]	lr: 5.010e-05, eta: 2:40:41, time: 0.295, data_time: 0.047, memory: 5529, decode.loss_ce: 0.1148, decode.acc_seg: 95.6840, loss: 0.1148
2022-11-29 18:54:22,659 - mmseg - INFO - Iter [6650/40000]	lr: 5.003e-05, eta: 2:40:17, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0909, decode.acc_seg: 96.5179, loss: 0.0909
2022-11-29 18:54:35,054 - mmseg - INFO - Iter [6700/40000]	lr: 4.995e-05, eta: 2:39:53, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.1189, decode.acc_seg: 95.7629, loss: 0.1189
2022-11-29 18:54:47,514 - mmseg - INFO - Iter [6750/40000]	lr: 4.988e-05, eta: 2:39:29, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.1399, decode.acc_seg: 94.7649, loss: 0.1399
2022-11-29 18:55:02,464 - mmseg - INFO - Iter [6800/40000]	lr: 4.980e-05, eta: 2:39:17, time: 0.299, data_time: 0.047, memory: 5529, decode.loss_ce: 0.2102, decode.acc_seg: 93.2494, loss: 0.2102
2022-11-29 18:55:15,348 - mmseg - INFO - Iter [6850/40000]	lr: 4.973e-05, eta: 2:38:55, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1445, decode.acc_seg: 95.3651, loss: 0.1445
2022-11-29 18:55:28,413 - mmseg - INFO - Iter [6900/40000]	lr: 4.965e-05, eta: 2:38:35, time: 0.261, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1346, decode.acc_seg: 95.3927, loss: 0.1346
2022-11-29 18:55:41,319 - mmseg - INFO - Iter [6950/40000]	lr: 4.958e-05, eta: 2:38:13, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1242, decode.acc_seg: 95.7197, loss: 0.1242
2022-11-29 18:55:57,676 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 18:55:57,676 - mmseg - INFO - Iter [7000/40000]	lr: 4.950e-05, eta: 2:38:08, time: 0.327, data_time: 0.049, memory: 5529, decode.loss_ce: 0.1577, decode.acc_seg: 94.6278, loss: 0.1577
2022-11-29 18:56:12,624 - mmseg - INFO - Iter [7050/40000]	lr: 4.943e-05, eta: 2:37:57, time: 0.299, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1271, decode.acc_seg: 95.5655, loss: 0.1271
2022-11-29 18:56:25,510 - mmseg - INFO - Iter [7100/40000]	lr: 4.935e-05, eta: 2:37:35, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1378, decode.acc_seg: 94.2390, loss: 0.1378
2022-11-29 18:56:40,555 - mmseg - INFO - Iter [7150/40000]	lr: 4.928e-05, eta: 2:37:24, time: 0.301, data_time: 0.049, memory: 5529, decode.loss_ce: 0.1111, decode.acc_seg: 96.2259, loss: 0.1111
2022-11-29 18:56:53,405 - mmseg - INFO - Iter [7200/40000]	lr: 4.920e-05, eta: 2:37:03, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1694, decode.acc_seg: 94.3558, loss: 0.1694
2022-11-29 18:57:06,252 - mmseg - INFO - Iter [7250/40000]	lr: 4.913e-05, eta: 2:36:41, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1574, decode.acc_seg: 95.3276, loss: 0.1574
2022-11-29 18:57:19,159 - mmseg - INFO - Iter [7300/40000]	lr: 4.905e-05, eta: 2:36:21, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1423, decode.acc_seg: 95.5632, loss: 0.1423
2022-11-29 18:57:34,096 - mmseg - INFO - Iter [7350/40000]	lr: 4.898e-05, eta: 2:36:09, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0937, decode.acc_seg: 96.7856, loss: 0.0937
2022-11-29 18:57:46,931 - mmseg - INFO - Iter [7400/40000]	lr: 4.890e-05, eta: 2:35:48, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1624, decode.acc_seg: 94.5684, loss: 0.1624
2022-11-29 18:58:00,500 - mmseg - INFO - Iter [7450/40000]	lr: 4.883e-05, eta: 2:35:30, time: 0.271, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1996, decode.acc_seg: 92.5352, loss: 0.1996
2022-11-29 18:58:14,743 - mmseg - INFO - Iter [7500/40000]	lr: 4.875e-05, eta: 2:35:15, time: 0.285, data_time: 0.007, memory: 5529, decode.loss_ce: 0.2005, decode.acc_seg: 94.3936, loss: 0.2005
2022-11-29 18:58:29,958 - mmseg - INFO - Iter [7550/40000]	lr: 4.868e-05, eta: 2:35:05, time: 0.304, data_time: 0.048, memory: 5529, decode.loss_ce: 0.1073, decode.acc_seg: 96.4688, loss: 0.1073
2022-11-29 18:58:42,822 - mmseg - INFO - Iter [7600/40000]	lr: 4.860e-05, eta: 2:34:44, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1481, decode.acc_seg: 94.8590, loss: 0.1481
2022-11-29 18:58:55,649 - mmseg - INFO - Iter [7650/40000]	lr: 4.853e-05, eta: 2:34:24, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0978, decode.acc_seg: 96.9278, loss: 0.0978
2022-11-29 18:59:11,121 - mmseg - INFO - Iter [7700/40000]	lr: 4.845e-05, eta: 2:34:14, time: 0.309, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0957, decode.acc_seg: 96.5456, loss: 0.0957
2022-11-29 18:59:23,997 - mmseg - INFO - Iter [7750/40000]	lr: 4.838e-05, eta: 2:33:54, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0761, decode.acc_seg: 97.0764, loss: 0.0761
2022-11-29 18:59:36,865 - mmseg - INFO - Iter [7800/40000]	lr: 4.830e-05, eta: 2:33:33, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0807, decode.acc_seg: 97.3491, loss: 0.0807
2022-11-29 18:59:49,526 - mmseg - INFO - Iter [7850/40000]	lr: 4.823e-05, eta: 2:33:12, time: 0.253, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1107, decode.acc_seg: 95.4764, loss: 0.1107
2022-11-29 19:00:05,193 - mmseg - INFO - Iter [7900/40000]	lr: 4.815e-05, eta: 2:33:04, time: 0.313, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0786, decode.acc_seg: 97.0669, loss: 0.0786
2022-11-29 19:00:18,170 - mmseg - INFO - Iter [7950/40000]	lr: 4.808e-05, eta: 2:32:44, time: 0.260, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0646, decode.acc_seg: 97.4588, loss: 0.0646
2022-11-29 19:00:32,424 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:00:32,424 - mmseg - INFO - Iter [8000/40000]	lr: 4.800e-05, eta: 2:32:30, time: 0.285, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0643, decode.acc_seg: 97.5263, loss: 0.0643
2022-11-29 19:00:45,263 - mmseg - INFO - Iter [8050/40000]	lr: 4.793e-05, eta: 2:32:09, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0506, decode.acc_seg: 97.9604, loss: 0.0506
2022-11-29 19:01:00,271 - mmseg - INFO - Iter [8100/40000]	lr: 4.785e-05, eta: 2:31:58, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0743, decode.acc_seg: 97.3257, loss: 0.0743
2022-11-29 19:01:13,134 - mmseg - INFO - Iter [8150/40000]	lr: 4.778e-05, eta: 2:31:38, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1200, decode.acc_seg: 95.9323, loss: 0.1200
2022-11-29 19:01:26,040 - mmseg - INFO - Iter [8200/40000]	lr: 4.770e-05, eta: 2:31:18, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0875, decode.acc_seg: 96.9720, loss: 0.0875
2022-11-29 19:01:41,111 - mmseg - INFO - Iter [8250/40000]	lr: 4.763e-05, eta: 2:31:07, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0828, decode.acc_seg: 96.8756, loss: 0.0828
2022-11-29 19:01:54,208 - mmseg - INFO - Iter [8300/40000]	lr: 4.755e-05, eta: 2:30:48, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0574, decode.acc_seg: 97.6580, loss: 0.0574
2022-11-29 19:02:07,365 - mmseg - INFO - Iter [8350/40000]	lr: 4.748e-05, eta: 2:30:30, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1556, decode.acc_seg: 95.0769, loss: 0.1556
2022-11-29 19:02:20,419 - mmseg - INFO - Iter [8400/40000]	lr: 4.740e-05, eta: 2:30:11, time: 0.261, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1397, decode.acc_seg: 96.3210, loss: 0.1397
2022-11-29 19:02:36,280 - mmseg - INFO - Iter [8450/40000]	lr: 4.733e-05, eta: 2:30:03, time: 0.317, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0522, decode.acc_seg: 98.1192, loss: 0.0522
2022-11-29 19:02:49,130 - mmseg - INFO - Iter [8500/40000]	lr: 4.725e-05, eta: 2:29:43, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0710, decode.acc_seg: 97.5691, loss: 0.0710
2022-11-29 19:03:02,033 - mmseg - INFO - Iter [8550/40000]	lr: 4.718e-05, eta: 2:29:24, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0654, decode.acc_seg: 97.3831, loss: 0.0654
2022-11-29 19:03:14,874 - mmseg - INFO - Iter [8600/40000]	lr: 4.710e-05, eta: 2:29:05, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0542, decode.acc_seg: 97.8337, loss: 0.0542
2022-11-29 19:03:29,843 - mmseg - INFO - Iter [8650/40000]	lr: 4.703e-05, eta: 2:28:53, time: 0.299, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0938, decode.acc_seg: 96.8185, loss: 0.0938
2022-11-29 19:03:42,683 - mmseg - INFO - Iter [8700/40000]	lr: 4.695e-05, eta: 2:28:34, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0966, decode.acc_seg: 96.5254, loss: 0.0966
2022-11-29 19:03:55,594 - mmseg - INFO - Iter [8750/40000]	lr: 4.688e-05, eta: 2:28:15, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0894, decode.acc_seg: 97.0428, loss: 0.0894
2022-11-29 19:04:10,518 - mmseg - INFO - Iter [8800/40000]	lr: 4.680e-05, eta: 2:28:03, time: 0.298, data_time: 0.048, memory: 5529, decode.loss_ce: 0.2429, decode.acc_seg: 94.3442, loss: 0.2429
2022-11-29 19:04:23,355 - mmseg - INFO - Iter [8850/40000]	lr: 4.673e-05, eta: 2:27:44, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1123, decode.acc_seg: 96.2283, loss: 0.1123
2022-11-29 19:04:36,313 - mmseg - INFO - Iter [8900/40000]	lr: 4.665e-05, eta: 2:27:25, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1519, decode.acc_seg: 94.8660, loss: 0.1519
2022-11-29 19:04:49,141 - mmseg - INFO - Iter [8950/40000]	lr: 4.658e-05, eta: 2:27:06, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1131, decode.acc_seg: 95.8285, loss: 0.1131
2022-11-29 19:05:04,118 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:05:04,118 - mmseg - INFO - Iter [9000/40000]	lr: 4.650e-05, eta: 2:26:54, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0937, decode.acc_seg: 96.5074, loss: 0.0937
2022-11-29 19:05:16,975 - mmseg - INFO - Iter [9050/40000]	lr: 4.643e-05, eta: 2:26:36, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0643, decode.acc_seg: 97.4118, loss: 0.0643
2022-11-29 19:05:29,784 - mmseg - INFO - Iter [9100/40000]	lr: 4.635e-05, eta: 2:26:17, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0760, decode.acc_seg: 97.2317, loss: 0.0760
2022-11-29 19:05:42,196 - mmseg - INFO - Iter [9150/40000]	lr: 4.628e-05, eta: 2:25:56, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0625, decode.acc_seg: 97.6295, loss: 0.0625
2022-11-29 19:05:58,350 - mmseg - INFO - Iter [9200/40000]	lr: 4.620e-05, eta: 2:25:49, time: 0.323, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0857, decode.acc_seg: 97.2552, loss: 0.0857
2022-11-29 19:06:10,882 - mmseg - INFO - Iter [9250/40000]	lr: 4.613e-05, eta: 2:25:29, time: 0.251, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0668, decode.acc_seg: 97.3752, loss: 0.0668
2022-11-29 19:06:23,290 - mmseg - INFO - Iter [9300/40000]	lr: 4.605e-05, eta: 2:25:09, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.1041, decode.acc_seg: 95.8186, loss: 0.1041
2022-11-29 19:06:37,902 - mmseg - INFO - Iter [9350/40000]	lr: 4.598e-05, eta: 2:24:56, time: 0.292, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0832, decode.acc_seg: 97.0238, loss: 0.0832
2022-11-29 19:06:50,466 - mmseg - INFO - Iter [9400/40000]	lr: 4.590e-05, eta: 2:24:37, time: 0.251, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0951, decode.acc_seg: 96.9963, loss: 0.0951
2022-11-29 19:07:02,917 - mmseg - INFO - Iter [9450/40000]	lr: 4.583e-05, eta: 2:24:17, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.2011, decode.acc_seg: 94.6269, loss: 0.2011
2022-11-29 19:07:15,977 - mmseg - INFO - Iter [9500/40000]	lr: 4.575e-05, eta: 2:23:59, time: 0.261, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0840, decode.acc_seg: 96.9565, loss: 0.0840
2022-11-29 19:07:33,029 - mmseg - INFO - Iter [9550/40000]	lr: 4.568e-05, eta: 2:23:54, time: 0.341, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0625, decode.acc_seg: 97.7239, loss: 0.0625
2022-11-29 19:07:46,197 - mmseg - INFO - Iter [9600/40000]	lr: 4.560e-05, eta: 2:23:37, time: 0.263, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0840, decode.acc_seg: 97.2946, loss: 0.0840
2022-11-29 19:07:58,643 - mmseg - INFO - Iter [9650/40000]	lr: 4.553e-05, eta: 2:23:17, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0760, decode.acc_seg: 97.1872, loss: 0.0760
2022-11-29 19:08:13,312 - mmseg - INFO - Iter [9700/40000]	lr: 4.545e-05, eta: 2:23:05, time: 0.293, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0641, decode.acc_seg: 97.7223, loss: 0.0641
2022-11-29 19:08:25,841 - mmseg - INFO - Iter [9750/40000]	lr: 4.538e-05, eta: 2:22:45, time: 0.251, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0597, decode.acc_seg: 98.0026, loss: 0.0597
2022-11-29 19:08:38,334 - mmseg - INFO - Iter [9800/40000]	lr: 4.530e-05, eta: 2:22:26, time: 0.250, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0876, decode.acc_seg: 97.0981, loss: 0.0876
2022-11-29 19:08:50,733 - mmseg - INFO - Iter [9850/40000]	lr: 4.523e-05, eta: 2:22:07, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.2022, decode.acc_seg: 95.6488, loss: 0.2022
2022-11-29 19:09:05,483 - mmseg - INFO - Iter [9900/40000]	lr: 4.515e-05, eta: 2:21:54, time: 0.295, data_time: 0.047, memory: 5529, decode.loss_ce: 0.2423, decode.acc_seg: 91.9551, loss: 0.2423
2022-11-29 19:09:18,455 - mmseg - INFO - Iter [9950/40000]	lr: 4.508e-05, eta: 2:21:37, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1943, decode.acc_seg: 93.0756, loss: 0.1943
2022-11-29 19:09:31,333 - mmseg - INFO - Saving checkpoint at 10000 iterations
2022-11-29 19:09:33,138 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:09:33,138 - mmseg - INFO - Iter [10000/40000]	lr: 4.500e-05, eta: 2:21:24, time: 0.294, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1614, decode.acc_seg: 95.4826, loss: 0.1614
2022-11-29 19:10:15,214 - mmseg - INFO - per class results:
2022-11-29 19:10:15,215 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 89.51 | 94.96 |
|  aeroplane  | 57.63 | 91.77 |
|   bicycle   | 49.62 | 55.62 |
|     bird    | 48.66 | 93.74 |
|     boat    | 40.51 |  74.2 |
|    bottle   | 56.21 | 64.44 |
|     bus     |  71.3 | 87.17 |
|     car     |  77.1 | 88.21 |
|     cat     |  65.5 | 71.49 |
|    chair    |  1.65 |  2.05 |
|     cow     | 55.37 |  68.5 |
| diningtable | 35.24 | 39.37 |
|     dog     | 57.12 | 89.45 |
|    horse    | 56.85 | 72.42 |
|  motorbike  | 67.64 | 76.92 |
|    person   | 75.32 | 88.74 |
| pottedplant | 38.69 | 46.37 |
|    sheep    | 63.65 | 70.78 |
|     sofa    | 25.58 | 28.21 |
|    train    | 75.16 |  80.1 |
|  tvmonitor  |  40.8 | 69.78 |
+-------------+-------+-------+
2022-11-29 19:10:15,215 - mmseg - INFO - Summary:
2022-11-29 19:10:15,215 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 89.04 | 54.72 | 69.25 |
+-------+-------+-------+
2022-11-29 19:10:15,216 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:10:15,217 - mmseg - INFO - Iter(val) [724]	aAcc: 0.8904, mIoU: 0.5472, mAcc: 0.6925, IoU.background: 0.8951, IoU.aeroplane: 0.5763, IoU.bicycle: 0.4962, IoU.bird: 0.4866, IoU.boat: 0.4051, IoU.bottle: 0.5621, IoU.bus: 0.7130, IoU.car: 0.7710, IoU.cat: 0.6550, IoU.chair: 0.0165, IoU.cow: 0.5537, IoU.diningtable: 0.3524, IoU.dog: 0.5712, IoU.horse: 0.5685, IoU.motorbike: 0.6764, IoU.person: 0.7532, IoU.pottedplant: 0.3869, IoU.sheep: 0.6365, IoU.sofa: 0.2558, IoU.train: 0.7516, IoU.tvmonitor: 0.4080, Acc.background: 0.9496, Acc.aeroplane: 0.9177, Acc.bicycle: 0.5562, Acc.bird: 0.9374, Acc.boat: 0.7420, Acc.bottle: 0.6444, Acc.bus: 0.8717, Acc.car: 0.8821, Acc.cat: 0.7149, Acc.chair: 0.0205, Acc.cow: 0.6850, Acc.diningtable: 0.3937, Acc.dog: 0.8945, Acc.horse: 0.7242, Acc.motorbike: 0.7692, Acc.person: 0.8874, Acc.pottedplant: 0.4637, Acc.sheep: 0.7078, Acc.sofa: 0.2821, Acc.train: 0.8010, Acc.tvmonitor: 0.6978
2022-11-29 19:10:28,650 - mmseg - INFO - Iter [10050/40000]	lr: 4.493e-05, eta: 2:23:13, time: 1.110, data_time: 0.848, memory: 5529, decode.loss_ce: 0.1215, decode.acc_seg: 96.3188, loss: 0.1215
2022-11-29 19:10:44,220 - mmseg - INFO - Iter [10100/40000]	lr: 4.485e-05, eta: 2:23:03, time: 0.311, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0825, decode.acc_seg: 97.2478, loss: 0.0825
2022-11-29 19:10:57,419 - mmseg - INFO - Iter [10150/40000]	lr: 4.478e-05, eta: 2:22:45, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1300, decode.acc_seg: 94.9058, loss: 0.1300
2022-11-29 19:11:10,317 - mmseg - INFO - Iter [10200/40000]	lr: 4.470e-05, eta: 2:22:26, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1043, decode.acc_seg: 95.9713, loss: 0.1043
2022-11-29 19:11:25,389 - mmseg - INFO - Iter [10250/40000]	lr: 4.463e-05, eta: 2:22:14, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0530, decode.acc_seg: 98.0956, loss: 0.0530
2022-11-29 19:11:38,377 - mmseg - INFO - Iter [10300/40000]	lr: 4.455e-05, eta: 2:21:56, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0725, decode.acc_seg: 97.2052, loss: 0.0725
2022-11-29 19:11:51,227 - mmseg - INFO - Iter [10350/40000]	lr: 4.448e-05, eta: 2:21:37, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1020, decode.acc_seg: 96.7492, loss: 0.1020
2022-11-29 19:12:04,117 - mmseg - INFO - Iter [10400/40000]	lr: 4.440e-05, eta: 2:21:19, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0754, decode.acc_seg: 96.9234, loss: 0.0754
2022-11-29 19:12:19,116 - mmseg - INFO - Iter [10450/40000]	lr: 4.433e-05, eta: 2:21:06, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0716, decode.acc_seg: 97.4966, loss: 0.0716
2022-11-29 19:12:31,978 - mmseg - INFO - Iter [10500/40000]	lr: 4.425e-05, eta: 2:20:48, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0473, decode.acc_seg: 98.1990, loss: 0.0473
2022-11-29 19:12:44,821 - mmseg - INFO - Iter [10550/40000]	lr: 4.418e-05, eta: 2:20:29, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0520, decode.acc_seg: 97.9202, loss: 0.0520
2022-11-29 19:12:57,659 - mmseg - INFO - Iter [10600/40000]	lr: 4.410e-05, eta: 2:20:11, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0820, decode.acc_seg: 96.9617, loss: 0.0820
2022-11-29 19:13:12,602 - mmseg - INFO - Iter [10650/40000]	lr: 4.403e-05, eta: 2:19:58, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0790, decode.acc_seg: 97.3634, loss: 0.0790
2022-11-29 19:13:25,472 - mmseg - INFO - Iter [10700/40000]	lr: 4.395e-05, eta: 2:19:40, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1028, decode.acc_seg: 96.1884, loss: 0.1028
2022-11-29 19:13:38,332 - mmseg - INFO - Iter [10750/40000]	lr: 4.388e-05, eta: 2:19:22, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0546, decode.acc_seg: 97.9048, loss: 0.0546
2022-11-29 19:13:53,341 - mmseg - INFO - Iter [10800/40000]	lr: 4.380e-05, eta: 2:19:10, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0624, decode.acc_seg: 97.3715, loss: 0.0624
2022-11-29 19:14:06,159 - mmseg - INFO - Iter [10850/40000]	lr: 4.373e-05, eta: 2:18:51, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0374, decode.acc_seg: 98.5807, loss: 0.0374
2022-11-29 19:14:18,526 - mmseg - INFO - Iter [10900/40000]	lr: 4.365e-05, eta: 2:18:32, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0557, decode.acc_seg: 97.8637, loss: 0.0557
2022-11-29 19:14:30,912 - mmseg - INFO - Iter [10950/40000]	lr: 4.358e-05, eta: 2:18:13, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0553, decode.acc_seg: 97.4305, loss: 0.0553
2022-11-29 19:14:45,524 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:14:45,524 - mmseg - INFO - Iter [11000/40000]	lr: 4.350e-05, eta: 2:17:59, time: 0.292, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0439, decode.acc_seg: 98.2650, loss: 0.0439
2022-11-29 19:14:58,771 - mmseg - INFO - Iter [11050/40000]	lr: 4.343e-05, eta: 2:17:42, time: 0.265, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0604, decode.acc_seg: 97.7636, loss: 0.0604
2022-11-29 19:15:11,991 - mmseg - INFO - Iter [11100/40000]	lr: 4.335e-05, eta: 2:17:25, time: 0.264, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0522, decode.acc_seg: 98.1411, loss: 0.0522
2022-11-29 19:15:24,453 - mmseg - INFO - Iter [11150/40000]	lr: 4.328e-05, eta: 2:17:06, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0403, decode.acc_seg: 98.4073, loss: 0.0403
2022-11-29 19:15:39,211 - mmseg - INFO - Iter [11200/40000]	lr: 4.320e-05, eta: 2:16:53, time: 0.295, data_time: 0.050, memory: 5529, decode.loss_ce: 0.0335, decode.acc_seg: 98.6993, loss: 0.0335
2022-11-29 19:15:51,614 - mmseg - INFO - Iter [11250/40000]	lr: 4.313e-05, eta: 2:16:34, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0669, decode.acc_seg: 97.4410, loss: 0.0669
2022-11-29 19:16:04,020 - mmseg - INFO - Iter [11300/40000]	lr: 4.305e-05, eta: 2:16:15, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0647, decode.acc_seg: 97.7277, loss: 0.0647
2022-11-29 19:16:18,550 - mmseg - INFO - Iter [11350/40000]	lr: 4.298e-05, eta: 2:16:02, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0585, decode.acc_seg: 97.7242, loss: 0.0585
2022-11-29 19:16:30,998 - mmseg - INFO - Iter [11400/40000]	lr: 4.290e-05, eta: 2:15:43, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.2069, decode.acc_seg: 94.6475, loss: 0.2069
2022-11-29 19:16:43,388 - mmseg - INFO - Iter [11450/40000]	lr: 4.283e-05, eta: 2:15:24, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.1692, decode.acc_seg: 93.5009, loss: 0.1692
2022-11-29 19:16:55,774 - mmseg - INFO - Iter [11500/40000]	lr: 4.275e-05, eta: 2:15:05, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.1014, decode.acc_seg: 96.2878, loss: 0.1014
2022-11-29 19:17:10,398 - mmseg - INFO - Iter [11550/40000]	lr: 4.268e-05, eta: 2:14:52, time: 0.292, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0845, decode.acc_seg: 96.6132, loss: 0.0845
2022-11-29 19:17:22,820 - mmseg - INFO - Iter [11600/40000]	lr: 4.260e-05, eta: 2:14:34, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0533, decode.acc_seg: 97.9982, loss: 0.0533
2022-11-29 19:17:35,241 - mmseg - INFO - Iter [11650/40000]	lr: 4.253e-05, eta: 2:14:15, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0476, decode.acc_seg: 98.1528, loss: 0.0476
2022-11-29 19:17:47,643 - mmseg - INFO - Iter [11700/40000]	lr: 4.245e-05, eta: 2:13:56, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0575, decode.acc_seg: 97.8584, loss: 0.0575
2022-11-29 19:18:02,156 - mmseg - INFO - Iter [11750/40000]	lr: 4.238e-05, eta: 2:13:43, time: 0.290, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0829, decode.acc_seg: 97.3651, loss: 0.0829
2022-11-29 19:18:14,565 - mmseg - INFO - Iter [11800/40000]	lr: 4.230e-05, eta: 2:13:24, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0606, decode.acc_seg: 97.5772, loss: 0.0606
2022-11-29 19:18:26,989 - mmseg - INFO - Iter [11850/40000]	lr: 4.223e-05, eta: 2:13:06, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0714, decode.acc_seg: 97.3206, loss: 0.0714
2022-11-29 19:18:41,631 - mmseg - INFO - Iter [11900/40000]	lr: 4.215e-05, eta: 2:12:53, time: 0.293, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0601, decode.acc_seg: 97.5848, loss: 0.0601
2022-11-29 19:18:54,193 - mmseg - INFO - Iter [11950/40000]	lr: 4.208e-05, eta: 2:12:35, time: 0.251, data_time: 0.005, memory: 5529, decode.loss_ce: 0.1372, decode.acc_seg: 96.0169, loss: 0.1372
2022-11-29 19:19:07,103 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:19:07,103 - mmseg - INFO - Iter [12000/40000]	lr: 4.200e-05, eta: 2:12:18, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 0.2295, decode.acc_seg: 92.5480, loss: 0.2295
2022-11-29 19:19:19,826 - mmseg - INFO - Iter [12050/40000]	lr: 4.193e-05, eta: 2:12:00, time: 0.254, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1291, decode.acc_seg: 96.6250, loss: 0.1291
2022-11-29 19:19:36,322 - mmseg - INFO - Iter [12100/40000]	lr: 4.185e-05, eta: 2:11:51, time: 0.330, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0587, decode.acc_seg: 98.1261, loss: 0.0587
2022-11-29 19:19:49,283 - mmseg - INFO - Iter [12150/40000]	lr: 4.178e-05, eta: 2:11:34, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1188, decode.acc_seg: 95.9471, loss: 0.1188
2022-11-29 19:20:02,188 - mmseg - INFO - Iter [12200/40000]	lr: 4.170e-05, eta: 2:11:17, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0433, decode.acc_seg: 98.4333, loss: 0.0433
2022-11-29 19:20:15,336 - mmseg - INFO - Iter [12250/40000]	lr: 4.163e-05, eta: 2:11:01, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0760, decode.acc_seg: 97.3899, loss: 0.0760
2022-11-29 19:20:31,097 - mmseg - INFO - Iter [12300/40000]	lr: 4.155e-05, eta: 2:10:50, time: 0.315, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0365, decode.acc_seg: 98.5063, loss: 0.0365
2022-11-29 19:20:43,971 - mmseg - INFO - Iter [12350/40000]	lr: 4.148e-05, eta: 2:10:33, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0503, decode.acc_seg: 98.1528, loss: 0.0503
2022-11-29 19:20:56,856 - mmseg - INFO - Iter [12400/40000]	lr: 4.140e-05, eta: 2:10:16, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0593, decode.acc_seg: 97.5353, loss: 0.0593
2022-11-29 19:21:11,856 - mmseg - INFO - Iter [12450/40000]	lr: 4.133e-05, eta: 2:10:04, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0440, decode.acc_seg: 98.3483, loss: 0.0440
2022-11-29 19:21:24,777 - mmseg - INFO - Iter [12500/40000]	lr: 4.125e-05, eta: 2:09:47, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0539, decode.acc_seg: 97.9661, loss: 0.0539
2022-11-29 19:21:37,705 - mmseg - INFO - Iter [12550/40000]	lr: 4.118e-05, eta: 2:09:30, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0388, decode.acc_seg: 98.4293, loss: 0.0388
2022-11-29 19:21:50,521 - mmseg - INFO - Iter [12600/40000]	lr: 4.110e-05, eta: 2:09:13, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0498, decode.acc_seg: 98.0449, loss: 0.0498
2022-11-29 19:22:05,841 - mmseg - INFO - Iter [12650/40000]	lr: 4.103e-05, eta: 2:09:01, time: 0.306, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0532, decode.acc_seg: 98.2014, loss: 0.0532
2022-11-29 19:22:18,694 - mmseg - INFO - Iter [12700/40000]	lr: 4.095e-05, eta: 2:08:45, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0761, decode.acc_seg: 97.0783, loss: 0.0761
2022-11-29 19:22:31,545 - mmseg - INFO - Iter [12750/40000]	lr: 4.088e-05, eta: 2:08:28, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0342, decode.acc_seg: 98.6948, loss: 0.0342
2022-11-29 19:22:44,389 - mmseg - INFO - Iter [12800/40000]	lr: 4.080e-05, eta: 2:08:11, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0592, decode.acc_seg: 97.9119, loss: 0.0592
2022-11-29 19:22:59,356 - mmseg - INFO - Iter [12850/40000]	lr: 4.073e-05, eta: 2:07:58, time: 0.299, data_time: 0.047, memory: 5529, decode.loss_ce: 0.1086, decode.acc_seg: 96.8278, loss: 0.1086
2022-11-29 19:23:12,199 - mmseg - INFO - Iter [12900/40000]	lr: 4.065e-05, eta: 2:07:41, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0496, decode.acc_seg: 98.0266, loss: 0.0496
2022-11-29 19:23:25,046 - mmseg - INFO - Iter [12950/40000]	lr: 4.058e-05, eta: 2:07:25, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0830, decode.acc_seg: 96.8350, loss: 0.0830
2022-11-29 19:23:40,160 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:23:40,161 - mmseg - INFO - Iter [13000/40000]	lr: 4.050e-05, eta: 2:07:13, time: 0.302, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0402, decode.acc_seg: 98.6294, loss: 0.0402
2022-11-29 19:23:54,762 - mmseg - INFO - Iter [13050/40000]	lr: 4.043e-05, eta: 2:06:59, time: 0.292, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0372, decode.acc_seg: 98.4318, loss: 0.0372
2022-11-29 19:24:07,974 - mmseg - INFO - Iter [13100/40000]	lr: 4.035e-05, eta: 2:06:43, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0488, decode.acc_seg: 98.1237, loss: 0.0488
2022-11-29 19:24:21,374 - mmseg - INFO - Iter [13150/40000]	lr: 4.028e-05, eta: 2:06:28, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0745, decode.acc_seg: 96.8907, loss: 0.0745
2022-11-29 19:24:37,016 - mmseg - INFO - Iter [13200/40000]	lr: 4.020e-05, eta: 2:06:17, time: 0.313, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0476, decode.acc_seg: 97.9554, loss: 0.0476
2022-11-29 19:24:49,438 - mmseg - INFO - Iter [13250/40000]	lr: 4.013e-05, eta: 2:05:59, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0691, decode.acc_seg: 97.3512, loss: 0.0691
2022-11-29 19:25:01,875 - mmseg - INFO - Iter [13300/40000]	lr: 4.005e-05, eta: 2:05:42, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0754, decode.acc_seg: 97.0086, loss: 0.0754
2022-11-29 19:25:14,270 - mmseg - INFO - Iter [13350/40000]	lr: 3.998e-05, eta: 2:05:24, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.1975, decode.acc_seg: 94.5336, loss: 0.1975
2022-11-29 19:25:29,049 - mmseg - INFO - Iter [13400/40000]	lr: 3.990e-05, eta: 2:05:11, time: 0.296, data_time: 0.048, memory: 5529, decode.loss_ce: 0.1155, decode.acc_seg: 96.2640, loss: 0.1155
2022-11-29 19:25:41,722 - mmseg - INFO - Iter [13450/40000]	lr: 3.983e-05, eta: 2:04:54, time: 0.253, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1071, decode.acc_seg: 96.1073, loss: 0.1071
2022-11-29 19:25:54,308 - mmseg - INFO - Iter [13500/40000]	lr: 3.975e-05, eta: 2:04:37, time: 0.252, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0438, decode.acc_seg: 98.4079, loss: 0.0438
2022-11-29 19:26:08,901 - mmseg - INFO - Iter [13550/40000]	lr: 3.968e-05, eta: 2:04:24, time: 0.292, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0741, decode.acc_seg: 96.8342, loss: 0.0741
2022-11-29 19:26:21,704 - mmseg - INFO - Iter [13600/40000]	lr: 3.960e-05, eta: 2:04:07, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0602, decode.acc_seg: 97.7944, loss: 0.0602
2022-11-29 19:26:34,672 - mmseg - INFO - Iter [13650/40000]	lr: 3.953e-05, eta: 2:03:51, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0509, decode.acc_seg: 98.3323, loss: 0.0509
2022-11-29 19:26:47,550 - mmseg - INFO - Iter [13700/40000]	lr: 3.945e-05, eta: 2:03:34, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0724, decode.acc_seg: 97.3608, loss: 0.0724
2022-11-29 19:27:03,087 - mmseg - INFO - Iter [13750/40000]	lr: 3.938e-05, eta: 2:03:23, time: 0.311, data_time: 0.048, memory: 5529, decode.loss_ce: 0.1176, decode.acc_seg: 96.0206, loss: 0.1176
2022-11-29 19:27:15,915 - mmseg - INFO - Iter [13800/40000]	lr: 3.930e-05, eta: 2:03:07, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0443, decode.acc_seg: 98.4628, loss: 0.0443
2022-11-29 19:27:28,761 - mmseg - INFO - Iter [13850/40000]	lr: 3.923e-05, eta: 2:02:50, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0623, decode.acc_seg: 97.8053, loss: 0.0623
2022-11-29 19:27:41,949 - mmseg - INFO - Iter [13900/40000]	lr: 3.915e-05, eta: 2:02:34, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0752, decode.acc_seg: 97.2478, loss: 0.0752
2022-11-29 19:27:57,102 - mmseg - INFO - Iter [13950/40000]	lr: 3.908e-05, eta: 2:02:22, time: 0.303, data_time: 0.047, memory: 5529, decode.loss_ce: 0.1330, decode.acc_seg: 96.0329, loss: 0.1330
2022-11-29 19:28:09,975 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:28:09,975 - mmseg - INFO - Iter [14000/40000]	lr: 3.900e-05, eta: 2:02:06, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0858, decode.acc_seg: 97.0648, loss: 0.0858
2022-11-29 19:28:22,900 - mmseg - INFO - Iter [14050/40000]	lr: 3.893e-05, eta: 2:01:50, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0981, decode.acc_seg: 96.9001, loss: 0.0981
2022-11-29 19:28:37,951 - mmseg - INFO - Iter [14100/40000]	lr: 3.885e-05, eta: 2:01:37, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0491, decode.acc_seg: 98.0910, loss: 0.0491
2022-11-29 19:28:51,291 - mmseg - INFO - Iter [14150/40000]	lr: 3.878e-05, eta: 2:01:22, time: 0.267, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1206, decode.acc_seg: 96.8189, loss: 0.1206
2022-11-29 19:29:04,511 - mmseg - INFO - Iter [14200/40000]	lr: 3.870e-05, eta: 2:01:06, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0462, decode.acc_seg: 98.2309, loss: 0.0462
2022-11-29 19:29:17,332 - mmseg - INFO - Iter [14250/40000]	lr: 3.863e-05, eta: 2:00:50, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.1812, decode.acc_seg: 96.5583, loss: 0.1812
2022-11-29 19:29:32,283 - mmseg - INFO - Iter [14300/40000]	lr: 3.855e-05, eta: 2:00:37, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0588, decode.acc_seg: 97.7966, loss: 0.0588
2022-11-29 19:29:45,167 - mmseg - INFO - Iter [14350/40000]	lr: 3.848e-05, eta: 2:00:21, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0486, decode.acc_seg: 97.8008, loss: 0.0486
2022-11-29 19:30:00,472 - mmseg - INFO - Iter [14400/40000]	lr: 3.840e-05, eta: 2:00:09, time: 0.306, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0470, decode.acc_seg: 98.2583, loss: 0.0470
2022-11-29 19:30:16,091 - mmseg - INFO - Iter [14450/40000]	lr: 3.833e-05, eta: 1:59:58, time: 0.312, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0417, decode.acc_seg: 98.2660, loss: 0.0417
2022-11-29 19:30:31,348 - mmseg - INFO - Iter [14500/40000]	lr: 3.825e-05, eta: 1:59:46, time: 0.305, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0324, decode.acc_seg: 98.7421, loss: 0.0324
2022-11-29 19:30:44,209 - mmseg - INFO - Iter [14550/40000]	lr: 3.818e-05, eta: 1:59:30, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0503, decode.acc_seg: 97.8328, loss: 0.0503
2022-11-29 19:30:57,089 - mmseg - INFO - Iter [14600/40000]	lr: 3.810e-05, eta: 1:59:13, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0482, decode.acc_seg: 98.2532, loss: 0.0482
2022-11-29 19:31:11,877 - mmseg - INFO - Iter [14650/40000]	lr: 3.803e-05, eta: 1:59:01, time: 0.296, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0616, decode.acc_seg: 97.7238, loss: 0.0616
2022-11-29 19:31:24,318 - mmseg - INFO - Iter [14700/40000]	lr: 3.795e-05, eta: 1:58:44, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0537, decode.acc_seg: 98.1785, loss: 0.0537
2022-11-29 19:31:37,154 - mmseg - INFO - Iter [14750/40000]	lr: 3.788e-05, eta: 1:58:27, time: 0.257, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0410, decode.acc_seg: 98.4019, loss: 0.0410
2022-11-29 19:31:50,105 - mmseg - INFO - Iter [14800/40000]	lr: 3.780e-05, eta: 1:58:11, time: 0.259, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0405, decode.acc_seg: 98.4526, loss: 0.0405
2022-11-29 19:32:04,650 - mmseg - INFO - Iter [14850/40000]	lr: 3.773e-05, eta: 1:57:58, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0351, decode.acc_seg: 98.6009, loss: 0.0351
2022-11-29 19:32:17,643 - mmseg - INFO - Iter [14900/40000]	lr: 3.765e-05, eta: 1:57:42, time: 0.260, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0303, decode.acc_seg: 98.6127, loss: 0.0303
2022-11-29 19:32:32,526 - mmseg - INFO - Iter [14950/40000]	lr: 3.758e-05, eta: 1:57:30, time: 0.298, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0285, decode.acc_seg: 98.6555, loss: 0.0285
2022-11-29 19:32:47,461 - mmseg - INFO - Saving checkpoint at 15000 iterations
2022-11-29 19:32:50,041 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:32:50,042 - mmseg - INFO - Iter [15000/40000]	lr: 3.750e-05, eta: 1:57:21, time: 0.350, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0399, decode.acc_seg: 98.5030, loss: 0.0399
2022-11-29 19:33:31,414 - mmseg - INFO - per class results:
2022-11-29 19:33:31,415 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  92.2 | 96.09 |
|  aeroplane  | 69.83 |  90.1 |
|   bicycle   | 54.36 | 87.37 |
|     bird    | 60.36 | 93.11 |
|     boat    | 54.76 | 69.17 |
|    bottle   | 63.22 | 69.04 |
|     bus     | 82.51 | 87.99 |
|     car     | 76.73 | 86.91 |
|     cat     | 74.61 | 84.79 |
|    chair    | 27.57 | 46.06 |
|     cow     | 52.32 | 71.01 |
| diningtable | 53.93 | 66.94 |
|     dog     | 67.35 | 81.08 |
|    horse    |  58.8 | 74.54 |
|  motorbike  | 70.07 | 80.19 |
|    person   |  78.9 | 89.34 |
| pottedplant | 45.48 | 69.21 |
|    sheep    | 66.05 | 78.48 |
|     sofa    | 35.24 | 41.52 |
|    train    |  73.4 | 83.63 |
|  tvmonitor  | 45.07 | 55.98 |
+-------------+-------+-------+
2022-11-29 19:33:31,415 - mmseg - INFO - Summary:
2022-11-29 19:33:31,416 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 91.33 | 62.04 | 76.31 |
+-------+-------+-------+
2022-11-29 19:33:31,417 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:33:31,417 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9133, mIoU: 0.6204, mAcc: 0.7631, IoU.background: 0.9220, IoU.aeroplane: 0.6983, IoU.bicycle: 0.5436, IoU.bird: 0.6036, IoU.boat: 0.5476, IoU.bottle: 0.6322, IoU.bus: 0.8251, IoU.car: 0.7673, IoU.cat: 0.7461, IoU.chair: 0.2757, IoU.cow: 0.5232, IoU.diningtable: 0.5393, IoU.dog: 0.6735, IoU.horse: 0.5880, IoU.motorbike: 0.7007, IoU.person: 0.7890, IoU.pottedplant: 0.4548, IoU.sheep: 0.6605, IoU.sofa: 0.3524, IoU.train: 0.7340, IoU.tvmonitor: 0.4507, Acc.background: 0.9609, Acc.aeroplane: 0.9010, Acc.bicycle: 0.8737, Acc.bird: 0.9311, Acc.boat: 0.6917, Acc.bottle: 0.6904, Acc.bus: 0.8799, Acc.car: 0.8691, Acc.cat: 0.8479, Acc.chair: 0.4606, Acc.cow: 0.7101, Acc.diningtable: 0.6694, Acc.dog: 0.8108, Acc.horse: 0.7454, Acc.motorbike: 0.8019, Acc.person: 0.8934, Acc.pottedplant: 0.6921, Acc.sheep: 0.7848, Acc.sofa: 0.4152, Acc.train: 0.8363, Acc.tvmonitor: 0.5598
2022-11-29 19:33:46,102 - mmseg - INFO - Iter [15050/40000]	lr: 3.743e-05, eta: 1:58:17, time: 1.121, data_time: 0.875, memory: 5529, decode.loss_ce: 0.0353, decode.acc_seg: 98.5123, loss: 0.0353
2022-11-29 19:33:58,530 - mmseg - INFO - Iter [15100/40000]	lr: 3.735e-05, eta: 1:58:00, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0444, decode.acc_seg: 98.0453, loss: 0.0444
2022-11-29 19:34:10,976 - mmseg - INFO - Iter [15150/40000]	lr: 3.728e-05, eta: 1:57:42, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0413, decode.acc_seg: 98.4148, loss: 0.0413
2022-11-29 19:34:25,508 - mmseg - INFO - Iter [15200/40000]	lr: 3.720e-05, eta: 1:57:29, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0396, decode.acc_seg: 98.1769, loss: 0.0396
2022-11-29 19:34:37,923 - mmseg - INFO - Iter [15250/40000]	lr: 3.713e-05, eta: 1:57:12, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0647, decode.acc_seg: 97.3083, loss: 0.0647
2022-11-29 19:34:50,346 - mmseg - INFO - Iter [15300/40000]	lr: 3.705e-05, eta: 1:56:55, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0365, decode.acc_seg: 98.4755, loss: 0.0365
2022-11-29 19:35:02,814 - mmseg - INFO - Iter [15350/40000]	lr: 3.698e-05, eta: 1:56:38, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0311, decode.acc_seg: 98.7859, loss: 0.0311
2022-11-29 19:35:18,693 - mmseg - INFO - Iter [15400/40000]	lr: 3.690e-05, eta: 1:56:26, time: 0.318, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0621, decode.acc_seg: 97.7880, loss: 0.0621
2022-11-29 19:35:33,619 - mmseg - INFO - Iter [15450/40000]	lr: 3.683e-05, eta: 1:56:13, time: 0.298, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0297, decode.acc_seg: 98.7683, loss: 0.0297
2022-11-29 19:35:48,553 - mmseg - INFO - Iter [15500/40000]	lr: 3.675e-05, eta: 1:56:00, time: 0.299, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0349, decode.acc_seg: 98.5398, loss: 0.0349
2022-11-29 19:36:01,655 - mmseg - INFO - Iter [15550/40000]	lr: 3.668e-05, eta: 1:55:44, time: 0.262, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0632, decode.acc_seg: 97.1704, loss: 0.0632
2022-11-29 19:36:18,453 - mmseg - INFO - Iter [15600/40000]	lr: 3.660e-05, eta: 1:55:34, time: 0.336, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0639, decode.acc_seg: 98.0829, loss: 0.0639
2022-11-29 19:36:32,880 - mmseg - INFO - Iter [15650/40000]	lr: 3.653e-05, eta: 1:55:20, time: 0.289, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0412, decode.acc_seg: 98.4529, loss: 0.0412
2022-11-29 19:36:45,326 - mmseg - INFO - Iter [15700/40000]	lr: 3.645e-05, eta: 1:55:03, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0554, decode.acc_seg: 98.0571, loss: 0.0554
2022-11-29 19:36:59,894 - mmseg - INFO - Iter [15750/40000]	lr: 3.638e-05, eta: 1:54:49, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0693, decode.acc_seg: 97.1270, loss: 0.0693
2022-11-29 19:37:12,287 - mmseg - INFO - Iter [15800/40000]	lr: 3.630e-05, eta: 1:54:32, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0464, decode.acc_seg: 98.6604, loss: 0.0464
2022-11-29 19:37:24,679 - mmseg - INFO - Iter [15850/40000]	lr: 3.623e-05, eta: 1:54:15, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0434, decode.acc_seg: 98.3811, loss: 0.0434
2022-11-29 19:37:37,071 - mmseg - INFO - Iter [15900/40000]	lr: 3.615e-05, eta: 1:53:59, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0341, decode.acc_seg: 98.7674, loss: 0.0341
2022-11-29 19:37:51,606 - mmseg - INFO - Iter [15950/40000]	lr: 3.608e-05, eta: 1:53:45, time: 0.291, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0386, decode.acc_seg: 98.3119, loss: 0.0386
2022-11-29 19:38:03,982 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:38:03,983 - mmseg - INFO - Iter [16000/40000]	lr: 3.600e-05, eta: 1:53:28, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0280, decode.acc_seg: 98.9131, loss: 0.0280
2022-11-29 19:38:16,344 - mmseg - INFO - Iter [16050/40000]	lr: 3.593e-05, eta: 1:53:11, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0339, decode.acc_seg: 98.5710, loss: 0.0339
2022-11-29 19:38:28,760 - mmseg - INFO - Iter [16100/40000]	lr: 3.585e-05, eta: 1:52:54, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0633, decode.acc_seg: 97.8098, loss: 0.0633
2022-11-29 19:38:43,244 - mmseg - INFO - Iter [16150/40000]	lr: 3.578e-05, eta: 1:52:41, time: 0.290, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0450, decode.acc_seg: 98.4601, loss: 0.0450
2022-11-29 19:38:55,659 - mmseg - INFO - Iter [16200/40000]	lr: 3.570e-05, eta: 1:52:24, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0717, decode.acc_seg: 97.9368, loss: 0.0717
2022-11-29 19:39:08,052 - mmseg - INFO - Iter [16250/40000]	lr: 3.563e-05, eta: 1:52:07, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0380, decode.acc_seg: 98.5913, loss: 0.0380
2022-11-29 19:39:22,544 - mmseg - INFO - Iter [16300/40000]	lr: 3.555e-05, eta: 1:51:53, time: 0.290, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0372, decode.acc_seg: 98.3770, loss: 0.0372
2022-11-29 19:39:34,980 - mmseg - INFO - Iter [16350/40000]	lr: 3.548e-05, eta: 1:51:37, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0368, decode.acc_seg: 98.4415, loss: 0.0368
2022-11-29 19:39:47,371 - mmseg - INFO - Iter [16400/40000]	lr: 3.540e-05, eta: 1:51:20, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0406, decode.acc_seg: 98.4579, loss: 0.0406
2022-11-29 19:39:59,766 - mmseg - INFO - Iter [16450/40000]	lr: 3.533e-05, eta: 1:51:03, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0362, decode.acc_seg: 98.5660, loss: 0.0362
2022-11-29 19:40:14,266 - mmseg - INFO - Iter [16500/40000]	lr: 3.525e-05, eta: 1:50:50, time: 0.290, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0488, decode.acc_seg: 98.0131, loss: 0.0488
2022-11-29 19:40:26,678 - mmseg - INFO - Iter [16550/40000]	lr: 3.518e-05, eta: 1:50:33, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0452, decode.acc_seg: 98.4976, loss: 0.0452
2022-11-29 19:40:39,080 - mmseg - INFO - Iter [16600/40000]	lr: 3.510e-05, eta: 1:50:16, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0352, decode.acc_seg: 98.4576, loss: 0.0352
2022-11-29 19:40:51,528 - mmseg - INFO - Iter [16650/40000]	lr: 3.503e-05, eta: 1:50:00, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0354, decode.acc_seg: 98.5518, loss: 0.0354
2022-11-29 19:41:06,088 - mmseg - INFO - Iter [16700/40000]	lr: 3.495e-05, eta: 1:49:46, time: 0.291, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0223, decode.acc_seg: 98.9996, loss: 0.0223
2022-11-29 19:41:18,481 - mmseg - INFO - Iter [16750/40000]	lr: 3.488e-05, eta: 1:49:30, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0449, decode.acc_seg: 97.9310, loss: 0.0449
2022-11-29 19:41:30,909 - mmseg - INFO - Iter [16800/40000]	lr: 3.480e-05, eta: 1:49:13, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0380, decode.acc_seg: 98.6513, loss: 0.0380
2022-11-29 19:41:45,466 - mmseg - INFO - Iter [16850/40000]	lr: 3.473e-05, eta: 1:49:00, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0239, decode.acc_seg: 99.1487, loss: 0.0239
2022-11-29 19:41:57,901 - mmseg - INFO - Iter [16900/40000]	lr: 3.465e-05, eta: 1:48:43, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0276, decode.acc_seg: 98.7770, loss: 0.0276
2022-11-29 19:42:10,370 - mmseg - INFO - Iter [16950/40000]	lr: 3.458e-05, eta: 1:48:27, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.2795, decode.acc_seg: 95.2042, loss: 0.2795
2022-11-29 19:42:22,814 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:42:22,814 - mmseg - INFO - Iter [17000/40000]	lr: 3.450e-05, eta: 1:48:11, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0487, decode.acc_seg: 98.4566, loss: 0.0487
2022-11-29 19:42:37,908 - mmseg - INFO - Iter [17050/40000]	lr: 3.443e-05, eta: 1:47:58, time: 0.302, data_time: 0.046, memory: 5529, decode.loss_ce: 0.1287, decode.acc_seg: 94.9294, loss: 0.1287
2022-11-29 19:42:50,304 - mmseg - INFO - Iter [17100/40000]	lr: 3.435e-05, eta: 1:47:41, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0596, decode.acc_seg: 97.7516, loss: 0.0596
2022-11-29 19:43:02,702 - mmseg - INFO - Iter [17150/40000]	lr: 3.428e-05, eta: 1:47:25, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0816, decode.acc_seg: 97.2005, loss: 0.0816
2022-11-29 19:43:15,080 - mmseg - INFO - Iter [17200/40000]	lr: 3.420e-05, eta: 1:47:09, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0402, decode.acc_seg: 98.7107, loss: 0.0402
2022-11-29 19:43:29,647 - mmseg - INFO - Iter [17250/40000]	lr: 3.413e-05, eta: 1:46:55, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0424, decode.acc_seg: 98.5179, loss: 0.0424
2022-11-29 19:43:42,023 - mmseg - INFO - Iter [17300/40000]	lr: 3.405e-05, eta: 1:46:39, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0370, decode.acc_seg: 98.7101, loss: 0.0370
2022-11-29 19:43:54,412 - mmseg - INFO - Iter [17350/40000]	lr: 3.398e-05, eta: 1:46:22, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0484, decode.acc_seg: 98.1540, loss: 0.0484
2022-11-29 19:44:08,951 - mmseg - INFO - Iter [17400/40000]	lr: 3.390e-05, eta: 1:46:09, time: 0.291, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0928, decode.acc_seg: 96.7461, loss: 0.0928
2022-11-29 19:44:21,357 - mmseg - INFO - Iter [17450/40000]	lr: 3.383e-05, eta: 1:45:53, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0472, decode.acc_seg: 98.1415, loss: 0.0472
2022-11-29 19:44:33,754 - mmseg - INFO - Iter [17500/40000]	lr: 3.375e-05, eta: 1:45:36, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0417, decode.acc_seg: 98.4202, loss: 0.0417
2022-11-29 19:44:46,169 - mmseg - INFO - Iter [17550/40000]	lr: 3.368e-05, eta: 1:45:20, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0310, decode.acc_seg: 98.7831, loss: 0.0310
2022-11-29 19:45:01,064 - mmseg - INFO - Iter [17600/40000]	lr: 3.360e-05, eta: 1:45:07, time: 0.298, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0347, decode.acc_seg: 98.5737, loss: 0.0347
2022-11-29 19:45:13,471 - mmseg - INFO - Iter [17650/40000]	lr: 3.353e-05, eta: 1:44:51, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0627, decode.acc_seg: 97.5559, loss: 0.0627
2022-11-29 19:45:25,908 - mmseg - INFO - Iter [17700/40000]	lr: 3.345e-05, eta: 1:44:35, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0746, decode.acc_seg: 97.5269, loss: 0.0746
2022-11-29 19:45:38,308 - mmseg - INFO - Iter [17750/40000]	lr: 3.338e-05, eta: 1:44:19, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0823, decode.acc_seg: 96.5186, loss: 0.0823
2022-11-29 19:45:53,122 - mmseg - INFO - Iter [17800/40000]	lr: 3.330e-05, eta: 1:44:06, time: 0.296, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0324, decode.acc_seg: 98.4409, loss: 0.0324
2022-11-29 19:46:05,599 - mmseg - INFO - Iter [17850/40000]	lr: 3.323e-05, eta: 1:43:49, time: 0.250, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0372, decode.acc_seg: 98.6947, loss: 0.0372
2022-11-29 19:46:18,020 - mmseg - INFO - Iter [17900/40000]	lr: 3.315e-05, eta: 1:43:33, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0303, decode.acc_seg: 98.9534, loss: 0.0303
2022-11-29 19:46:33,075 - mmseg - INFO - Iter [17950/40000]	lr: 3.308e-05, eta: 1:43:21, time: 0.301, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0427, decode.acc_seg: 98.2814, loss: 0.0427
2022-11-29 19:46:45,567 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:46:45,568 - mmseg - INFO - Iter [18000/40000]	lr: 3.300e-05, eta: 1:43:05, time: 0.250, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0455, decode.acc_seg: 98.1906, loss: 0.0455
2022-11-29 19:46:57,960 - mmseg - INFO - Iter [18050/40000]	lr: 3.293e-05, eta: 1:42:49, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0350, decode.acc_seg: 98.6576, loss: 0.0350
2022-11-29 19:47:10,419 - mmseg - INFO - Iter [18100/40000]	lr: 3.285e-05, eta: 1:42:33, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.1680, decode.acc_seg: 94.5127, loss: 0.1680
2022-11-29 19:47:25,769 - mmseg - INFO - Iter [18150/40000]	lr: 3.278e-05, eta: 1:42:20, time: 0.307, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0873, decode.acc_seg: 97.3595, loss: 0.0873
2022-11-29 19:47:38,251 - mmseg - INFO - Iter [18200/40000]	lr: 3.270e-05, eta: 1:42:04, time: 0.250, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0577, decode.acc_seg: 98.2285, loss: 0.0577
2022-11-29 19:47:50,659 - mmseg - INFO - Iter [18250/40000]	lr: 3.263e-05, eta: 1:41:48, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0611, decode.acc_seg: 97.6266, loss: 0.0611
2022-11-29 19:48:03,027 - mmseg - INFO - Iter [18300/40000]	lr: 3.255e-05, eta: 1:41:32, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0372, decode.acc_seg: 98.6054, loss: 0.0372
2022-11-29 19:48:17,511 - mmseg - INFO - Iter [18350/40000]	lr: 3.248e-05, eta: 1:41:19, time: 0.290, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0285, decode.acc_seg: 98.8980, loss: 0.0285
2022-11-29 19:48:29,880 - mmseg - INFO - Iter [18400/40000]	lr: 3.240e-05, eta: 1:41:03, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0510, decode.acc_seg: 97.9984, loss: 0.0510
2022-11-29 19:48:42,270 - mmseg - INFO - Iter [18450/40000]	lr: 3.233e-05, eta: 1:40:47, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0685, decode.acc_seg: 97.4415, loss: 0.0685
2022-11-29 19:48:56,761 - mmseg - INFO - Iter [18500/40000]	lr: 3.225e-05, eta: 1:40:33, time: 0.290, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0580, decode.acc_seg: 97.8556, loss: 0.0580
2022-11-29 19:49:09,161 - mmseg - INFO - Iter [18550/40000]	lr: 3.218e-05, eta: 1:40:17, time: 0.248, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0327, decode.acc_seg: 98.7575, loss: 0.0327
2022-11-29 19:49:21,582 - mmseg - INFO - Iter [18600/40000]	lr: 3.210e-05, eta: 1:40:01, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0288, decode.acc_seg: 98.8836, loss: 0.0288
2022-11-29 19:49:33,976 - mmseg - INFO - Iter [18650/40000]	lr: 3.203e-05, eta: 1:39:45, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0298, decode.acc_seg: 98.7402, loss: 0.0298
2022-11-29 19:49:48,502 - mmseg - INFO - Iter [18700/40000]	lr: 3.195e-05, eta: 1:39:32, time: 0.291, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0313, decode.acc_seg: 98.2808, loss: 0.0313
2022-11-29 19:50:02,541 - mmseg - INFO - Iter [18750/40000]	lr: 3.188e-05, eta: 1:39:18, time: 0.281, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0279, decode.acc_seg: 99.0437, loss: 0.0279
2022-11-29 19:50:15,472 - mmseg - INFO - Iter [18800/40000]	lr: 3.180e-05, eta: 1:39:03, time: 0.259, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0267, decode.acc_seg: 98.9022, loss: 0.0267
2022-11-29 19:50:30,058 - mmseg - INFO - Iter [18850/40000]	lr: 3.173e-05, eta: 1:38:49, time: 0.292, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0537, decode.acc_seg: 97.7199, loss: 0.0537
2022-11-29 19:50:42,662 - mmseg - INFO - Iter [18900/40000]	lr: 3.165e-05, eta: 1:38:34, time: 0.252, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0253, decode.acc_seg: 99.0202, loss: 0.0253
2022-11-29 19:50:55,534 - mmseg - INFO - Iter [18950/40000]	lr: 3.158e-05, eta: 1:38:18, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0834, decode.acc_seg: 97.1578, loss: 0.0834
2022-11-29 19:51:08,278 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:51:08,278 - mmseg - INFO - Iter [19000/40000]	lr: 3.150e-05, eta: 1:38:03, time: 0.255, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0405, decode.acc_seg: 98.5480, loss: 0.0405
2022-11-29 19:51:23,255 - mmseg - INFO - Iter [19050/40000]	lr: 3.143e-05, eta: 1:37:50, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0738, decode.acc_seg: 97.4178, loss: 0.0738
2022-11-29 19:51:36,440 - mmseg - INFO - Iter [19100/40000]	lr: 3.135e-05, eta: 1:37:35, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0604, decode.acc_seg: 97.9229, loss: 0.0604
2022-11-29 19:51:49,295 - mmseg - INFO - Iter [19150/40000]	lr: 3.128e-05, eta: 1:37:20, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0396, decode.acc_seg: 98.2878, loss: 0.0396
2022-11-29 19:52:02,155 - mmseg - INFO - Iter [19200/40000]	lr: 3.120e-05, eta: 1:37:05, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0256, decode.acc_seg: 98.9797, loss: 0.0256
2022-11-29 19:52:17,154 - mmseg - INFO - Iter [19250/40000]	lr: 3.113e-05, eta: 1:36:52, time: 0.300, data_time: 0.049, memory: 5529, decode.loss_ce: 0.0300, decode.acc_seg: 98.9185, loss: 0.0300
2022-11-29 19:52:29,999 - mmseg - INFO - Iter [19300/40000]	lr: 3.105e-05, eta: 1:36:37, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0347, decode.acc_seg: 98.6641, loss: 0.0347
2022-11-29 19:52:42,877 - mmseg - INFO - Iter [19350/40000]	lr: 3.098e-05, eta: 1:36:21, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0436, decode.acc_seg: 98.5040, loss: 0.0436
2022-11-29 19:52:57,834 - mmseg - INFO - Iter [19400/40000]	lr: 3.090e-05, eta: 1:36:08, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0416, decode.acc_seg: 98.4247, loss: 0.0416
2022-11-29 19:53:10,781 - mmseg - INFO - Iter [19450/40000]	lr: 3.083e-05, eta: 1:35:53, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0268, decode.acc_seg: 98.7364, loss: 0.0268
2022-11-29 19:53:23,646 - mmseg - INFO - Iter [19500/40000]	lr: 3.075e-05, eta: 1:35:38, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0262, decode.acc_seg: 98.8162, loss: 0.0262
2022-11-29 19:53:36,512 - mmseg - INFO - Iter [19550/40000]	lr: 3.068e-05, eta: 1:35:23, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0276, decode.acc_seg: 98.7670, loss: 0.0276
2022-11-29 19:53:51,494 - mmseg - INFO - Iter [19600/40000]	lr: 3.060e-05, eta: 1:35:10, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0241, decode.acc_seg: 99.1618, loss: 0.0241
2022-11-29 19:54:04,356 - mmseg - INFO - Iter [19650/40000]	lr: 3.053e-05, eta: 1:34:55, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0250, decode.acc_seg: 99.0479, loss: 0.0250
2022-11-29 19:54:17,735 - mmseg - INFO - Iter [19700/40000]	lr: 3.045e-05, eta: 1:34:40, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0341, decode.acc_seg: 98.6303, loss: 0.0341
2022-11-29 19:54:30,603 - mmseg - INFO - Iter [19750/40000]	lr: 3.038e-05, eta: 1:34:25, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0330, decode.acc_seg: 98.6293, loss: 0.0330
2022-11-29 19:54:45,650 - mmseg - INFO - Iter [19800/40000]	lr: 3.030e-05, eta: 1:34:12, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0443, decode.acc_seg: 98.3704, loss: 0.0443
2022-11-29 19:54:58,096 - mmseg - INFO - Iter [19850/40000]	lr: 3.023e-05, eta: 1:33:56, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0254, decode.acc_seg: 99.0675, loss: 0.0254
2022-11-29 19:55:10,553 - mmseg - INFO - Iter [19900/40000]	lr: 3.015e-05, eta: 1:33:41, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0285, decode.acc_seg: 98.9474, loss: 0.0285
2022-11-29 19:55:25,342 - mmseg - INFO - Iter [19950/40000]	lr: 3.008e-05, eta: 1:33:28, time: 0.296, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0338, decode.acc_seg: 98.4521, loss: 0.0338
2022-11-29 19:55:38,086 - mmseg - INFO - Saving checkpoint at 20000 iterations
2022-11-29 19:55:39,943 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:55:39,943 - mmseg - INFO - Iter [20000/40000]	lr: 3.000e-05, eta: 1:33:14, time: 0.292, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0447, decode.acc_seg: 98.2855, loss: 0.0447
2022-11-29 19:56:22,020 - mmseg - INFO - per class results:
2022-11-29 19:56:22,022 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  92.0 | 96.47 |
|  aeroplane  | 72.42 | 92.09 |
|   bicycle   | 61.38 | 68.77 |
|     bird    | 48.98 | 49.53 |
|     boat    | 55.08 | 70.72 |
|    bottle   | 49.17 | 52.52 |
|     bus     | 74.33 | 86.92 |
|     car     | 71.58 | 80.57 |
|     cat     |  75.2 | 82.97 |
|    chair    | 25.27 |  43.2 |
|     cow     |  46.3 | 64.43 |
| diningtable | 47.41 | 51.58 |
|     dog     | 49.07 | 92.95 |
|    horse    |  39.8 | 41.55 |
|  motorbike  | 58.31 | 62.98 |
|    person   | 77.59 | 89.16 |
| pottedplant | 38.86 | 42.42 |
|    sheep    | 57.72 | 62.01 |
|     sofa    | 34.65 | 45.14 |
|    train    | 70.96 | 79.95 |
|  tvmonitor  | 51.02 | 75.45 |
+-------------+-------+-------+
2022-11-29 19:56:22,022 - mmseg - INFO - Summary:
2022-11-29 19:56:22,022 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 90.21 | 57.01 | 68.16 |
+-------+-------+-------+
2022-11-29 19:56:22,024 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 19:56:22,024 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9021, mIoU: 0.5701, mAcc: 0.6816, IoU.background: 0.9200, IoU.aeroplane: 0.7242, IoU.bicycle: 0.6138, IoU.bird: 0.4898, IoU.boat: 0.5508, IoU.bottle: 0.4917, IoU.bus: 0.7433, IoU.car: 0.7158, IoU.cat: 0.7520, IoU.chair: 0.2527, IoU.cow: 0.4630, IoU.diningtable: 0.4741, IoU.dog: 0.4907, IoU.horse: 0.3980, IoU.motorbike: 0.5831, IoU.person: 0.7759, IoU.pottedplant: 0.3886, IoU.sheep: 0.5772, IoU.sofa: 0.3465, IoU.train: 0.7096, IoU.tvmonitor: 0.5102, Acc.background: 0.9647, Acc.aeroplane: 0.9209, Acc.bicycle: 0.6877, Acc.bird: 0.4953, Acc.boat: 0.7072, Acc.bottle: 0.5252, Acc.bus: 0.8692, Acc.car: 0.8057, Acc.cat: 0.8297, Acc.chair: 0.4320, Acc.cow: 0.6443, Acc.diningtable: 0.5158, Acc.dog: 0.9295, Acc.horse: 0.4155, Acc.motorbike: 0.6298, Acc.person: 0.8916, Acc.pottedplant: 0.4242, Acc.sheep: 0.6201, Acc.sofa: 0.4514, Acc.train: 0.7995, Acc.tvmonitor: 0.7545
2022-11-29 19:56:35,250 - mmseg - INFO - Iter [20050/40000]	lr: 2.993e-05, eta: 1:33:42, time: 1.106, data_time: 0.848, memory: 5529, decode.loss_ce: 0.0390, decode.acc_seg: 98.4544, loss: 0.0390
2022-11-29 19:56:48,295 - mmseg - INFO - Iter [20100/40000]	lr: 2.985e-05, eta: 1:33:26, time: 0.261, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0269, decode.acc_seg: 98.9604, loss: 0.0269
2022-11-29 19:57:03,317 - mmseg - INFO - Iter [20150/40000]	lr: 2.978e-05, eta: 1:33:13, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0196, decode.acc_seg: 99.3158, loss: 0.0196
2022-11-29 19:57:16,227 - mmseg - INFO - Iter [20200/40000]	lr: 2.970e-05, eta: 1:32:58, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0294, decode.acc_seg: 98.8855, loss: 0.0294
2022-11-29 19:57:29,139 - mmseg - INFO - Iter [20250/40000]	lr: 2.963e-05, eta: 1:32:43, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0240, decode.acc_seg: 98.9298, loss: 0.0240
2022-11-29 19:57:42,067 - mmseg - INFO - Iter [20300/40000]	lr: 2.955e-05, eta: 1:32:28, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0209, decode.acc_seg: 99.1516, loss: 0.0209
2022-11-29 19:57:57,095 - mmseg - INFO - Iter [20350/40000]	lr: 2.948e-05, eta: 1:32:14, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0247, decode.acc_seg: 99.0592, loss: 0.0247
2022-11-29 19:58:09,976 - mmseg - INFO - Iter [20400/40000]	lr: 2.940e-05, eta: 1:31:59, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0289, decode.acc_seg: 99.0509, loss: 0.0289
2022-11-29 19:58:22,914 - mmseg - INFO - Iter [20450/40000]	lr: 2.933e-05, eta: 1:31:44, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0250, decode.acc_seg: 98.9776, loss: 0.0250
2022-11-29 19:58:37,940 - mmseg - INFO - Iter [20500/40000]	lr: 2.925e-05, eta: 1:31:31, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0267, decode.acc_seg: 98.9600, loss: 0.0267
2022-11-29 19:58:51,319 - mmseg - INFO - Iter [20550/40000]	lr: 2.918e-05, eta: 1:31:16, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0187, decode.acc_seg: 99.2359, loss: 0.0187
2022-11-29 19:59:06,828 - mmseg - INFO - Iter [20600/40000]	lr: 2.910e-05, eta: 1:31:03, time: 0.310, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0216, decode.acc_seg: 99.0728, loss: 0.0216
2022-11-29 19:59:20,550 - mmseg - INFO - Iter [20650/40000]	lr: 2.903e-05, eta: 1:30:49, time: 0.274, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0202, decode.acc_seg: 99.0841, loss: 0.0202
2022-11-29 19:59:35,098 - mmseg - INFO - Iter [20700/40000]	lr: 2.895e-05, eta: 1:30:35, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0211, decode.acc_seg: 99.1548, loss: 0.0211
2022-11-29 19:59:47,532 - mmseg - INFO - Iter [20750/40000]	lr: 2.888e-05, eta: 1:30:20, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0214, decode.acc_seg: 99.0128, loss: 0.0214
2022-11-29 20:00:00,297 - mmseg - INFO - Iter [20800/40000]	lr: 2.880e-05, eta: 1:30:04, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0393, decode.acc_seg: 98.5379, loss: 0.0393
2022-11-29 20:00:13,101 - mmseg - INFO - Iter [20850/40000]	lr: 2.873e-05, eta: 1:29:49, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0233, decode.acc_seg: 98.9750, loss: 0.0233
2022-11-29 20:00:28,340 - mmseg - INFO - Iter [20900/40000]	lr: 2.865e-05, eta: 1:29:36, time: 0.305, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0201, decode.acc_seg: 99.1223, loss: 0.0201
2022-11-29 20:00:41,173 - mmseg - INFO - Iter [20950/40000]	lr: 2.858e-05, eta: 1:29:21, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0192, decode.acc_seg: 99.1570, loss: 0.0192
2022-11-29 20:00:54,140 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:00:54,140 - mmseg - INFO - Iter [21000/40000]	lr: 2.850e-05, eta: 1:29:06, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0277, decode.acc_seg: 98.6868, loss: 0.0277
2022-11-29 20:01:09,204 - mmseg - INFO - Iter [21050/40000]	lr: 2.843e-05, eta: 1:28:53, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0176, decode.acc_seg: 99.1601, loss: 0.0176
2022-11-29 20:01:22,470 - mmseg - INFO - Iter [21100/40000]	lr: 2.835e-05, eta: 1:28:38, time: 0.265, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0232, decode.acc_seg: 99.1106, loss: 0.0232
2022-11-29 20:01:35,436 - mmseg - INFO - Iter [21150/40000]	lr: 2.828e-05, eta: 1:28:23, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0186, decode.acc_seg: 99.1226, loss: 0.0186
2022-11-29 20:01:48,310 - mmseg - INFO - Iter [21200/40000]	lr: 2.820e-05, eta: 1:28:08, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0427, decode.acc_seg: 98.1749, loss: 0.0427
2022-11-29 20:02:03,486 - mmseg - INFO - Iter [21250/40000]	lr: 2.813e-05, eta: 1:27:55, time: 0.304, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0719, decode.acc_seg: 97.2064, loss: 0.0719
2022-11-29 20:02:16,388 - mmseg - INFO - Iter [21300/40000]	lr: 2.805e-05, eta: 1:27:39, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0215, decode.acc_seg: 99.0727, loss: 0.0215
2022-11-29 20:02:29,313 - mmseg - INFO - Iter [21350/40000]	lr: 2.798e-05, eta: 1:27:24, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0744, decode.acc_seg: 97.5860, loss: 0.0744
2022-11-29 20:02:42,152 - mmseg - INFO - Iter [21400/40000]	lr: 2.790e-05, eta: 1:27:09, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0461, decode.acc_seg: 98.1642, loss: 0.0461
2022-11-29 20:02:57,145 - mmseg - INFO - Iter [21450/40000]	lr: 2.783e-05, eta: 1:26:56, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0286, decode.acc_seg: 98.9726, loss: 0.0286
2022-11-29 20:03:10,081 - mmseg - INFO - Iter [21500/40000]	lr: 2.775e-05, eta: 1:26:41, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0338, decode.acc_seg: 98.6062, loss: 0.0338
2022-11-29 20:03:23,088 - mmseg - INFO - Iter [21550/40000]	lr: 2.768e-05, eta: 1:26:26, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0405, decode.acc_seg: 98.4000, loss: 0.0405
2022-11-29 20:03:38,559 - mmseg - INFO - Iter [21600/40000]	lr: 2.760e-05, eta: 1:26:13, time: 0.309, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0269, decode.acc_seg: 98.9407, loss: 0.0269
2022-11-29 20:03:51,507 - mmseg - INFO - Iter [21650/40000]	lr: 2.753e-05, eta: 1:25:58, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0246, decode.acc_seg: 98.8961, loss: 0.0246
2022-11-29 20:04:03,918 - mmseg - INFO - Iter [21700/40000]	lr: 2.745e-05, eta: 1:25:43, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0288, decode.acc_seg: 98.7383, loss: 0.0288
2022-11-29 20:04:16,311 - mmseg - INFO - Iter [21750/40000]	lr: 2.738e-05, eta: 1:25:27, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0236, decode.acc_seg: 98.9786, loss: 0.0236
2022-11-29 20:04:31,819 - mmseg - INFO - Iter [21800/40000]	lr: 2.730e-05, eta: 1:25:14, time: 0.310, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0243, decode.acc_seg: 98.9505, loss: 0.0243
2022-11-29 20:04:44,632 - mmseg - INFO - Iter [21850/40000]	lr: 2.723e-05, eta: 1:24:59, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0226, decode.acc_seg: 99.0903, loss: 0.0226
2022-11-29 20:04:57,467 - mmseg - INFO - Iter [21900/40000]	lr: 2.715e-05, eta: 1:24:44, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0245, decode.acc_seg: 98.8984, loss: 0.0245
2022-11-29 20:05:10,353 - mmseg - INFO - Iter [21950/40000]	lr: 2.708e-05, eta: 1:24:29, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0245, decode.acc_seg: 98.9543, loss: 0.0245
2022-11-29 20:05:25,328 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:05:25,328 - mmseg - INFO - Iter [22000/40000]	lr: 2.700e-05, eta: 1:24:16, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0153, decode.acc_seg: 99.3396, loss: 0.0153
2022-11-29 20:05:38,195 - mmseg - INFO - Iter [22050/40000]	lr: 2.693e-05, eta: 1:24:01, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0761, decode.acc_seg: 97.8773, loss: 0.0761
2022-11-29 20:05:51,055 - mmseg - INFO - Iter [22100/40000]	lr: 2.685e-05, eta: 1:23:46, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.1428, decode.acc_seg: 97.1597, loss: 0.1428
2022-11-29 20:06:06,030 - mmseg - INFO - Iter [22150/40000]	lr: 2.678e-05, eta: 1:23:33, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0674, decode.acc_seg: 97.5599, loss: 0.0674
2022-11-29 20:06:18,970 - mmseg - INFO - Iter [22200/40000]	lr: 2.670e-05, eta: 1:23:18, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0288, decode.acc_seg: 98.8139, loss: 0.0288
2022-11-29 20:06:31,928 - mmseg - INFO - Iter [22250/40000]	lr: 2.663e-05, eta: 1:23:03, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0352, decode.acc_seg: 98.6020, loss: 0.0352
2022-11-29 20:06:44,815 - mmseg - INFO - Iter [22300/40000]	lr: 2.655e-05, eta: 1:22:48, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0408, decode.acc_seg: 98.5842, loss: 0.0408
2022-11-29 20:06:59,825 - mmseg - INFO - Iter [22350/40000]	lr: 2.648e-05, eta: 1:22:35, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0302, decode.acc_seg: 98.8844, loss: 0.0302
2022-11-29 20:07:12,714 - mmseg - INFO - Iter [22400/40000]	lr: 2.640e-05, eta: 1:22:20, time: 0.258, data_time: 0.008, memory: 5529, decode.loss_ce: 0.0253, decode.acc_seg: 98.9604, loss: 0.0253
2022-11-29 20:07:25,557 - mmseg - INFO - Iter [22450/40000]	lr: 2.633e-05, eta: 1:22:05, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0234, decode.acc_seg: 99.0026, loss: 0.0234
2022-11-29 20:07:38,478 - mmseg - INFO - Iter [22500/40000]	lr: 2.625e-05, eta: 1:21:50, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0354, decode.acc_seg: 98.5055, loss: 0.0354
2022-11-29 20:07:53,597 - mmseg - INFO - Iter [22550/40000]	lr: 2.618e-05, eta: 1:21:37, time: 0.302, data_time: 0.049, memory: 5529, decode.loss_ce: 0.0260, decode.acc_seg: 98.9129, loss: 0.0260
2022-11-29 20:08:07,141 - mmseg - INFO - Iter [22600/40000]	lr: 2.610e-05, eta: 1:21:22, time: 0.271, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0522, decode.acc_seg: 97.7492, loss: 0.0522
2022-11-29 20:08:20,045 - mmseg - INFO - Iter [22650/40000]	lr: 2.603e-05, eta: 1:21:07, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0370, decode.acc_seg: 98.7817, loss: 0.0370
2022-11-29 20:08:34,630 - mmseg - INFO - Iter [22700/40000]	lr: 2.595e-05, eta: 1:20:54, time: 0.292, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0452, decode.acc_seg: 98.4384, loss: 0.0452
2022-11-29 20:08:47,122 - mmseg - INFO - Iter [22750/40000]	lr: 2.588e-05, eta: 1:20:39, time: 0.250, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0256, decode.acc_seg: 98.9745, loss: 0.0256
2022-11-29 20:08:59,868 - mmseg - INFO - Iter [22800/40000]	lr: 2.580e-05, eta: 1:20:24, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0246, decode.acc_seg: 98.9623, loss: 0.0246
2022-11-29 20:09:12,611 - mmseg - INFO - Iter [22850/40000]	lr: 2.573e-05, eta: 1:20:09, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0215, decode.acc_seg: 99.0777, loss: 0.0215
2022-11-29 20:09:27,622 - mmseg - INFO - Iter [22900/40000]	lr: 2.565e-05, eta: 1:19:55, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0188, decode.acc_seg: 98.9974, loss: 0.0188
2022-11-29 20:09:41,152 - mmseg - INFO - Iter [22950/40000]	lr: 2.558e-05, eta: 1:19:41, time: 0.271, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0236, decode.acc_seg: 99.0806, loss: 0.0236
2022-11-29 20:09:56,635 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:09:56,635 - mmseg - INFO - Iter [23000/40000]	lr: 2.550e-05, eta: 1:19:28, time: 0.310, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0240, decode.acc_seg: 98.9920, loss: 0.0240
2022-11-29 20:10:12,231 - mmseg - INFO - Iter [23050/40000]	lr: 2.543e-05, eta: 1:19:15, time: 0.312, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0217, decode.acc_seg: 98.9863, loss: 0.0217
2022-11-29 20:10:27,802 - mmseg - INFO - Iter [23100/40000]	lr: 2.535e-05, eta: 1:19:02, time: 0.311, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0289, decode.acc_seg: 98.7489, loss: 0.0289
2022-11-29 20:10:40,730 - mmseg - INFO - Iter [23150/40000]	lr: 2.528e-05, eta: 1:18:47, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0343, decode.acc_seg: 98.7389, loss: 0.0343
2022-11-29 20:10:53,664 - mmseg - INFO - Iter [23200/40000]	lr: 2.520e-05, eta: 1:18:33, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0229, decode.acc_seg: 99.1639, loss: 0.0229
2022-11-29 20:11:08,722 - mmseg - INFO - Iter [23250/40000]	lr: 2.513e-05, eta: 1:18:19, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0218, decode.acc_seg: 99.0474, loss: 0.0218
2022-11-29 20:11:21,587 - mmseg - INFO - Iter [23300/40000]	lr: 2.505e-05, eta: 1:18:04, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0452, decode.acc_seg: 98.3538, loss: 0.0452
2022-11-29 20:11:34,511 - mmseg - INFO - Iter [23350/40000]	lr: 2.498e-05, eta: 1:17:50, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0210, decode.acc_seg: 99.0955, loss: 0.0210
2022-11-29 20:11:47,634 - mmseg - INFO - Iter [23400/40000]	lr: 2.490e-05, eta: 1:17:35, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0336, decode.acc_seg: 98.5344, loss: 0.0336
2022-11-29 20:12:02,619 - mmseg - INFO - Iter [23450/40000]	lr: 2.483e-05, eta: 1:17:22, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0403, decode.acc_seg: 98.2116, loss: 0.0403
2022-11-29 20:12:15,504 - mmseg - INFO - Iter [23500/40000]	lr: 2.475e-05, eta: 1:17:07, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0303, decode.acc_seg: 98.8225, loss: 0.0303
2022-11-29 20:12:28,377 - mmseg - INFO - Iter [23550/40000]	lr: 2.468e-05, eta: 1:16:52, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0865, decode.acc_seg: 97.0668, loss: 0.0865
2022-11-29 20:12:41,250 - mmseg - INFO - Iter [23600/40000]	lr: 2.460e-05, eta: 1:16:37, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0343, decode.acc_seg: 98.7882, loss: 0.0343
2022-11-29 20:12:55,979 - mmseg - INFO - Iter [23650/40000]	lr: 2.453e-05, eta: 1:16:24, time: 0.295, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0260, decode.acc_seg: 98.9703, loss: 0.0260
2022-11-29 20:13:08,387 - mmseg - INFO - Iter [23700/40000]	lr: 2.445e-05, eta: 1:16:08, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0212, decode.acc_seg: 99.2359, loss: 0.0212
2022-11-29 20:13:20,789 - mmseg - INFO - Iter [23750/40000]	lr: 2.438e-05, eta: 1:15:53, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0172, decode.acc_seg: 99.2484, loss: 0.0172
2022-11-29 20:13:35,683 - mmseg - INFO - Iter [23800/40000]	lr: 2.430e-05, eta: 1:15:40, time: 0.298, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0263, decode.acc_seg: 99.0167, loss: 0.0263
2022-11-29 20:13:48,485 - mmseg - INFO - Iter [23850/40000]	lr: 2.423e-05, eta: 1:15:25, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0144, decode.acc_seg: 99.4114, loss: 0.0144
2022-11-29 20:14:01,315 - mmseg - INFO - Iter [23900/40000]	lr: 2.415e-05, eta: 1:15:10, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0209, decode.acc_seg: 99.0813, loss: 0.0209
2022-11-29 20:14:14,133 - mmseg - INFO - Iter [23950/40000]	lr: 2.408e-05, eta: 1:14:56, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0242, decode.acc_seg: 99.1445, loss: 0.0242
2022-11-29 20:14:29,094 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:14:29,095 - mmseg - INFO - Iter [24000/40000]	lr: 2.400e-05, eta: 1:14:42, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0872, decode.acc_seg: 97.0577, loss: 0.0872
2022-11-29 20:14:42,717 - mmseg - INFO - Iter [24050/40000]	lr: 2.393e-05, eta: 1:14:28, time: 0.272, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0230, decode.acc_seg: 99.1724, loss: 0.0230
2022-11-29 20:14:55,543 - mmseg - INFO - Iter [24100/40000]	lr: 2.385e-05, eta: 1:14:13, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0185, decode.acc_seg: 99.1355, loss: 0.0185
2022-11-29 20:15:08,422 - mmseg - INFO - Iter [24150/40000]	lr: 2.378e-05, eta: 1:13:58, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0193, decode.acc_seg: 99.2605, loss: 0.0193
2022-11-29 20:15:24,013 - mmseg - INFO - Iter [24200/40000]	lr: 2.370e-05, eta: 1:13:45, time: 0.312, data_time: 0.049, memory: 5529, decode.loss_ce: 0.0230, decode.acc_seg: 99.1336, loss: 0.0230
2022-11-29 20:15:38,111 - mmseg - INFO - Iter [24250/40000]	lr: 2.363e-05, eta: 1:13:31, time: 0.282, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0312, decode.acc_seg: 98.7574, loss: 0.0312
2022-11-29 20:15:53,370 - mmseg - INFO - Iter [24300/40000]	lr: 2.355e-05, eta: 1:13:18, time: 0.305, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0214, decode.acc_seg: 99.0181, loss: 0.0214
2022-11-29 20:16:10,564 - mmseg - INFO - Iter [24350/40000]	lr: 2.348e-05, eta: 1:13:06, time: 0.344, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0224, decode.acc_seg: 99.0118, loss: 0.0224
2022-11-29 20:16:24,266 - mmseg - INFO - Iter [24400/40000]	lr: 2.340e-05, eta: 1:12:52, time: 0.274, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0320, decode.acc_seg: 98.8936, loss: 0.0320
2022-11-29 20:16:37,651 - mmseg - INFO - Iter [24450/40000]	lr: 2.333e-05, eta: 1:12:38, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0182, decode.acc_seg: 99.2911, loss: 0.0182
2022-11-29 20:16:50,537 - mmseg - INFO - Iter [24500/40000]	lr: 2.325e-05, eta: 1:12:23, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0294, decode.acc_seg: 98.9418, loss: 0.0294
2022-11-29 20:17:06,261 - mmseg - INFO - Iter [24550/40000]	lr: 2.318e-05, eta: 1:12:10, time: 0.314, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0253, decode.acc_seg: 98.9697, loss: 0.0253
2022-11-29 20:17:21,052 - mmseg - INFO - Iter [24600/40000]	lr: 2.310e-05, eta: 1:11:56, time: 0.296, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0202, decode.acc_seg: 99.1628, loss: 0.0202
2022-11-29 20:17:35,964 - mmseg - INFO - Iter [24650/40000]	lr: 2.303e-05, eta: 1:11:43, time: 0.298, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0496, decode.acc_seg: 98.3187, loss: 0.0496
2022-11-29 20:17:50,870 - mmseg - INFO - Iter [24700/40000]	lr: 2.295e-05, eta: 1:11:30, time: 0.298, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0453, decode.acc_seg: 98.2256, loss: 0.0453
2022-11-29 20:18:06,124 - mmseg - INFO - Iter [24750/40000]	lr: 2.288e-05, eta: 1:11:16, time: 0.305, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0189, decode.acc_seg: 99.0300, loss: 0.0189
2022-11-29 20:18:18,991 - mmseg - INFO - Iter [24800/40000]	lr: 2.280e-05, eta: 1:11:02, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0207, decode.acc_seg: 99.0904, loss: 0.0207
2022-11-29 20:18:33,787 - mmseg - INFO - Iter [24850/40000]	lr: 2.273e-05, eta: 1:10:48, time: 0.296, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0156, decode.acc_seg: 99.2761, loss: 0.0156
2022-11-29 20:18:48,754 - mmseg - INFO - Iter [24900/40000]	lr: 2.265e-05, eta: 1:10:35, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0225, decode.acc_seg: 98.8854, loss: 0.0225
2022-11-29 20:19:01,724 - mmseg - INFO - Iter [24950/40000]	lr: 2.258e-05, eta: 1:10:20, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0240, decode.acc_seg: 98.9592, loss: 0.0240
2022-11-29 20:19:14,676 - mmseg - INFO - Saving checkpoint at 25000 iterations
2022-11-29 20:19:16,494 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:19:16,494 - mmseg - INFO - Iter [25000/40000]	lr: 2.250e-05, eta: 1:10:06, time: 0.295, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0173, decode.acc_seg: 99.1640, loss: 0.0173
2022-11-29 20:19:58,812 - mmseg - INFO - per class results:
2022-11-29 20:19:58,814 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 92.28 | 97.27 |
|  aeroplane  |  74.3 | 94.07 |
|   bicycle   | 65.09 | 78.72 |
|     bird    | 80.09 | 92.77 |
|     boat    | 72.47 | 78.45 |
|    bottle   | 62.51 | 72.71 |
|     bus     | 81.36 |  90.7 |
|     car     | 75.44 | 85.27 |
|     cat     | 81.86 | 90.81 |
|    chair    | 21.47 | 28.14 |
|     cow     | 50.09 | 64.03 |
| diningtable | 51.69 | 64.72 |
|     dog     | 76.33 | 88.42 |
|    horse    | 58.65 | 69.42 |
|  motorbike  | 68.96 | 78.32 |
|    person   | 80.36 | 87.84 |
| pottedplant | 52.36 | 61.69 |
|    sheep    | 64.63 | 79.78 |
|     sofa    |  31.3 | 32.94 |
|    train    |  73.0 | 85.05 |
|  tvmonitor  | 47.79 | 56.66 |
+-------------+-------+-------+
2022-11-29 20:19:58,814 - mmseg - INFO - Summary:
2022-11-29 20:19:58,814 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 91.99 | 64.86 | 75.13 |
+-------+-------+-------+
2022-11-29 20:19:58,815 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:19:58,815 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9199, mIoU: 0.6486, mAcc: 0.7513, IoU.background: 0.9228, IoU.aeroplane: 0.7430, IoU.bicycle: 0.6509, IoU.bird: 0.8009, IoU.boat: 0.7247, IoU.bottle: 0.6251, IoU.bus: 0.8136, IoU.car: 0.7544, IoU.cat: 0.8186, IoU.chair: 0.2147, IoU.cow: 0.5009, IoU.diningtable: 0.5169, IoU.dog: 0.7633, IoU.horse: 0.5865, IoU.motorbike: 0.6896, IoU.person: 0.8036, IoU.pottedplant: 0.5236, IoU.sheep: 0.6463, IoU.sofa: 0.3130, IoU.train: 0.7300, IoU.tvmonitor: 0.4779, Acc.background: 0.9727, Acc.aeroplane: 0.9407, Acc.bicycle: 0.7872, Acc.bird: 0.9277, Acc.boat: 0.7845, Acc.bottle: 0.7271, Acc.bus: 0.9070, Acc.car: 0.8527, Acc.cat: 0.9081, Acc.chair: 0.2814, Acc.cow: 0.6403, Acc.diningtable: 0.6472, Acc.dog: 0.8842, Acc.horse: 0.6942, Acc.motorbike: 0.7832, Acc.person: 0.8784, Acc.pottedplant: 0.6169, Acc.sheep: 0.7978, Acc.sofa: 0.3294, Acc.train: 0.8505, Acc.tvmonitor: 0.5666
2022-11-29 20:20:12,171 - mmseg - INFO - Iter [25050/40000]	lr: 2.243e-05, eta: 1:10:17, time: 1.114, data_time: 0.853, memory: 5529, decode.loss_ce: 0.0282, decode.acc_seg: 99.0129, loss: 0.0282
2022-11-29 20:20:27,380 - mmseg - INFO - Iter [25100/40000]	lr: 2.235e-05, eta: 1:10:04, time: 0.304, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0176, decode.acc_seg: 99.2542, loss: 0.0176
2022-11-29 20:20:40,828 - mmseg - INFO - Iter [25150/40000]	lr: 2.228e-05, eta: 1:09:49, time: 0.269, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0272, decode.acc_seg: 98.8277, loss: 0.0272
2022-11-29 20:20:54,116 - mmseg - INFO - Iter [25200/40000]	lr: 2.220e-05, eta: 1:09:35, time: 0.266, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0423, decode.acc_seg: 98.3547, loss: 0.0423
2022-11-29 20:21:07,297 - mmseg - INFO - Iter [25250/40000]	lr: 2.213e-05, eta: 1:09:20, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0191, decode.acc_seg: 99.2521, loss: 0.0191
2022-11-29 20:21:23,054 - mmseg - INFO - Iter [25300/40000]	lr: 2.205e-05, eta: 1:09:07, time: 0.315, data_time: 0.049, memory: 5529, decode.loss_ce: 0.0247, decode.acc_seg: 99.0580, loss: 0.0247
2022-11-29 20:21:36,046 - mmseg - INFO - Iter [25350/40000]	lr: 2.198e-05, eta: 1:08:52, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0470, decode.acc_seg: 98.3081, loss: 0.0470
2022-11-29 20:21:48,929 - mmseg - INFO - Iter [25400/40000]	lr: 2.190e-05, eta: 1:08:37, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0240, decode.acc_seg: 98.9994, loss: 0.0240
2022-11-29 20:22:03,549 - mmseg - INFO - Iter [25450/40000]	lr: 2.183e-05, eta: 1:08:23, time: 0.292, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0158, decode.acc_seg: 99.3784, loss: 0.0158
2022-11-29 20:22:16,169 - mmseg - INFO - Iter [25500/40000]	lr: 2.175e-05, eta: 1:08:09, time: 0.252, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0187, decode.acc_seg: 99.2703, loss: 0.0187
2022-11-29 20:22:28,954 - mmseg - INFO - Iter [25550/40000]	lr: 2.168e-05, eta: 1:07:54, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0149, decode.acc_seg: 99.3626, loss: 0.0149
2022-11-29 20:22:41,867 - mmseg - INFO - Iter [25600/40000]	lr: 2.160e-05, eta: 1:07:39, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0218, decode.acc_seg: 99.1204, loss: 0.0218
2022-11-29 20:22:56,714 - mmseg - INFO - Iter [25650/40000]	lr: 2.153e-05, eta: 1:07:25, time: 0.297, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0263, decode.acc_seg: 99.0342, loss: 0.0263
2022-11-29 20:23:09,605 - mmseg - INFO - Iter [25700/40000]	lr: 2.145e-05, eta: 1:07:10, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0169, decode.acc_seg: 99.3123, loss: 0.0169
2022-11-29 20:23:22,455 - mmseg - INFO - Iter [25750/40000]	lr: 2.138e-05, eta: 1:06:56, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0214, decode.acc_seg: 99.0701, loss: 0.0214
2022-11-29 20:23:35,303 - mmseg - INFO - Iter [25800/40000]	lr: 2.130e-05, eta: 1:06:41, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0192, decode.acc_seg: 99.0633, loss: 0.0192
2022-11-29 20:23:50,295 - mmseg - INFO - Iter [25850/40000]	lr: 2.123e-05, eta: 1:06:27, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0183, decode.acc_seg: 99.1967, loss: 0.0183
2022-11-29 20:24:03,231 - mmseg - INFO - Iter [25900/40000]	lr: 2.115e-05, eta: 1:06:13, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0168, decode.acc_seg: 99.2793, loss: 0.0168
2022-11-29 20:24:16,088 - mmseg - INFO - Iter [25950/40000]	lr: 2.108e-05, eta: 1:05:58, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0182, decode.acc_seg: 99.3351, loss: 0.0182
2022-11-29 20:24:31,051 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:24:31,051 - mmseg - INFO - Iter [26000/40000]	lr: 2.100e-05, eta: 1:05:44, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0181, decode.acc_seg: 99.1851, loss: 0.0181
2022-11-29 20:24:45,248 - mmseg - INFO - Iter [26050/40000]	lr: 2.093e-05, eta: 1:05:30, time: 0.284, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0193, decode.acc_seg: 99.1710, loss: 0.0193
2022-11-29 20:25:00,760 - mmseg - INFO - Iter [26100/40000]	lr: 2.085e-05, eta: 1:05:17, time: 0.310, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0157, decode.acc_seg: 99.3192, loss: 0.0157
2022-11-29 20:25:15,153 - mmseg - INFO - Iter [26150/40000]	lr: 2.078e-05, eta: 1:05:03, time: 0.288, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0177, decode.acc_seg: 99.2269, loss: 0.0177
2022-11-29 20:25:30,321 - mmseg - INFO - Iter [26200/40000]	lr: 2.070e-05, eta: 1:04:49, time: 0.303, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0214, decode.acc_seg: 99.0592, loss: 0.0214
2022-11-29 20:25:45,841 - mmseg - INFO - Iter [26250/40000]	lr: 2.063e-05, eta: 1:04:36, time: 0.310, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0241, decode.acc_seg: 99.0147, loss: 0.0241
2022-11-29 20:26:00,612 - mmseg - INFO - Iter [26300/40000]	lr: 2.055e-05, eta: 1:04:22, time: 0.295, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0187, decode.acc_seg: 99.2468, loss: 0.0187
2022-11-29 20:26:13,466 - mmseg - INFO - Iter [26350/40000]	lr: 2.048e-05, eta: 1:04:08, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0152, decode.acc_seg: 99.3032, loss: 0.0152
2022-11-29 20:26:28,480 - mmseg - INFO - Iter [26400/40000]	lr: 2.040e-05, eta: 1:03:54, time: 0.300, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0290, decode.acc_seg: 98.8906, loss: 0.0290
2022-11-29 20:26:41,079 - mmseg - INFO - Iter [26450/40000]	lr: 2.033e-05, eta: 1:03:39, time: 0.252, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0167, decode.acc_seg: 99.2382, loss: 0.0167
2022-11-29 20:26:53,648 - mmseg - INFO - Iter [26500/40000]	lr: 2.025e-05, eta: 1:03:24, time: 0.251, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0120, decode.acc_seg: 99.4822, loss: 0.0120
2022-11-29 20:27:08,606 - mmseg - INFO - Iter [26550/40000]	lr: 2.018e-05, eta: 1:03:11, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0189, decode.acc_seg: 99.2701, loss: 0.0189
2022-11-29 20:27:21,484 - mmseg - INFO - Iter [26600/40000]	lr: 2.010e-05, eta: 1:02:56, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0211, decode.acc_seg: 99.1004, loss: 0.0211
2022-11-29 20:27:34,430 - mmseg - INFO - Iter [26650/40000]	lr: 2.003e-05, eta: 1:02:41, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0115, decode.acc_seg: 99.4836, loss: 0.0115
2022-11-29 20:27:47,364 - mmseg - INFO - Iter [26700/40000]	lr: 1.995e-05, eta: 1:02:27, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0248, decode.acc_seg: 99.0361, loss: 0.0248
2022-11-29 20:28:02,565 - mmseg - INFO - Iter [26750/40000]	lr: 1.988e-05, eta: 1:02:13, time: 0.304, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0280, decode.acc_seg: 98.8711, loss: 0.0280
2022-11-29 20:28:15,573 - mmseg - INFO - Iter [26800/40000]	lr: 1.980e-05, eta: 1:01:58, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0183, decode.acc_seg: 99.3214, loss: 0.0183
2022-11-29 20:28:28,628 - mmseg - INFO - Iter [26850/40000]	lr: 1.973e-05, eta: 1:01:44, time: 0.261, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0139, decode.acc_seg: 99.3439, loss: 0.0139
2022-11-29 20:28:41,497 - mmseg - INFO - Iter [26900/40000]	lr: 1.965e-05, eta: 1:01:29, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0179, decode.acc_seg: 99.2473, loss: 0.0179
2022-11-29 20:28:57,200 - mmseg - INFO - Iter [26950/40000]	lr: 1.958e-05, eta: 1:01:16, time: 0.314, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0178, decode.acc_seg: 99.2072, loss: 0.0178
2022-11-29 20:29:10,913 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:29:10,913 - mmseg - INFO - Iter [27000/40000]	lr: 1.950e-05, eta: 1:01:02, time: 0.274, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0133, decode.acc_seg: 99.4882, loss: 0.0133
2022-11-29 20:29:24,711 - mmseg - INFO - Iter [27050/40000]	lr: 1.943e-05, eta: 1:00:47, time: 0.276, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0173, decode.acc_seg: 99.3001, loss: 0.0173
2022-11-29 20:29:39,848 - mmseg - INFO - Iter [27100/40000]	lr: 1.935e-05, eta: 1:00:34, time: 0.303, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0130, decode.acc_seg: 99.3483, loss: 0.0130
2022-11-29 20:29:53,057 - mmseg - INFO - Iter [27150/40000]	lr: 1.928e-05, eta: 1:00:19, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0185, decode.acc_seg: 99.1604, loss: 0.0185
2022-11-29 20:30:05,979 - mmseg - INFO - Iter [27200/40000]	lr: 1.920e-05, eta: 1:00:05, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0186, decode.acc_seg: 99.2076, loss: 0.0186
2022-11-29 20:30:19,253 - mmseg - INFO - Iter [27250/40000]	lr: 1.913e-05, eta: 0:59:50, time: 0.265, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0121, decode.acc_seg: 99.4511, loss: 0.0121
2022-11-29 20:30:34,420 - mmseg - INFO - Iter [27300/40000]	lr: 1.905e-05, eta: 0:59:37, time: 0.303, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0173, decode.acc_seg: 99.3068, loss: 0.0173
2022-11-29 20:30:47,220 - mmseg - INFO - Iter [27350/40000]	lr: 1.898e-05, eta: 0:59:22, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0242, decode.acc_seg: 98.9890, loss: 0.0242
2022-11-29 20:30:59,702 - mmseg - INFO - Iter [27400/40000]	lr: 1.890e-05, eta: 0:59:07, time: 0.250, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0200, decode.acc_seg: 99.0546, loss: 0.0200
2022-11-29 20:31:12,502 - mmseg - INFO - Iter [27450/40000]	lr: 1.883e-05, eta: 0:58:52, time: 0.256, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0231, decode.acc_seg: 99.1488, loss: 0.0231
2022-11-29 20:31:27,286 - mmseg - INFO - Iter [27500/40000]	lr: 1.875e-05, eta: 0:58:39, time: 0.296, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0210, decode.acc_seg: 99.1821, loss: 0.0210
2022-11-29 20:31:40,121 - mmseg - INFO - Iter [27550/40000]	lr: 1.868e-05, eta: 0:58:24, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0377, decode.acc_seg: 98.7612, loss: 0.0377
2022-11-29 20:31:53,060 - mmseg - INFO - Iter [27600/40000]	lr: 1.860e-05, eta: 0:58:09, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0194, decode.acc_seg: 99.1842, loss: 0.0194
2022-11-29 20:32:08,132 - mmseg - INFO - Iter [27650/40000]	lr: 1.853e-05, eta: 0:57:56, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0180, decode.acc_seg: 99.2777, loss: 0.0180
2022-11-29 20:32:21,041 - mmseg - INFO - Iter [27700/40000]	lr: 1.845e-05, eta: 0:57:41, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0174, decode.acc_seg: 99.2722, loss: 0.0174
2022-11-29 20:32:34,083 - mmseg - INFO - Iter [27750/40000]	lr: 1.838e-05, eta: 0:57:27, time: 0.261, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0216, decode.acc_seg: 99.1179, loss: 0.0216
2022-11-29 20:32:46,943 - mmseg - INFO - Iter [27800/40000]	lr: 1.830e-05, eta: 0:57:12, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0149, decode.acc_seg: 99.3763, loss: 0.0149
2022-11-29 20:33:02,261 - mmseg - INFO - Iter [27850/40000]	lr: 1.823e-05, eta: 0:56:59, time: 0.306, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0157, decode.acc_seg: 99.4126, loss: 0.0157
2022-11-29 20:33:15,656 - mmseg - INFO - Iter [27900/40000]	lr: 1.815e-05, eta: 0:56:44, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0111, decode.acc_seg: 99.5103, loss: 0.0111
2022-11-29 20:33:28,587 - mmseg - INFO - Iter [27950/40000]	lr: 1.808e-05, eta: 0:56:30, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0188, decode.acc_seg: 99.2329, loss: 0.0188
2022-11-29 20:33:43,548 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:33:43,549 - mmseg - INFO - Iter [28000/40000]	lr: 1.800e-05, eta: 0:56:16, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0184, decode.acc_seg: 99.1178, loss: 0.0184
2022-11-29 20:33:56,534 - mmseg - INFO - Iter [28050/40000]	lr: 1.793e-05, eta: 0:56:01, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0894, decode.acc_seg: 97.4534, loss: 0.0894
2022-11-29 20:34:09,460 - mmseg - INFO - Iter [28100/40000]	lr: 1.785e-05, eta: 0:55:47, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0255, decode.acc_seg: 98.9260, loss: 0.0255
2022-11-29 20:34:22,309 - mmseg - INFO - Iter [28150/40000]	lr: 1.778e-05, eta: 0:55:32, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0245, decode.acc_seg: 99.0200, loss: 0.0245
2022-11-29 20:34:37,561 - mmseg - INFO - Iter [28200/40000]	lr: 1.770e-05, eta: 0:55:19, time: 0.305, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0304, decode.acc_seg: 99.0559, loss: 0.0304
2022-11-29 20:34:50,479 - mmseg - INFO - Iter [28250/40000]	lr: 1.763e-05, eta: 0:55:04, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0433, decode.acc_seg: 98.4468, loss: 0.0433
2022-11-29 20:35:04,220 - mmseg - INFO - Iter [28300/40000]	lr: 1.755e-05, eta: 0:54:50, time: 0.275, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0237, decode.acc_seg: 99.0605, loss: 0.0237
2022-11-29 20:35:17,221 - mmseg - INFO - Iter [28350/40000]	lr: 1.748e-05, eta: 0:54:35, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0169, decode.acc_seg: 99.3148, loss: 0.0169
2022-11-29 20:35:31,764 - mmseg - INFO - Iter [28400/40000]	lr: 1.740e-05, eta: 0:54:22, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0210, decode.acc_seg: 99.0517, loss: 0.0210
2022-11-29 20:35:44,505 - mmseg - INFO - Iter [28450/40000]	lr: 1.733e-05, eta: 0:54:07, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0235, decode.acc_seg: 99.0606, loss: 0.0235
2022-11-29 20:35:57,322 - mmseg - INFO - Iter [28500/40000]	lr: 1.725e-05, eta: 0:53:52, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0177, decode.acc_seg: 99.3155, loss: 0.0177
2022-11-29 20:36:12,250 - mmseg - INFO - Iter [28550/40000]	lr: 1.718e-05, eta: 0:53:39, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0216, decode.acc_seg: 99.0754, loss: 0.0216
2022-11-29 20:36:25,612 - mmseg - INFO - Iter [28600/40000]	lr: 1.710e-05, eta: 0:53:24, time: 0.267, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0182, decode.acc_seg: 99.3283, loss: 0.0182
2022-11-29 20:36:39,015 - mmseg - INFO - Iter [28650/40000]	lr: 1.703e-05, eta: 0:53:10, time: 0.268, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0196, decode.acc_seg: 99.2494, loss: 0.0196
2022-11-29 20:36:52,867 - mmseg - INFO - Iter [28700/40000]	lr: 1.695e-05, eta: 0:52:56, time: 0.277, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0156, decode.acc_seg: 99.3167, loss: 0.0156
2022-11-29 20:37:07,968 - mmseg - INFO - Iter [28750/40000]	lr: 1.688e-05, eta: 0:52:42, time: 0.302, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0253, decode.acc_seg: 98.9799, loss: 0.0253
2022-11-29 20:37:20,830 - mmseg - INFO - Iter [28800/40000]	lr: 1.680e-05, eta: 0:52:28, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0153, decode.acc_seg: 99.3404, loss: 0.0153
2022-11-29 20:37:33,674 - mmseg - INFO - Iter [28850/40000]	lr: 1.673e-05, eta: 0:52:13, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0332, decode.acc_seg: 98.7753, loss: 0.0332
2022-11-29 20:37:46,549 - mmseg - INFO - Iter [28900/40000]	lr: 1.665e-05, eta: 0:51:59, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0191, decode.acc_seg: 99.1914, loss: 0.0191
2022-11-29 20:38:01,544 - mmseg - INFO - Iter [28950/40000]	lr: 1.658e-05, eta: 0:51:45, time: 0.300, data_time: 0.049, memory: 5529, decode.loss_ce: 0.0164, decode.acc_seg: 99.2494, loss: 0.0164
2022-11-29 20:38:14,394 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:38:14,395 - mmseg - INFO - Iter [29000/40000]	lr: 1.650e-05, eta: 0:51:31, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0222, decode.acc_seg: 99.1356, loss: 0.0222
2022-11-29 20:38:27,257 - mmseg - INFO - Iter [29050/40000]	lr: 1.643e-05, eta: 0:51:16, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0163, decode.acc_seg: 99.3364, loss: 0.0163
2022-11-29 20:38:42,269 - mmseg - INFO - Iter [29100/40000]	lr: 1.635e-05, eta: 0:51:02, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0129, decode.acc_seg: 99.3477, loss: 0.0129
2022-11-29 20:38:56,298 - mmseg - INFO - Iter [29150/40000]	lr: 1.628e-05, eta: 0:50:48, time: 0.281, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0157, decode.acc_seg: 99.3329, loss: 0.0157
2022-11-29 20:39:10,283 - mmseg - INFO - Iter [29200/40000]	lr: 1.620e-05, eta: 0:50:34, time: 0.280, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0152, decode.acc_seg: 99.3260, loss: 0.0152
2022-11-29 20:39:23,135 - mmseg - INFO - Iter [29250/40000]	lr: 1.613e-05, eta: 0:50:20, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0126, decode.acc_seg: 99.4550, loss: 0.0126
2022-11-29 20:39:37,877 - mmseg - INFO - Iter [29300/40000]	lr: 1.605e-05, eta: 0:50:06, time: 0.295, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0118, decode.acc_seg: 99.5382, loss: 0.0118
2022-11-29 20:39:50,328 - mmseg - INFO - Iter [29350/40000]	lr: 1.598e-05, eta: 0:49:51, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0203, decode.acc_seg: 98.8071, loss: 0.0203
2022-11-29 20:40:03,112 - mmseg - INFO - Iter [29400/40000]	lr: 1.590e-05, eta: 0:49:37, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0203, decode.acc_seg: 99.1474, loss: 0.0203
2022-11-29 20:40:16,584 - mmseg - INFO - Iter [29450/40000]	lr: 1.583e-05, eta: 0:49:23, time: 0.269, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0173, decode.acc_seg: 99.2630, loss: 0.0173
2022-11-29 20:40:31,611 - mmseg - INFO - Iter [29500/40000]	lr: 1.575e-05, eta: 0:49:09, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0111, decode.acc_seg: 99.5560, loss: 0.0111
2022-11-29 20:40:44,483 - mmseg - INFO - Iter [29550/40000]	lr: 1.568e-05, eta: 0:48:54, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0145, decode.acc_seg: 99.4163, loss: 0.0145
2022-11-29 20:40:57,486 - mmseg - INFO - Iter [29600/40000]	lr: 1.560e-05, eta: 0:48:40, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0152, decode.acc_seg: 99.3099, loss: 0.0152
2022-11-29 20:41:12,573 - mmseg - INFO - Iter [29650/40000]	lr: 1.553e-05, eta: 0:48:26, time: 0.302, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0158, decode.acc_seg: 99.3132, loss: 0.0158
2022-11-29 20:41:27,551 - mmseg - INFO - Iter [29700/40000]	lr: 1.545e-05, eta: 0:48:13, time: 0.300, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0189, decode.acc_seg: 99.0833, loss: 0.0189
2022-11-29 20:41:43,077 - mmseg - INFO - Iter [29750/40000]	lr: 1.538e-05, eta: 0:47:59, time: 0.311, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0178, decode.acc_seg: 99.2797, loss: 0.0178
2022-11-29 20:41:56,065 - mmseg - INFO - Iter [29800/40000]	lr: 1.530e-05, eta: 0:47:45, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0133, decode.acc_seg: 99.3905, loss: 0.0133
2022-11-29 20:42:11,097 - mmseg - INFO - Iter [29850/40000]	lr: 1.523e-05, eta: 0:47:31, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0130, decode.acc_seg: 99.3596, loss: 0.0130
2022-11-29 20:42:23,953 - mmseg - INFO - Iter [29900/40000]	lr: 1.515e-05, eta: 0:47:17, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0200, decode.acc_seg: 99.1579, loss: 0.0200
2022-11-29 20:42:36,805 - mmseg - INFO - Iter [29950/40000]	lr: 1.508e-05, eta: 0:47:02, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0167, decode.acc_seg: 99.2726, loss: 0.0167
2022-11-29 20:42:49,672 - mmseg - INFO - Saving checkpoint at 30000 iterations
2022-11-29 20:42:52,120 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:42:52,120 - mmseg - INFO - Iter [30000/40000]	lr: 1.500e-05, eta: 0:46:48, time: 0.306, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0112, decode.acc_seg: 99.4681, loss: 0.0112
2022-11-29 20:43:34,824 - mmseg - INFO - per class results:
2022-11-29 20:43:34,825 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 92.65 | 97.66 |
|  aeroplane  | 76.42 | 92.61 |
|   bicycle   | 67.71 | 81.79 |
|     bird    | 80.76 | 91.67 |
|     boat    | 59.13 | 75.34 |
|    bottle   | 64.16 | 73.89 |
|     bus     | 80.46 | 92.25 |
|     car     | 78.77 | 85.64 |
|     cat     | 81.62 | 84.66 |
|    chair    | 29.63 |  34.4 |
|     cow     | 51.77 | 66.91 |
| diningtable |  52.3 |  58.8 |
|     dog     | 76.97 | 89.35 |
|    horse    | 61.11 |  67.3 |
|  motorbike  |  74.4 | 84.64 |
|    person   | 80.49 | 89.73 |
| pottedplant | 42.23 |  46.0 |
|    sheep    | 57.85 | 82.67 |
|     sofa    | 35.41 | 38.95 |
|    train    | 77.76 | 84.19 |
|  tvmonitor  | 43.91 | 51.12 |
+-------------+-------+-------+
2022-11-29 20:43:34,825 - mmseg - INFO - Summary:
2022-11-29 20:43:34,825 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 92.33 | 65.03 | 74.74 |
+-------+-------+-------+
2022-11-29 20:43:34,827 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:43:34,827 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9233, mIoU: 0.6503, mAcc: 0.7474, IoU.background: 0.9265, IoU.aeroplane: 0.7642, IoU.bicycle: 0.6771, IoU.bird: 0.8076, IoU.boat: 0.5913, IoU.bottle: 0.6416, IoU.bus: 0.8046, IoU.car: 0.7877, IoU.cat: 0.8162, IoU.chair: 0.2963, IoU.cow: 0.5177, IoU.diningtable: 0.5230, IoU.dog: 0.7697, IoU.horse: 0.6111, IoU.motorbike: 0.7440, IoU.person: 0.8049, IoU.pottedplant: 0.4223, IoU.sheep: 0.5785, IoU.sofa: 0.3541, IoU.train: 0.7776, IoU.tvmonitor: 0.4391, Acc.background: 0.9766, Acc.aeroplane: 0.9261, Acc.bicycle: 0.8179, Acc.bird: 0.9167, Acc.boat: 0.7534, Acc.bottle: 0.7389, Acc.bus: 0.9225, Acc.car: 0.8564, Acc.cat: 0.8466, Acc.chair: 0.3440, Acc.cow: 0.6691, Acc.diningtable: 0.5880, Acc.dog: 0.8935, Acc.horse: 0.6730, Acc.motorbike: 0.8464, Acc.person: 0.8973, Acc.pottedplant: 0.4600, Acc.sheep: 0.8267, Acc.sofa: 0.3895, Acc.train: 0.8419, Acc.tvmonitor: 0.5112
2022-11-29 20:43:49,954 - mmseg - INFO - Iter [30050/40000]	lr: 1.493e-05, eta: 0:46:49, time: 1.157, data_time: 0.901, memory: 5529, decode.loss_ce: 0.0158, decode.acc_seg: 99.2343, loss: 0.0158
2022-11-29 20:44:02,558 - mmseg - INFO - Iter [30100/40000]	lr: 1.485e-05, eta: 0:46:34, time: 0.252, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0154, decode.acc_seg: 99.3319, loss: 0.0154
2022-11-29 20:44:15,179 - mmseg - INFO - Iter [30150/40000]	lr: 1.478e-05, eta: 0:46:20, time: 0.252, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0142, decode.acc_seg: 99.3398, loss: 0.0142
2022-11-29 20:44:30,124 - mmseg - INFO - Iter [30200/40000]	lr: 1.470e-05, eta: 0:46:06, time: 0.299, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0129, decode.acc_seg: 99.3674, loss: 0.0129
2022-11-29 20:44:43,315 - mmseg - INFO - Iter [30250/40000]	lr: 1.463e-05, eta: 0:45:51, time: 0.264, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0188, decode.acc_seg: 99.2821, loss: 0.0188
2022-11-29 20:44:56,336 - mmseg - INFO - Iter [30300/40000]	lr: 1.455e-05, eta: 0:45:37, time: 0.260, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0136, decode.acc_seg: 99.4526, loss: 0.0136
2022-11-29 20:45:09,313 - mmseg - INFO - Iter [30350/40000]	lr: 1.448e-05, eta: 0:45:23, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0180, decode.acc_seg: 99.2013, loss: 0.0180
2022-11-29 20:45:24,430 - mmseg - INFO - Iter [30400/40000]	lr: 1.440e-05, eta: 0:45:09, time: 0.302, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0106, decode.acc_seg: 99.4149, loss: 0.0106
2022-11-29 20:45:37,327 - mmseg - INFO - Iter [30450/40000]	lr: 1.433e-05, eta: 0:44:54, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0155, decode.acc_seg: 99.4200, loss: 0.0155
2022-11-29 20:45:50,215 - mmseg - INFO - Iter [30500/40000]	lr: 1.425e-05, eta: 0:44:40, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0124, decode.acc_seg: 99.5122, loss: 0.0124
2022-11-29 20:46:03,162 - mmseg - INFO - Iter [30550/40000]	lr: 1.418e-05, eta: 0:44:25, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0141, decode.acc_seg: 99.4214, loss: 0.0141
2022-11-29 20:46:18,168 - mmseg - INFO - Iter [30600/40000]	lr: 1.410e-05, eta: 0:44:11, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0176, decode.acc_seg: 99.2329, loss: 0.0176
2022-11-29 20:46:31,105 - mmseg - INFO - Iter [30650/40000]	lr: 1.403e-05, eta: 0:43:57, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0129, decode.acc_seg: 99.4323, loss: 0.0129
2022-11-29 20:46:43,971 - mmseg - INFO - Iter [30700/40000]	lr: 1.395e-05, eta: 0:43:43, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0126, decode.acc_seg: 99.4719, loss: 0.0126
2022-11-29 20:46:59,278 - mmseg - INFO - Iter [30750/40000]	lr: 1.388e-05, eta: 0:43:29, time: 0.306, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0181, decode.acc_seg: 99.1970, loss: 0.0181
2022-11-29 20:47:12,135 - mmseg - INFO - Iter [30800/40000]	lr: 1.380e-05, eta: 0:43:14, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0134, decode.acc_seg: 99.4716, loss: 0.0134
2022-11-29 20:47:25,036 - mmseg - INFO - Iter [30850/40000]	lr: 1.373e-05, eta: 0:43:00, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0282, decode.acc_seg: 98.8238, loss: 0.0282
2022-11-29 20:47:37,892 - mmseg - INFO - Iter [30900/40000]	lr: 1.365e-05, eta: 0:42:45, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0125, decode.acc_seg: 99.4781, loss: 0.0125
2022-11-29 20:47:52,803 - mmseg - INFO - Iter [30950/40000]	lr: 1.358e-05, eta: 0:42:32, time: 0.298, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0163, decode.acc_seg: 99.3568, loss: 0.0163
2022-11-29 20:48:05,929 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:48:05,929 - mmseg - INFO - Iter [31000/40000]	lr: 1.350e-05, eta: 0:42:17, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0114, decode.acc_seg: 99.5252, loss: 0.0114
2022-11-29 20:48:19,184 - mmseg - INFO - Iter [31050/40000]	lr: 1.343e-05, eta: 0:42:03, time: 0.265, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0161, decode.acc_seg: 99.2317, loss: 0.0161
2022-11-29 20:48:33,201 - mmseg - INFO - Iter [31100/40000]	lr: 1.335e-05, eta: 0:41:49, time: 0.280, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0171, decode.acc_seg: 99.2218, loss: 0.0171
2022-11-29 20:48:48,521 - mmseg - INFO - Iter [31150/40000]	lr: 1.328e-05, eta: 0:41:35, time: 0.306, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0140, decode.acc_seg: 99.4379, loss: 0.0140
2022-11-29 20:49:01,006 - mmseg - INFO - Iter [31200/40000]	lr: 1.320e-05, eta: 0:41:20, time: 0.250, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0116, decode.acc_seg: 99.5323, loss: 0.0116
2022-11-29 20:49:13,678 - mmseg - INFO - Iter [31250/40000]	lr: 1.313e-05, eta: 0:41:06, time: 0.253, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0135, decode.acc_seg: 99.3981, loss: 0.0135
2022-11-29 20:49:28,537 - mmseg - INFO - Iter [31300/40000]	lr: 1.305e-05, eta: 0:40:52, time: 0.297, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0119, decode.acc_seg: 99.4916, loss: 0.0119
2022-11-29 20:49:41,473 - mmseg - INFO - Iter [31350/40000]	lr: 1.298e-05, eta: 0:40:38, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0139, decode.acc_seg: 99.3802, loss: 0.0139
2022-11-29 20:49:54,317 - mmseg - INFO - Iter [31400/40000]	lr: 1.290e-05, eta: 0:40:23, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0131, decode.acc_seg: 99.4585, loss: 0.0131
2022-11-29 20:50:07,180 - mmseg - INFO - Iter [31450/40000]	lr: 1.283e-05, eta: 0:40:09, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0171, decode.acc_seg: 99.3297, loss: 0.0171
2022-11-29 20:50:23,465 - mmseg - INFO - Iter [31500/40000]	lr: 1.275e-05, eta: 0:39:55, time: 0.326, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0149, decode.acc_seg: 99.3553, loss: 0.0149
2022-11-29 20:50:36,547 - mmseg - INFO - Iter [31550/40000]	lr: 1.268e-05, eta: 0:39:41, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0110, decode.acc_seg: 99.4964, loss: 0.0110
2022-11-29 20:50:49,549 - mmseg - INFO - Iter [31600/40000]	lr: 1.260e-05, eta: 0:39:26, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0117, decode.acc_seg: 99.4530, loss: 0.0117
2022-11-29 20:51:02,595 - mmseg - INFO - Iter [31650/40000]	lr: 1.253e-05, eta: 0:39:12, time: 0.261, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0134, decode.acc_seg: 99.3044, loss: 0.0134
2022-11-29 20:51:17,608 - mmseg - INFO - Iter [31700/40000]	lr: 1.245e-05, eta: 0:38:58, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0116, decode.acc_seg: 99.4611, loss: 0.0116
2022-11-29 20:51:30,462 - mmseg - INFO - Iter [31750/40000]	lr: 1.238e-05, eta: 0:38:44, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0179, decode.acc_seg: 99.2915, loss: 0.0179
2022-11-29 20:51:43,322 - mmseg - INFO - Iter [31800/40000]	lr: 1.230e-05, eta: 0:38:29, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0204, decode.acc_seg: 99.2130, loss: 0.0204
2022-11-29 20:51:58,246 - mmseg - INFO - Iter [31850/40000]	lr: 1.223e-05, eta: 0:38:16, time: 0.298, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0134, decode.acc_seg: 99.5060, loss: 0.0134
2022-11-29 20:52:11,105 - mmseg - INFO - Iter [31900/40000]	lr: 1.215e-05, eta: 0:38:01, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0172, decode.acc_seg: 99.2848, loss: 0.0172
2022-11-29 20:52:23,983 - mmseg - INFO - Iter [31950/40000]	lr: 1.208e-05, eta: 0:37:47, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0134, decode.acc_seg: 99.4317, loss: 0.0134
2022-11-29 20:52:37,015 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:52:37,016 - mmseg - INFO - Iter [32000/40000]	lr: 1.200e-05, eta: 0:37:32, time: 0.261, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0204, decode.acc_seg: 99.2494, loss: 0.0204
2022-11-29 20:52:51,976 - mmseg - INFO - Iter [32050/40000]	lr: 1.193e-05, eta: 0:37:19, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0167, decode.acc_seg: 99.3270, loss: 0.0167
2022-11-29 20:53:04,821 - mmseg - INFO - Iter [32100/40000]	lr: 1.185e-05, eta: 0:37:04, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0158, decode.acc_seg: 99.3077, loss: 0.0158
2022-11-29 20:53:17,647 - mmseg - INFO - Iter [32150/40000]	lr: 1.178e-05, eta: 0:36:50, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0198, decode.acc_seg: 99.2265, loss: 0.0198
2022-11-29 20:53:30,538 - mmseg - INFO - Iter [32200/40000]	lr: 1.170e-05, eta: 0:36:35, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0484, decode.acc_seg: 98.0633, loss: 0.0484
2022-11-29 20:53:45,627 - mmseg - INFO - Iter [32250/40000]	lr: 1.163e-05, eta: 0:36:22, time: 0.302, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0632, decode.acc_seg: 98.7129, loss: 0.0632
2022-11-29 20:53:58,490 - mmseg - INFO - Iter [32300/40000]	lr: 1.155e-05, eta: 0:36:07, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0178, decode.acc_seg: 99.2414, loss: 0.0178
2022-11-29 20:54:11,354 - mmseg - INFO - Iter [32350/40000]	lr: 1.148e-05, eta: 0:35:53, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0176, decode.acc_seg: 99.2120, loss: 0.0176
2022-11-29 20:54:26,216 - mmseg - INFO - Iter [32400/40000]	lr: 1.140e-05, eta: 0:35:39, time: 0.297, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0105, decode.acc_seg: 99.5905, loss: 0.0105
2022-11-29 20:54:38,625 - mmseg - INFO - Iter [32450/40000]	lr: 1.133e-05, eta: 0:35:25, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0188, decode.acc_seg: 99.2185, loss: 0.0188
2022-11-29 20:54:50,979 - mmseg - INFO - Iter [32500/40000]	lr: 1.125e-05, eta: 0:35:10, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0136, decode.acc_seg: 99.3612, loss: 0.0136
2022-11-29 20:55:03,380 - mmseg - INFO - Iter [32550/40000]	lr: 1.118e-05, eta: 0:34:56, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0244, decode.acc_seg: 99.1795, loss: 0.0244
2022-11-29 20:55:17,837 - mmseg - INFO - Iter [32600/40000]	lr: 1.110e-05, eta: 0:34:42, time: 0.289, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0113, decode.acc_seg: 99.5188, loss: 0.0113
2022-11-29 20:55:30,200 - mmseg - INFO - Iter [32650/40000]	lr: 1.103e-05, eta: 0:34:27, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0140, decode.acc_seg: 99.3506, loss: 0.0140
2022-11-29 20:55:42,573 - mmseg - INFO - Iter [32700/40000]	lr: 1.095e-05, eta: 0:34:13, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0125, decode.acc_seg: 99.5150, loss: 0.0125
2022-11-29 20:55:55,027 - mmseg - INFO - Iter [32750/40000]	lr: 1.088e-05, eta: 0:33:58, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0120, decode.acc_seg: 99.5085, loss: 0.0120
2022-11-29 20:56:09,700 - mmseg - INFO - Iter [32800/40000]	lr: 1.080e-05, eta: 0:33:44, time: 0.293, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0141, decode.acc_seg: 98.5577, loss: 0.0141
2022-11-29 20:56:22,102 - mmseg - INFO - Iter [32850/40000]	lr: 1.073e-05, eta: 0:33:30, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0132, decode.acc_seg: 99.3711, loss: 0.0132
2022-11-29 20:56:36,184 - mmseg - INFO - Iter [32900/40000]	lr: 1.065e-05, eta: 0:33:16, time: 0.282, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0108, decode.acc_seg: 99.5893, loss: 0.0108
2022-11-29 20:56:52,802 - mmseg - INFO - Iter [32950/40000]	lr: 1.058e-05, eta: 0:33:02, time: 0.332, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0106, decode.acc_seg: 99.5416, loss: 0.0106
2022-11-29 20:57:05,675 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 20:57:05,676 - mmseg - INFO - Iter [33000/40000]	lr: 1.050e-05, eta: 0:32:48, time: 0.257, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0121, decode.acc_seg: 99.5231, loss: 0.0121
2022-11-29 20:57:18,121 - mmseg - INFO - Iter [33050/40000]	lr: 1.043e-05, eta: 0:32:34, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0132, decode.acc_seg: 99.4283, loss: 0.0132
2022-11-29 20:57:30,542 - mmseg - INFO - Iter [33100/40000]	lr: 1.035e-05, eta: 0:32:19, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0113, decode.acc_seg: 99.4714, loss: 0.0113
2022-11-29 20:57:45,063 - mmseg - INFO - Iter [33150/40000]	lr: 1.028e-05, eta: 0:32:05, time: 0.290, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0096, decode.acc_seg: 99.5346, loss: 0.0096
2022-11-29 20:57:57,438 - mmseg - INFO - Iter [33200/40000]	lr: 1.020e-05, eta: 0:31:51, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0119, decode.acc_seg: 99.4765, loss: 0.0119
2022-11-29 20:58:09,841 - mmseg - INFO - Iter [33250/40000]	lr: 1.013e-05, eta: 0:31:37, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0109, decode.acc_seg: 99.4997, loss: 0.0109
2022-11-29 20:58:22,228 - mmseg - INFO - Iter [33300/40000]	lr: 1.005e-05, eta: 0:31:22, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0166, decode.acc_seg: 99.2160, loss: 0.0166
2022-11-29 20:58:37,723 - mmseg - INFO - Iter [33350/40000]	lr: 9.976e-06, eta: 0:31:08, time: 0.310, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0144, decode.acc_seg: 99.3316, loss: 0.0144
2022-11-29 20:58:51,240 - mmseg - INFO - Iter [33400/40000]	lr: 9.901e-06, eta: 0:30:54, time: 0.270, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0152, decode.acc_seg: 99.3133, loss: 0.0152
2022-11-29 20:59:03,626 - mmseg - INFO - Iter [33450/40000]	lr: 9.826e-06, eta: 0:30:40, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0114, decode.acc_seg: 99.4159, loss: 0.0114
2022-11-29 20:59:18,199 - mmseg - INFO - Iter [33500/40000]	lr: 9.752e-06, eta: 0:30:26, time: 0.291, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0084, decode.acc_seg: 99.6152, loss: 0.0084
2022-11-29 20:59:30,923 - mmseg - INFO - Iter [33550/40000]	lr: 9.676e-06, eta: 0:30:12, time: 0.254, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0123, decode.acc_seg: 99.4214, loss: 0.0123
2022-11-29 20:59:43,516 - mmseg - INFO - Iter [33600/40000]	lr: 9.601e-06, eta: 0:29:57, time: 0.252, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0099, decode.acc_seg: 99.5761, loss: 0.0099
2022-11-29 20:59:56,503 - mmseg - INFO - Iter [33650/40000]	lr: 9.527e-06, eta: 0:29:43, time: 0.260, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0123, decode.acc_seg: 99.4587, loss: 0.0123
2022-11-29 21:00:12,539 - mmseg - INFO - Iter [33700/40000]	lr: 9.452e-06, eta: 0:29:29, time: 0.321, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0123, decode.acc_seg: 99.3889, loss: 0.0123
2022-11-29 21:00:25,368 - mmseg - INFO - Iter [33750/40000]	lr: 9.377e-06, eta: 0:29:15, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0118, decode.acc_seg: 99.5073, loss: 0.0118
2022-11-29 21:00:38,165 - mmseg - INFO - Iter [33800/40000]	lr: 9.301e-06, eta: 0:29:01, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0137, decode.acc_seg: 99.4274, loss: 0.0137
2022-11-29 21:00:51,458 - mmseg - INFO - Iter [33850/40000]	lr: 9.227e-06, eta: 0:28:47, time: 0.266, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0177, decode.acc_seg: 99.2275, loss: 0.0177
2022-11-29 21:01:06,876 - mmseg - INFO - Iter [33900/40000]	lr: 9.152e-06, eta: 0:28:33, time: 0.308, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0127, decode.acc_seg: 99.4681, loss: 0.0127
2022-11-29 21:01:19,880 - mmseg - INFO - Iter [33950/40000]	lr: 9.077e-06, eta: 0:28:19, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0149, decode.acc_seg: 99.2832, loss: 0.0149
2022-11-29 21:01:33,403 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 21:01:33,403 - mmseg - INFO - Iter [34000/40000]	lr: 9.001e-06, eta: 0:28:04, time: 0.270, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0140, decode.acc_seg: 99.3928, loss: 0.0140
2022-11-29 21:01:48,451 - mmseg - INFO - Iter [34050/40000]	lr: 8.926e-06, eta: 0:27:51, time: 0.301, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0105, decode.acc_seg: 99.5540, loss: 0.0105
2022-11-29 21:02:01,213 - mmseg - INFO - Iter [34100/40000]	lr: 8.852e-06, eta: 0:27:36, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0243, decode.acc_seg: 99.2737, loss: 0.0243
2022-11-29 21:02:13,941 - mmseg - INFO - Iter [34150/40000]	lr: 8.777e-06, eta: 0:27:22, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0091, decode.acc_seg: 99.5797, loss: 0.0091
2022-11-29 21:02:26,698 - mmseg - INFO - Iter [34200/40000]	lr: 8.701e-06, eta: 0:27:08, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0168, decode.acc_seg: 99.2772, loss: 0.0168
2022-11-29 21:02:41,569 - mmseg - INFO - Iter [34250/40000]	lr: 8.626e-06, eta: 0:26:54, time: 0.297, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0129, decode.acc_seg: 99.4316, loss: 0.0129
2022-11-29 21:02:54,353 - mmseg - INFO - Iter [34300/40000]	lr: 8.552e-06, eta: 0:26:40, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0172, decode.acc_seg: 99.3036, loss: 0.0172
2022-11-29 21:03:07,170 - mmseg - INFO - Iter [34350/40000]	lr: 8.477e-06, eta: 0:26:25, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0115, decode.acc_seg: 99.5243, loss: 0.0115
2022-11-29 21:03:19,951 - mmseg - INFO - Iter [34400/40000]	lr: 8.401e-06, eta: 0:26:11, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0110, decode.acc_seg: 99.5752, loss: 0.0110
2022-11-29 21:03:34,879 - mmseg - INFO - Iter [34450/40000]	lr: 8.326e-06, eta: 0:25:57, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0153, decode.acc_seg: 99.4159, loss: 0.0153
2022-11-29 21:03:47,676 - mmseg - INFO - Iter [34500/40000]	lr: 8.252e-06, eta: 0:25:43, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0103, decode.acc_seg: 99.5004, loss: 0.0103
2022-11-29 21:04:00,468 - mmseg - INFO - Iter [34550/40000]	lr: 8.177e-06, eta: 0:25:29, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0173, decode.acc_seg: 99.3122, loss: 0.0173
2022-11-29 21:04:15,304 - mmseg - INFO - Iter [34600/40000]	lr: 8.101e-06, eta: 0:25:15, time: 0.297, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0127, decode.acc_seg: 99.4732, loss: 0.0127
2022-11-29 21:04:28,057 - mmseg - INFO - Iter [34650/40000]	lr: 8.026e-06, eta: 0:25:01, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0147, decode.acc_seg: 99.4130, loss: 0.0147
2022-11-29 21:04:40,812 - mmseg - INFO - Iter [34700/40000]	lr: 7.952e-06, eta: 0:24:46, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0178, decode.acc_seg: 99.2174, loss: 0.0178
2022-11-29 21:04:53,601 - mmseg - INFO - Iter [34750/40000]	lr: 7.877e-06, eta: 0:24:32, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0114, decode.acc_seg: 99.3675, loss: 0.0114
2022-11-29 21:05:08,776 - mmseg - INFO - Iter [34800/40000]	lr: 7.801e-06, eta: 0:24:18, time: 0.303, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0094, decode.acc_seg: 99.5923, loss: 0.0094
2022-11-29 21:05:21,229 - mmseg - INFO - Iter [34850/40000]	lr: 7.726e-06, eta: 0:24:04, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0103, decode.acc_seg: 99.5652, loss: 0.0103
2022-11-29 21:05:33,585 - mmseg - INFO - Iter [34900/40000]	lr: 7.651e-06, eta: 0:23:50, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0123, decode.acc_seg: 99.4784, loss: 0.0123
2022-11-29 21:05:45,939 - mmseg - INFO - Iter [34950/40000]	lr: 7.577e-06, eta: 0:23:36, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0124, decode.acc_seg: 99.3705, loss: 0.0124
2022-11-29 21:06:02,742 - mmseg - INFO - Saving checkpoint at 35000 iterations
2022-11-29 21:06:05,312 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 21:06:05,312 - mmseg - INFO - Iter [35000/40000]	lr: 7.502e-06, eta: 0:23:22, time: 0.387, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0088, decode.acc_seg: 99.6254, loss: 0.0088
2022-11-29 21:06:46,734 - mmseg - INFO - per class results:
2022-11-29 21:06:46,735 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 92.28 | 97.53 |
|  aeroplane  | 74.17 |  91.9 |
|   bicycle   |  65.2 | 82.45 |
|     bird    | 83.46 | 89.58 |
|     boat    | 52.99 | 63.18 |
|    bottle   | 62.51 | 68.07 |
|     bus     | 80.99 | 91.58 |
|     car     | 77.61 | 86.49 |
|     cat     | 85.72 | 88.85 |
|    chair    | 29.12 | 34.51 |
|     cow     | 54.55 | 80.49 |
| diningtable | 49.67 | 61.39 |
|     dog     | 79.85 | 90.01 |
|    horse    | 60.08 | 66.45 |
|  motorbike  | 71.25 | 78.01 |
|    person   |  81.1 |  88.6 |
| pottedplant | 44.48 | 48.95 |
|    sheep    | 72.54 | 80.22 |
|     sofa    |  31.8 | 34.76 |
|    train    | 77.18 | 88.59 |
|  tvmonitor  | 42.61 | 49.05 |
+-------------+-------+-------+
2022-11-29 21:06:46,735 - mmseg - INFO - Summary:
2022-11-29 21:06:46,735 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 92.25 | 65.2 | 74.32 |
+-------+------+-------+
2022-11-29 21:06:46,736 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 21:06:46,736 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9225, mIoU: 0.6520, mAcc: 0.7432, IoU.background: 0.9228, IoU.aeroplane: 0.7417, IoU.bicycle: 0.6520, IoU.bird: 0.8346, IoU.boat: 0.5299, IoU.bottle: 0.6251, IoU.bus: 0.8099, IoU.car: 0.7761, IoU.cat: 0.8572, IoU.chair: 0.2912, IoU.cow: 0.5455, IoU.diningtable: 0.4967, IoU.dog: 0.7985, IoU.horse: 0.6008, IoU.motorbike: 0.7125, IoU.person: 0.8110, IoU.pottedplant: 0.4448, IoU.sheep: 0.7254, IoU.sofa: 0.3180, IoU.train: 0.7718, IoU.tvmonitor: 0.4261, Acc.background: 0.9753, Acc.aeroplane: 0.9190, Acc.bicycle: 0.8245, Acc.bird: 0.8958, Acc.boat: 0.6318, Acc.bottle: 0.6807, Acc.bus: 0.9158, Acc.car: 0.8649, Acc.cat: 0.8885, Acc.chair: 0.3451, Acc.cow: 0.8049, Acc.diningtable: 0.6139, Acc.dog: 0.9001, Acc.horse: 0.6645, Acc.motorbike: 0.7801, Acc.person: 0.8860, Acc.pottedplant: 0.4895, Acc.sheep: 0.8022, Acc.sofa: 0.3476, Acc.train: 0.8859, Acc.tvmonitor: 0.4905
2022-11-29 21:07:00,515 - mmseg - INFO - Iter [35050/40000]	lr: 7.426e-06, eta: 0:23:14, time: 1.104, data_time: 0.834, memory: 5529, decode.loss_ce: 0.0120, decode.acc_seg: 99.4492, loss: 0.0120
2022-11-29 21:07:14,126 - mmseg - INFO - Iter [35100/40000]	lr: 7.351e-06, eta: 0:23:00, time: 0.272, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0116, decode.acc_seg: 99.4937, loss: 0.0116
2022-11-29 21:07:28,824 - mmseg - INFO - Iter [35150/40000]	lr: 7.277e-06, eta: 0:22:46, time: 0.294, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0101, decode.acc_seg: 99.5793, loss: 0.0101
2022-11-29 21:07:42,422 - mmseg - INFO - Iter [35200/40000]	lr: 7.202e-06, eta: 0:22:32, time: 0.272, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0131, decode.acc_seg: 99.4363, loss: 0.0131
2022-11-29 21:07:56,991 - mmseg - INFO - Iter [35250/40000]	lr: 7.126e-06, eta: 0:22:18, time: 0.291, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0095, decode.acc_seg: 99.5705, loss: 0.0095
2022-11-29 21:08:09,786 - mmseg - INFO - Iter [35300/40000]	lr: 7.051e-06, eta: 0:22:04, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0113, decode.acc_seg: 99.5158, loss: 0.0113
2022-11-29 21:08:24,748 - mmseg - INFO - Iter [35350/40000]	lr: 6.977e-06, eta: 0:21:50, time: 0.299, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0135, decode.acc_seg: 99.4434, loss: 0.0135
2022-11-29 21:08:37,619 - mmseg - INFO - Iter [35400/40000]	lr: 6.902e-06, eta: 0:21:35, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0151, decode.acc_seg: 99.3603, loss: 0.0151
2022-11-29 21:08:50,403 - mmseg - INFO - Iter [35450/40000]	lr: 6.826e-06, eta: 0:21:21, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0126, decode.acc_seg: 99.4255, loss: 0.0126
2022-11-29 21:09:03,232 - mmseg - INFO - Iter [35500/40000]	lr: 6.751e-06, eta: 0:21:07, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0128, decode.acc_seg: 99.3630, loss: 0.0128
2022-11-29 21:09:18,219 - mmseg - INFO - Iter [35550/40000]	lr: 6.677e-06, eta: 0:20:53, time: 0.300, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0108, decode.acc_seg: 99.5316, loss: 0.0108
2022-11-29 21:09:30,988 - mmseg - INFO - Iter [35600/40000]	lr: 6.602e-06, eta: 0:20:39, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0136, decode.acc_seg: 99.4323, loss: 0.0136
2022-11-29 21:09:43,854 - mmseg - INFO - Iter [35650/40000]	lr: 6.526e-06, eta: 0:20:24, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0134, decode.acc_seg: 99.3894, loss: 0.0134
2022-11-29 21:09:58,733 - mmseg - INFO - Iter [35700/40000]	lr: 6.451e-06, eta: 0:20:10, time: 0.298, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0161, decode.acc_seg: 99.3648, loss: 0.0161
2022-11-29 21:10:11,379 - mmseg - INFO - Iter [35750/40000]	lr: 6.377e-06, eta: 0:19:56, time: 0.253, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0110, decode.acc_seg: 99.4758, loss: 0.0110
2022-11-29 21:10:24,842 - mmseg - INFO - Iter [35800/40000]	lr: 6.302e-06, eta: 0:19:42, time: 0.269, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0116, decode.acc_seg: 99.5416, loss: 0.0116
2022-11-29 21:10:38,276 - mmseg - INFO - Iter [35850/40000]	lr: 6.226e-06, eta: 0:19:28, time: 0.269, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0130, decode.acc_seg: 99.4483, loss: 0.0130
2022-11-29 21:10:53,740 - mmseg - INFO - Iter [35900/40000]	lr: 6.151e-06, eta: 0:19:14, time: 0.309, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0070, decode.acc_seg: 99.7171, loss: 0.0070
2022-11-29 21:11:06,779 - mmseg - INFO - Iter [35950/40000]	lr: 6.077e-06, eta: 0:19:00, time: 0.261, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0097, decode.acc_seg: 99.5707, loss: 0.0097
2022-11-29 21:11:19,518 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 21:11:19,518 - mmseg - INFO - Iter [36000/40000]	lr: 6.002e-06, eta: 0:18:46, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0123, decode.acc_seg: 99.3956, loss: 0.0123
2022-11-29 21:11:32,296 - mmseg - INFO - Iter [36050/40000]	lr: 5.926e-06, eta: 0:18:31, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0113, decode.acc_seg: 99.4865, loss: 0.0113
2022-11-29 21:11:47,314 - mmseg - INFO - Iter [36100/40000]	lr: 5.851e-06, eta: 0:18:17, time: 0.300, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0138, decode.acc_seg: 99.3814, loss: 0.0138
2022-11-29 21:12:00,082 - mmseg - INFO - Iter [36150/40000]	lr: 5.777e-06, eta: 0:18:03, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0082, decode.acc_seg: 99.6546, loss: 0.0082
2022-11-29 21:12:14,564 - mmseg - INFO - Iter [36200/40000]	lr: 5.702e-06, eta: 0:17:49, time: 0.290, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0171, decode.acc_seg: 99.3667, loss: 0.0171
2022-11-29 21:12:30,250 - mmseg - INFO - Iter [36250/40000]	lr: 5.627e-06, eta: 0:17:35, time: 0.314, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0142, decode.acc_seg: 99.3596, loss: 0.0142
2022-11-29 21:12:43,094 - mmseg - INFO - Iter [36300/40000]	lr: 5.551e-06, eta: 0:17:21, time: 0.257, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0110, decode.acc_seg: 99.3756, loss: 0.0110
2022-11-29 21:12:55,448 - mmseg - INFO - Iter [36350/40000]	lr: 5.476e-06, eta: 0:17:07, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0126, decode.acc_seg: 99.4337, loss: 0.0126
2022-11-29 21:13:07,764 - mmseg - INFO - Iter [36400/40000]	lr: 5.402e-06, eta: 0:16:52, time: 0.246, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0098, decode.acc_seg: 99.4609, loss: 0.0098
2022-11-29 21:13:22,287 - mmseg - INFO - Iter [36450/40000]	lr: 5.327e-06, eta: 0:16:38, time: 0.290, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0103, decode.acc_seg: 99.5918, loss: 0.0103
2022-11-29 21:13:35,202 - mmseg - INFO - Iter [36500/40000]	lr: 5.251e-06, eta: 0:16:24, time: 0.258, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0143, decode.acc_seg: 99.3919, loss: 0.0143
2022-11-29 21:13:47,875 - mmseg - INFO - Iter [36550/40000]	lr: 5.176e-06, eta: 0:16:10, time: 0.253, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0259, decode.acc_seg: 99.2560, loss: 0.0259
2022-11-29 21:14:00,421 - mmseg - INFO - Iter [36600/40000]	lr: 5.102e-06, eta: 0:15:56, time: 0.251, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0148, decode.acc_seg: 99.3704, loss: 0.0148
2022-11-29 21:14:14,956 - mmseg - INFO - Iter [36650/40000]	lr: 5.027e-06, eta: 0:15:42, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0113, decode.acc_seg: 99.4794, loss: 0.0113
2022-11-29 21:14:27,571 - mmseg - INFO - Iter [36700/40000]	lr: 4.951e-06, eta: 0:15:28, time: 0.252, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0098, decode.acc_seg: 99.4606, loss: 0.0098
2022-11-29 21:14:40,357 - mmseg - INFO - Iter [36750/40000]	lr: 4.876e-06, eta: 0:15:13, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0120, decode.acc_seg: 99.5105, loss: 0.0120
2022-11-29 21:14:55,472 - mmseg - INFO - Iter [36800/40000]	lr: 4.802e-06, eta: 0:15:00, time: 0.302, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0126, decode.acc_seg: 99.4224, loss: 0.0126
2022-11-29 21:15:08,842 - mmseg - INFO - Iter [36850/40000]	lr: 4.727e-06, eta: 0:14:45, time: 0.267, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0141, decode.acc_seg: 99.4132, loss: 0.0141
2022-11-29 21:15:21,810 - mmseg - INFO - Iter [36900/40000]	lr: 4.651e-06, eta: 0:14:31, time: 0.259, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0107, decode.acc_seg: 99.5238, loss: 0.0107
2022-11-29 21:15:34,927 - mmseg - INFO - Iter [36950/40000]	lr: 4.576e-06, eta: 0:14:17, time: 0.262, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0098, decode.acc_seg: 99.6050, loss: 0.0098
2022-11-29 21:15:49,950 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 21:15:49,950 - mmseg - INFO - Iter [37000/40000]	lr: 4.502e-06, eta: 0:14:03, time: 0.300, data_time: 0.049, memory: 5529, decode.loss_ce: 0.0125, decode.acc_seg: 99.3980, loss: 0.0125
2022-11-29 21:16:02,844 - mmseg - INFO - Iter [37050/40000]	lr: 4.427e-06, eta: 0:13:49, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0099, decode.acc_seg: 99.5904, loss: 0.0099
2022-11-29 21:16:15,664 - mmseg - INFO - Iter [37100/40000]	lr: 4.351e-06, eta: 0:13:35, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0115, decode.acc_seg: 99.4641, loss: 0.0115
2022-11-29 21:16:30,594 - mmseg - INFO - Iter [37150/40000]	lr: 4.276e-06, eta: 0:13:21, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0121, decode.acc_seg: 99.4405, loss: 0.0121
2022-11-29 21:16:43,812 - mmseg - INFO - Iter [37200/40000]	lr: 4.202e-06, eta: 0:13:07, time: 0.264, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0240, decode.acc_seg: 99.2535, loss: 0.0240
2022-11-29 21:16:56,628 - mmseg - INFO - Iter [37250/40000]	lr: 4.127e-06, eta: 0:12:53, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0143, decode.acc_seg: 99.3597, loss: 0.0143
2022-11-29 21:17:09,429 - mmseg - INFO - Iter [37300/40000]	lr: 4.051e-06, eta: 0:12:38, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0139, decode.acc_seg: 99.4415, loss: 0.0139
2022-11-29 21:17:24,736 - mmseg - INFO - Iter [37350/40000]	lr: 3.976e-06, eta: 0:12:24, time: 0.306, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0090, decode.acc_seg: 99.6032, loss: 0.0090
2022-11-29 21:17:38,095 - mmseg - INFO - Iter [37400/40000]	lr: 3.901e-06, eta: 0:12:10, time: 0.267, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0119, decode.acc_seg: 99.5376, loss: 0.0119
2022-11-29 21:17:50,854 - mmseg - INFO - Iter [37450/40000]	lr: 3.827e-06, eta: 0:11:56, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0125, decode.acc_seg: 99.4259, loss: 0.0125
2022-11-29 21:18:03,661 - mmseg - INFO - Iter [37500/40000]	lr: 3.752e-06, eta: 0:11:42, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0136, decode.acc_seg: 99.4238, loss: 0.0136
2022-11-29 21:18:18,483 - mmseg - INFO - Iter [37550/40000]	lr: 3.676e-06, eta: 0:11:28, time: 0.296, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0095, decode.acc_seg: 99.4712, loss: 0.0095
2022-11-29 21:18:31,242 - mmseg - INFO - Iter [37600/40000]	lr: 3.601e-06, eta: 0:11:14, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0091, decode.acc_seg: 99.6750, loss: 0.0091
2022-11-29 21:18:43,989 - mmseg - INFO - Iter [37650/40000]	lr: 3.527e-06, eta: 0:11:00, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0111, decode.acc_seg: 99.4708, loss: 0.0111
2022-11-29 21:18:58,894 - mmseg - INFO - Iter [37700/40000]	lr: 3.452e-06, eta: 0:10:46, time: 0.298, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0154, decode.acc_seg: 99.3221, loss: 0.0154
2022-11-29 21:19:12,214 - mmseg - INFO - Iter [37750/40000]	lr: 3.376e-06, eta: 0:10:32, time: 0.266, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0102, decode.acc_seg: 99.5711, loss: 0.0102
2022-11-29 21:19:24,771 - mmseg - INFO - Iter [37800/40000]	lr: 3.301e-06, eta: 0:10:18, time: 0.251, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0127, decode.acc_seg: 99.4217, loss: 0.0127
2022-11-29 21:19:37,156 - mmseg - INFO - Iter [37850/40000]	lr: 3.227e-06, eta: 0:10:03, time: 0.248, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0098, decode.acc_seg: 99.5552, loss: 0.0098
2022-11-29 21:19:51,683 - mmseg - INFO - Iter [37900/40000]	lr: 3.152e-06, eta: 0:09:49, time: 0.291, data_time: 0.046, memory: 5529, decode.loss_ce: 0.0096, decode.acc_seg: 99.5471, loss: 0.0096
2022-11-29 21:20:04,361 - mmseg - INFO - Iter [37950/40000]	lr: 3.076e-06, eta: 0:09:35, time: 0.254, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0107, decode.acc_seg: 99.4575, loss: 0.0107
2022-11-29 21:20:16,807 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 21:20:16,807 - mmseg - INFO - Iter [38000/40000]	lr: 3.001e-06, eta: 0:09:21, time: 0.249, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0093, decode.acc_seg: 99.5862, loss: 0.0093
2022-11-29 21:20:29,360 - mmseg - INFO - Iter [38050/40000]	lr: 2.927e-06, eta: 0:09:07, time: 0.251, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0098, decode.acc_seg: 99.5712, loss: 0.0098
2022-11-29 21:20:44,930 - mmseg - INFO - Iter [38100/40000]	lr: 2.852e-06, eta: 0:08:53, time: 0.311, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0118, decode.acc_seg: 99.4634, loss: 0.0118
2022-11-29 21:20:58,377 - mmseg - INFO - Iter [38150/40000]	lr: 2.776e-06, eta: 0:08:39, time: 0.269, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0144, decode.acc_seg: 99.3577, loss: 0.0144
2022-11-29 21:21:11,169 - mmseg - INFO - Iter [38200/40000]	lr: 2.701e-06, eta: 0:08:25, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0126, decode.acc_seg: 99.4331, loss: 0.0126
2022-11-29 21:21:26,070 - mmseg - INFO - Iter [38250/40000]	lr: 2.627e-06, eta: 0:08:11, time: 0.298, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0100, decode.acc_seg: 99.5900, loss: 0.0100
2022-11-29 21:21:38,873 - mmseg - INFO - Iter [38300/40000]	lr: 2.552e-06, eta: 0:07:57, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0166, decode.acc_seg: 99.3491, loss: 0.0166
2022-11-29 21:21:51,642 - mmseg - INFO - Iter [38350/40000]	lr: 2.476e-06, eta: 0:07:43, time: 0.255, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0149, decode.acc_seg: 99.3746, loss: 0.0149
2022-11-29 21:22:04,448 - mmseg - INFO - Iter [38400/40000]	lr: 2.401e-06, eta: 0:07:29, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0098, decode.acc_seg: 99.6077, loss: 0.0098
2022-11-29 21:22:19,918 - mmseg - INFO - Iter [38450/40000]	lr: 2.327e-06, eta: 0:07:15, time: 0.309, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0126, decode.acc_seg: 99.4498, loss: 0.0126
2022-11-29 21:22:32,946 - mmseg - INFO - Iter [38500/40000]	lr: 2.252e-06, eta: 0:07:01, time: 0.261, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0137, decode.acc_seg: 99.4922, loss: 0.0137
2022-11-29 21:22:45,768 - mmseg - INFO - Iter [38550/40000]	lr: 2.176e-06, eta: 0:06:46, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0097, decode.acc_seg: 99.5636, loss: 0.0097
2022-11-29 21:22:58,616 - mmseg - INFO - Iter [38600/40000]	lr: 2.101e-06, eta: 0:06:32, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0099, decode.acc_seg: 99.5785, loss: 0.0099
2022-11-29 21:23:13,660 - mmseg - INFO - Iter [38650/40000]	lr: 2.026e-06, eta: 0:06:18, time: 0.301, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0131, decode.acc_seg: 99.3895, loss: 0.0131
2022-11-29 21:23:26,878 - mmseg - INFO - Iter [38700/40000]	lr: 1.952e-06, eta: 0:06:04, time: 0.264, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0097, decode.acc_seg: 99.5313, loss: 0.0097
2022-11-29 21:23:39,885 - mmseg - INFO - Iter [38750/40000]	lr: 1.877e-06, eta: 0:05:50, time: 0.260, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0139, decode.acc_seg: 99.4630, loss: 0.0139
2022-11-29 21:23:54,961 - mmseg - INFO - Iter [38800/40000]	lr: 1.801e-06, eta: 0:05:36, time: 0.301, data_time: 0.049, memory: 5529, decode.loss_ce: 0.0104, decode.acc_seg: 99.5320, loss: 0.0104
2022-11-29 21:24:08,287 - mmseg - INFO - Iter [38850/40000]	lr: 1.726e-06, eta: 0:05:22, time: 0.267, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0136, decode.acc_seg: 99.4451, loss: 0.0136
2022-11-29 21:24:22,911 - mmseg - INFO - Iter [38900/40000]	lr: 1.652e-06, eta: 0:05:08, time: 0.292, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0104, decode.acc_seg: 99.4557, loss: 0.0104
2022-11-29 21:24:35,260 - mmseg - INFO - Iter [38950/40000]	lr: 1.577e-06, eta: 0:04:54, time: 0.247, data_time: 0.005, memory: 5529, decode.loss_ce: 0.0111, decode.acc_seg: 99.4749, loss: 0.0111
2022-11-29 21:24:49,954 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 21:24:49,955 - mmseg - INFO - Iter [39000/40000]	lr: 1.501e-06, eta: 0:04:40, time: 0.294, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0108, decode.acc_seg: 99.5149, loss: 0.0108
2022-11-29 21:25:02,718 - mmseg - INFO - Iter [39050/40000]	lr: 1.426e-06, eta: 0:04:26, time: 0.255, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0107, decode.acc_seg: 99.5215, loss: 0.0107
2022-11-29 21:25:15,564 - mmseg - INFO - Iter [39100/40000]	lr: 1.352e-06, eta: 0:04:12, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0107, decode.acc_seg: 99.5180, loss: 0.0107
2022-11-29 21:25:28,366 - mmseg - INFO - Iter [39150/40000]	lr: 1.277e-06, eta: 0:03:58, time: 0.256, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0105, decode.acc_seg: 99.5289, loss: 0.0105
2022-11-29 21:25:43,303 - mmseg - INFO - Iter [39200/40000]	lr: 1.201e-06, eta: 0:03:44, time: 0.299, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0127, decode.acc_seg: 99.5178, loss: 0.0127
2022-11-29 21:25:56,242 - mmseg - INFO - Iter [39250/40000]	lr: 1.126e-06, eta: 0:03:30, time: 0.259, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0095, decode.acc_seg: 99.5970, loss: 0.0095
2022-11-29 21:26:09,367 - mmseg - INFO - Iter [39300/40000]	lr: 1.052e-06, eta: 0:03:16, time: 0.263, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0093, decode.acc_seg: 99.5675, loss: 0.0093
2022-11-29 21:26:25,116 - mmseg - INFO - Iter [39350/40000]	lr: 9.765e-07, eta: 0:03:02, time: 0.315, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0124, decode.acc_seg: 99.4322, loss: 0.0124
2022-11-29 21:26:37,923 - mmseg - INFO - Iter [39400/40000]	lr: 9.015e-07, eta: 0:02:48, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0119, decode.acc_seg: 99.4692, loss: 0.0119
2022-11-29 21:26:50,722 - mmseg - INFO - Iter [39450/40000]	lr: 8.265e-07, eta: 0:02:34, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0135, decode.acc_seg: 99.4303, loss: 0.0135
2022-11-29 21:27:03,525 - mmseg - INFO - Iter [39500/40000]	lr: 7.515e-07, eta: 0:02:20, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0093, decode.acc_seg: 99.6079, loss: 0.0093
2022-11-29 21:27:18,585 - mmseg - INFO - Iter [39550/40000]	lr: 6.765e-07, eta: 0:02:06, time: 0.301, data_time: 0.049, memory: 5529, decode.loss_ce: 0.0119, decode.acc_seg: 99.4962, loss: 0.0119
2022-11-29 21:27:31,454 - mmseg - INFO - Iter [39600/40000]	lr: 6.015e-07, eta: 0:01:52, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0081, decode.acc_seg: 99.6218, loss: 0.0081
2022-11-29 21:27:44,280 - mmseg - INFO - Iter [39650/40000]	lr: 5.265e-07, eta: 0:01:38, time: 0.257, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0126, decode.acc_seg: 99.3155, loss: 0.0126
2022-11-29 21:27:57,080 - mmseg - INFO - Iter [39700/40000]	lr: 4.515e-07, eta: 0:01:24, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0100, decode.acc_seg: 99.5621, loss: 0.0100
2022-11-29 21:28:12,300 - mmseg - INFO - Iter [39750/40000]	lr: 3.765e-07, eta: 0:01:10, time: 0.304, data_time: 0.048, memory: 5529, decode.loss_ce: 0.0082, decode.acc_seg: 99.5820, loss: 0.0082
2022-11-29 21:28:25,206 - mmseg - INFO - Iter [39800/40000]	lr: 3.015e-07, eta: 0:00:56, time: 0.258, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0106, decode.acc_seg: 99.5803, loss: 0.0106
2022-11-29 21:28:38,021 - mmseg - INFO - Iter [39850/40000]	lr: 2.265e-07, eta: 0:00:42, time: 0.256, data_time: 0.007, memory: 5529, decode.loss_ce: 0.0099, decode.acc_seg: 99.5721, loss: 0.0099
2022-11-29 21:28:52,621 - mmseg - INFO - Iter [39900/40000]	lr: 1.515e-07, eta: 0:00:28, time: 0.292, data_time: 0.047, memory: 5529, decode.loss_ce: 0.0165, decode.acc_seg: 99.2457, loss: 0.0165
2022-11-29 21:29:05,138 - mmseg - INFO - Iter [39950/40000]	lr: 7.650e-08, eta: 0:00:14, time: 0.250, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0112, decode.acc_seg: 99.4646, loss: 0.0112
2022-11-29 21:29:17,943 - mmseg - INFO - Saving checkpoint at 40000 iterations
2022-11-29 21:29:19,895 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 21:29:19,895 - mmseg - INFO - Iter [40000/40000]	lr: 1.500e-09, eta: 0:00:00, time: 0.295, data_time: 0.006, memory: 5529, decode.loss_ce: 0.0099, decode.acc_seg: 99.6191, loss: 0.0099
2022-11-29 21:30:02,126 - mmseg - INFO - per class results:
2022-11-29 21:30:02,128 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 92.25 | 98.11 |
|  aeroplane  | 70.94 | 91.73 |
|   bicycle   | 67.45 | 78.58 |
|     bird    | 84.51 | 88.49 |
|     boat    | 52.53 | 58.86 |
|    bottle   | 60.76 | 67.85 |
|     bus     | 84.49 | 92.36 |
|     car     | 76.92 | 85.24 |
|     cat     | 86.27 | 89.57 |
|    chair    | 30.24 | 35.34 |
|     cow     | 57.79 | 78.21 |
| diningtable | 50.02 | 54.98 |
|     dog     | 79.31 | 89.99 |
|    horse    | 61.43 |  66.0 |
|  motorbike  | 74.38 | 82.45 |
|    person   | 81.09 | 86.11 |
| pottedplant | 42.13 | 50.38 |
|    sheep    | 73.02 | 82.59 |
|     sofa    | 30.49 | 32.53 |
|    train    | 77.49 | 87.66 |
|  tvmonitor  | 45.67 | 50.19 |
+-------------+-------+-------+
2022-11-29 21:30:02,128 - mmseg - INFO - Summary:
2022-11-29 21:30:02,128 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 92.41 | 65.67 | 73.68 |
+-------+-------+-------+
2022-11-29 21:30:02,130 - mmseg - INFO - Exp name: segnext.large.512x512.voc.40k_sub.py
2022-11-29 21:30:02,130 - mmseg - INFO - Iter(val) [724]	aAcc: 0.9241, mIoU: 0.6567, mAcc: 0.7368, IoU.background: 0.9225, IoU.aeroplane: 0.7094, IoU.bicycle: 0.6745, IoU.bird: 0.8451, IoU.boat: 0.5253, IoU.bottle: 0.6076, IoU.bus: 0.8449, IoU.car: 0.7692, IoU.cat: 0.8627, IoU.chair: 0.3024, IoU.cow: 0.5779, IoU.diningtable: 0.5002, IoU.dog: 0.7931, IoU.horse: 0.6143, IoU.motorbike: 0.7438, IoU.person: 0.8109, IoU.pottedplant: 0.4213, IoU.sheep: 0.7302, IoU.sofa: 0.3049, IoU.train: 0.7749, IoU.tvmonitor: 0.4567, Acc.background: 0.9811, Acc.aeroplane: 0.9173, Acc.bicycle: 0.7858, Acc.bird: 0.8849, Acc.boat: 0.5886, Acc.bottle: 0.6785, Acc.bus: 0.9236, Acc.car: 0.8524, Acc.cat: 0.8957, Acc.chair: 0.3534, Acc.cow: 0.7821, Acc.diningtable: 0.5498, Acc.dog: 0.8999, Acc.horse: 0.6600, Acc.motorbike: 0.8245, Acc.person: 0.8611, Acc.pottedplant: 0.5038, Acc.sheep: 0.8259, Acc.sofa: 0.3253, Acc.train: 0.8766, Acc.tvmonitor: 0.5019
